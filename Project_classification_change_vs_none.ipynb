{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1jV3IklNUb9"
   },
   "source": [
    "# Read data\n",
    "\n",
    "The dataset was compiled from the files for the United States Federal Reserve Bank and the (usa_df.csv) and the European Union Euporean Central Bank (ecb_df.csv) the initial corpus at https://github.com/CarolMoore19/Central-Bank-Texts-Parsed, which contains announcements following all scheduled meetings of monetary policy committees. These data were further cleaned and prepared offline, and combined with macroeconomic variables downloaded from the Fed's public site for economic data, https://fred.stlouisfed.org/.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jKJNCSme3J8U"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmd8a\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import os \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AwvJe8gh3Vth"
   },
   "outputs": [],
   "source": [
    "os.chdir('/Users/dmd8a/OneDrive - University of Virginia/Desktop/MSDS/DS6050/Project')\n",
    "df=pd.read_csv('us_ecb_combined_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVNwmSyvPWGp"
   },
   "source": [
    "The key variables are:\n",
    "\n",
    "* Bank:  The US Federal Reserve or European Central Bnak\n",
    "\n",
    "* rate_curr:  the policy (target) interest rate set at the monetary policy committee meeting.  \n",
    "\n",
    "* rate_next:  the rate set at the subsequent meeting.\n",
    "\n",
    "* rate_change:  a categorical variable indicating if the rate changed between the current and next meeting\n",
    "\n",
    "Macroeconomic variables are only available for the US at this time:\n",
    "\n",
    "* urate:  the unemployment rate on the first day of the month of the meeting\n",
    "\n",
    "* pce_inf:  inflation for personal consumption expenditures, less food and energy, on the first day of the month of the meeting.  This is the inflation concept that the Fed uses for policy.\n",
    "\n",
    "* effective_ffr:  The market federal funds rate on the first day of the month of the meeting.  When setting policy, the fed is trying to influence this interest rate.\n",
    "\n",
    "Other variables - filename, date_dt, and chron_order_in_country - exist to to keep track of the meeting dates and do not enter into the analysis below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TUBETiSa3eiY",
    "outputId": "41a12ec1-9a95-424a-ff3e-8c44657abf34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 434 entries, 0 to 433\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   bank                    434 non-null    object \n",
      " 1   filename                434 non-null    object \n",
      " 2   date_dt                 434 non-null    object \n",
      " 3   chron_order_in_country  434 non-null    int64  \n",
      " 4   rate_curr               434 non-null    float64\n",
      " 5   rate_next               434 non-null    float64\n",
      " 6   rate_change             434 non-null    int64  \n",
      " 7   urate                   171 non-null    float64\n",
      " 8   pce_inf                 171 non-null    float64\n",
      " 9   effective_ffr           171 non-null    float64\n",
      " 10  statement               434 non-null    object \n",
      "dtypes: float64(5), int64(2), object(4)\n",
      "memory usage: 37.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hrx9B4wd4MiX",
    "outputId": "1b1d16de-81d2-4970-8c28-3d89b5e10a59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(434, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-ZC7xHqSV2W"
   },
   "source": [
    "# Standardize continuous variables\n",
    "\n",
    "To predict the interest rate level to be set at the next policy meeting, we scale the target variables: 'rate_next' , 'rate_curr', and the macroeconomic variables.\n",
    "\n",
    "Note that the central bank communications are tailored for their own jurisdictions and economic conditions.  The policy interest rate concept differs for each bank. Further, the ranges of experience are differ:  ECB has had negative nominal interest rates, which the Fed never had. \n",
    "\n",
    "For this reason, we apply a stratified standardization - one for the ECB and one for the US banks. This means that a standardized value of 0 represents the average rate for the ECB and the Fed, respectively, rather than an overall average across both banks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DIXQXcjLUqWJ",
    "outputId": "40584a53-4699-4f9f-bffa-bbd01989b6fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ecb      265\n",
       "usfed    169\n",
       "Name: bank, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.bank.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TDssovfgSHfA"
   },
   "outputs": [],
   "source": [
    "#Target var - next meeting policy rate\n",
    "df['y_std_us'] = np.where(df.bank=='usfed',\n",
    "                          (df.rate_next - np.mean(df.rate_next))/np.std(df.rate_next),np.nan)\n",
    "df['y_std_ecb'] = np.where(df.bank=='ecb',\n",
    "                          (df.rate_next - np.mean(df.rate_next))/np.std(df.rate_next),np.nan)\n",
    "df['y_std'] = np.where(df.bank=='ecb',df.y_std_ecb,df.y_std_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "zg-TiYoVVR-E",
    "outputId": "fd0ec016-a012-4c42-b214-24c1af394aa7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>y_std_us</th>\n",
       "      <th>y_std_ecb</th>\n",
       "      <th>y_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usfed</td>\n",
       "      <td>0.039051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usfed</td>\n",
       "      <td>0.039051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usfed</td>\n",
       "      <td>0.039051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>usfed</td>\n",
       "      <td>-0.271642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.271642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>usfed</td>\n",
       "      <td>-0.271642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.271642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>ecb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.126050</td>\n",
       "      <td>-1.126050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>ecb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.126050</td>\n",
       "      <td>-1.126050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>ecb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.126050</td>\n",
       "      <td>-1.126050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>ecb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.815357</td>\n",
       "      <td>-0.815357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>ecb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.349316</td>\n",
       "      <td>-0.349316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>434 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      bank  y_std_us  y_std_ecb     y_std\n",
       "0    usfed  0.039051        NaN  0.039051\n",
       "1    usfed  0.039051        NaN  0.039051\n",
       "2    usfed  0.039051        NaN  0.039051\n",
       "3    usfed -0.271642        NaN -0.271642\n",
       "4    usfed -0.271642        NaN -0.271642\n",
       "..     ...       ...        ...       ...\n",
       "429    ecb       NaN  -1.126050 -1.126050\n",
       "430    ecb       NaN  -1.126050 -1.126050\n",
       "431    ecb       NaN  -1.126050 -1.126050\n",
       "432    ecb       NaN  -0.815357 -0.815357\n",
       "433    ecb       NaN  -0.349316 -0.349316\n",
       "\n",
       "[434 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['bank','y_std_us','y_std_ecb', 'y_std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "h-Z5wwCSt8PV"
   },
   "outputs": [],
   "source": [
    "#Current var -  policy rate set at current meeting\n",
    "df['y_std_us_curr'] = np.where(df.bank=='usfed',\n",
    "                          (df.rate_curr - np.mean(df.rate_curr))/np.std(df.rate_curr),np.nan)\n",
    "df['y_std_ecb_curr'] = np.where(df.bank=='ecb',\n",
    "                          (df.rate_curr - np.mean(df.rate_curr))/np.std(df.rate_curr),np.nan)\n",
    "df['y_std_curr'] = np.where(df.bank=='ecb',df.y_std_ecb_curr,df.y_std_us_curr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F35N9R2Qr1B6"
   },
   "source": [
    "#Standardize macroeconomic variables - only available for US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "f0T7hS9ZrzsK"
   },
   "outputs": [],
   "source": [
    "#Unemployment rate the first of the month in which the meeting occurred.\n",
    "df['urate_us_std'] = np.where(df.bank=='usfed',\n",
    "                          (df.urate - np.mean(df.urate))/np.std(df.urate),np.nan)\n",
    "\n",
    "#Inflation\n",
    "df['inf_us_std'] = np.where(df.bank=='usfed',(\n",
    "    df.pce_inf - np.mean(df.pce_inf))/np.std(df.pce_inf),np.nan)\n",
    "\n",
    "\n",
    "#Effective (market) Federal Fuinds RATE\n",
    "df['effr_us_std'] = np.where(df.bank=='usfed',\n",
    "    (df.effective_ffr - np.mean(df.effective_ffr))/np.std(df.effective_ffr),np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpPuyVWBjnxj"
   },
   "source": [
    "# Keep the variables we need for the analysis\n",
    "\n",
    "The rate_change variable includes 3 categories - up, down, and same. After some experimentation and following examples in the literature we chose to model a binary outcome, up (1) or not up (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "x40hOkZ3f9iq"
   },
   "outputs": [],
   "source": [
    "df=df[['statement', 'y_std_curr','y_std','urate_us_std', 'inf_us_std', 'effr_us_std', 'rate_change']]\n",
    "#df=df[['statement', 'rate_change', 'rate_next']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "SE4yn2PjND1R",
    "outputId": "84ce4271-7aaa-4a78-c1a4-9aabcdc34cc8",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>y_std_curr</th>\n",
       "      <th>y_std</th>\n",
       "      <th>urate_us_std</th>\n",
       "      <th>inf_us_std</th>\n",
       "      <th>effr_us_std</th>\n",
       "      <th>rate_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>0.037428</td>\n",
       "      <td>0.039051</td>\n",
       "      <td>-0.104017</td>\n",
       "      <td>-0.273528</td>\n",
       "      <td>0.348743</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>0.037428</td>\n",
       "      <td>0.039051</td>\n",
       "      <td>-0.104017</td>\n",
       "      <td>-0.358325</td>\n",
       "      <td>0.309969</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>0.037428</td>\n",
       "      <td>0.039051</td>\n",
       "      <td>-0.153426</td>\n",
       "      <td>-0.238576</td>\n",
       "      <td>0.361668</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>0.037428</td>\n",
       "      <td>-0.271642</td>\n",
       "      <td>-0.153426</td>\n",
       "      <td>0.706411</td>\n",
       "      <td>0.387517</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.273162</td>\n",
       "      <td>-0.271642</td>\n",
       "      <td>-0.054609</td>\n",
       "      <td>-0.225833</td>\n",
       "      <td>-0.013152</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.273162</td>\n",
       "      <td>-0.271642</td>\n",
       "      <td>-0.005201</td>\n",
       "      <td>-0.136049</td>\n",
       "      <td>-0.058388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.273162</td>\n",
       "      <td>-0.271642</td>\n",
       "      <td>-0.104017</td>\n",
       "      <td>-0.122053</td>\n",
       "      <td>0.051472</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.273162</td>\n",
       "      <td>-0.271642</td>\n",
       "      <td>-0.054609</td>\n",
       "      <td>-0.136619</td>\n",
       "      <td>0.083784</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the federal open market committee decided to k...</td>\n",
       "      <td>-0.273162</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>0.044207</td>\n",
       "      <td>-0.310871</td>\n",
       "      <td>0.019160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>0.143024</td>\n",
       "      <td>-0.441503</td>\n",
       "      <td>0.129021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the committee continues to believe that an acc...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>0.044207</td>\n",
       "      <td>-0.489983</td>\n",
       "      <td>-0.155324</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>0.044207</td>\n",
       "      <td>-0.520189</td>\n",
       "      <td>-0.051926</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>-0.005201</td>\n",
       "      <td>-0.393720</td>\n",
       "      <td>-0.181174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>-0.153426</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-0.200561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>-0.153426</td>\n",
       "      <td>-0.060780</td>\n",
       "      <td>-0.142400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>-0.104017</td>\n",
       "      <td>-0.019717</td>\n",
       "      <td>-0.129475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.271642</td>\n",
       "      <td>-0.202834</td>\n",
       "      <td>0.162546</td>\n",
       "      <td>-0.148862</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.273162</td>\n",
       "      <td>-0.116295</td>\n",
       "      <td>-0.202834</td>\n",
       "      <td>0.294014</td>\n",
       "      <td>0.083784</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.117867</td>\n",
       "      <td>0.039051</td>\n",
       "      <td>-0.301651</td>\n",
       "      <td>0.029940</td>\n",
       "      <td>0.193645</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>0.037428</td>\n",
       "      <td>0.194398</td>\n",
       "      <td>-0.301651</td>\n",
       "      <td>0.090479</td>\n",
       "      <td>0.445679</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            statement  y_std_curr     y_std  \\\n",
       "0   the federal open market committee decided toda...    0.037428  0.039051   \n",
       "1   the federal open market committee decided toda...    0.037428  0.039051   \n",
       "2   the federal open market committee decided toda...    0.037428  0.039051   \n",
       "3   the federal open market committee decided toda...    0.037428 -0.271642   \n",
       "4   the federal open market committee decided toda...   -0.273162 -0.271642   \n",
       "5   the federal open market committee decided toda...   -0.273162 -0.271642   \n",
       "6   the federal open market committee decided toda...   -0.273162 -0.271642   \n",
       "7   the federal open market committee decided toda...   -0.273162 -0.271642   \n",
       "8   the federal open market committee decided to k...   -0.273162 -0.426989   \n",
       "9   the federal open market committee decided toda...   -0.428457 -0.426989   \n",
       "10  the committee continues to believe that an acc...   -0.428457 -0.426989   \n",
       "11  the federal open market committee decided toda...   -0.428457 -0.426989   \n",
       "12  the federal open market committee decided toda...   -0.428457 -0.426989   \n",
       "13  the federal open market committee decided toda...   -0.428457 -0.426989   \n",
       "14  the federal open market committee decided toda...   -0.428457 -0.426989   \n",
       "15  the federal open market committee decided toda...   -0.428457 -0.426989   \n",
       "16  the federal open market committee decided toda...   -0.428457 -0.271642   \n",
       "17  the federal open market committee decided toda...   -0.273162 -0.116295   \n",
       "18  the federal open market committee decided toda...   -0.117867  0.039051   \n",
       "19  the federal open market committee decided toda...    0.037428  0.194398   \n",
       "\n",
       "    urate_us_std  inf_us_std  effr_us_std  rate_change  \n",
       "0      -0.104017   -0.273528     0.348743            0  \n",
       "1      -0.104017   -0.358325     0.309969            0  \n",
       "2      -0.153426   -0.238576     0.361668            0  \n",
       "3      -0.153426    0.706411     0.387517            1  \n",
       "4      -0.054609   -0.225833    -0.013152            0  \n",
       "5      -0.005201   -0.136049    -0.058388            0  \n",
       "6      -0.104017   -0.122053     0.051472            0  \n",
       "7      -0.054609   -0.136619     0.083784            0  \n",
       "8       0.044207   -0.310871     0.019160            1  \n",
       "9       0.143024   -0.441503     0.129021            0  \n",
       "10      0.044207   -0.489983    -0.155324            0  \n",
       "11      0.044207   -0.520189    -0.051926            0  \n",
       "12     -0.005201   -0.393720    -0.181174            0  \n",
       "13     -0.153426   -0.301254    -0.200561            0  \n",
       "14     -0.153426   -0.060780    -0.142400            0  \n",
       "15     -0.104017   -0.019717    -0.129475            0  \n",
       "16     -0.202834    0.162546    -0.148862            1  \n",
       "17     -0.202834    0.294014     0.083784            1  \n",
       "18     -0.301651    0.029940     0.193645            1  \n",
       "19     -0.301651    0.090479     0.445679            1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rate_change'] = np.where(df['rate_change'] == -1, 1, df['rate_change'])\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIDI1AWhmQ3O"
   },
   "source": [
    "# Get some rough stats on the text. Knowng the length of each statement will guide our choice of dimensions later.  \n",
    "\n",
    "The max approximate length of the statements is 1,011."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqWTRpVMND1S",
    "outputId": "b7010a96-e02c-4840-ac01-92e1a8a5a05e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     434.000000\n",
       "mean      229.396313\n",
       "std       213.255292\n",
       "min        36.000000\n",
       "25%        63.000000\n",
       "50%       148.000000\n",
       "75%       380.500000\n",
       "max      1011.000000\n",
       "Name: statement, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx_length = df['statement'].str.split().str.len()\n",
    "approx_length.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NR76ZNv_ZU5z"
   },
   "source": [
    "# Shuffle the data and split it into test, train and validation sets.\n",
    "\n",
    "Although the original data are time-series, the file is not organized as such.  The future values are on the same row as the current values. Therefore we shuffle the data.\n",
    "\n",
    "We first divide the file into test and train.  Then we split the test file into test and validate (60%, 20%, 20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "D9SuoyxbqF7G"
   },
   "outputs": [],
   "source": [
    "df_shuffled=df.sample(frac=1, random_state=42).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "iHl-2doiq3Gq",
    "outputId": "759369fb-d1b2-43f0-c6bb-661982835faa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>statement</th>\n",
       "      <th>y_std_curr</th>\n",
       "      <th>y_std</th>\n",
       "      <th>urate_us_std</th>\n",
       "      <th>inf_us_std</th>\n",
       "      <th>effr_us_std</th>\n",
       "      <th>rate_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>280</td>\n",
       "      <td>at today's meeting, the governing council of t...</td>\n",
       "      <td>1.279790</td>\n",
       "      <td>1.281827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78</td>\n",
       "      <td>information received since the federal open ma...</td>\n",
       "      <td>-0.894343</td>\n",
       "      <td>-0.893030</td>\n",
       "      <td>1.477048</td>\n",
       "      <td>-0.047189</td>\n",
       "      <td>-0.756328</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113</td>\n",
       "      <td>information received since the federal open ma...</td>\n",
       "      <td>-0.739048</td>\n",
       "      <td>-0.737683</td>\n",
       "      <td>-0.499284</td>\n",
       "      <td>-0.946329</td>\n",
       "      <td>-0.678779</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>0.192724</td>\n",
       "      <td>0.194398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>324</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                          statement  y_std_curr  \\\n",
       "0    280  at today's meeting, the governing council of t...    1.279790   \n",
       "1     78  information received since the federal open ma...   -0.894343   \n",
       "2    113  information received since the federal open ma...   -0.739048   \n",
       "3    253  at today's meeting the governing council of th...    0.192724   \n",
       "4    324  at today's meeting the governing council of th...   -0.428457   \n",
       "\n",
       "      y_std  urate_us_std  inf_us_std  effr_us_std  rate_change  \n",
       "0  1.281827           NaN         NaN          NaN            0  \n",
       "1 -0.893030      1.477048   -0.047189    -0.756328            0  \n",
       "2 -0.737683     -0.499284   -0.946329    -0.678779            0  \n",
       "3  0.194398           NaN         NaN          NaN            0  \n",
       "4 -0.426989           NaN         NaN          NaN            0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M68nu7j92XiP",
    "outputId": "3b3c7adc-e85c-4e17-9614-64b19fb6cbb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(434, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x8rul3Kx5eE6",
    "outputId": "53525de3-754e-4adb-b8a8-f5366b4b608d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260 347\n"
     ]
    }
   ],
   "source": [
    "train_cut=int(.6*df_shuffled.shape[0])\n",
    "val_cut=int(.8*df_shuffled.shape[0])\n",
    "print(train_cut, val_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "188yG1l0iShI",
    "outputId": "68c5925b-2639-4760-9cb8-49fb225b586b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>statement</th>\n",
       "      <th>y_std_curr</th>\n",
       "      <th>y_std</th>\n",
       "      <th>urate_us_std</th>\n",
       "      <th>inf_us_std</th>\n",
       "      <th>effr_us_std</th>\n",
       "      <th>rate_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>280</td>\n",
       "      <td>at today's meeting, the governing council of t...</td>\n",
       "      <td>1.279790</td>\n",
       "      <td>1.281827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78</td>\n",
       "      <td>information received since the federal open ma...</td>\n",
       "      <td>-0.894343</td>\n",
       "      <td>-0.893030</td>\n",
       "      <td>1.477048</td>\n",
       "      <td>-0.047189</td>\n",
       "      <td>-0.756328</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113</td>\n",
       "      <td>information received since the federal open ma...</td>\n",
       "      <td>-0.739048</td>\n",
       "      <td>-0.737683</td>\n",
       "      <td>-0.499284</td>\n",
       "      <td>-0.946329</td>\n",
       "      <td>-0.678779</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>0.192724</td>\n",
       "      <td>0.194398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>324</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>179</td>\n",
       "      <td>at today's meeting (which was held in the form...</td>\n",
       "      <td>1.279790</td>\n",
       "      <td>1.592521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>320</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>294</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>1.435086</td>\n",
       "      <td>1.592521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>285</td>\n",
       "      <td>at today's meeting, the governing council of t...</td>\n",
       "      <td>1.435086</td>\n",
       "      <td>1.437174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>418</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>-1.127286</td>\n",
       "      <td>-1.126050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                          statement  y_std_curr  \\\n",
       "0      280  at today's meeting, the governing council of t...    1.279790   \n",
       "1       78  information received since the federal open ma...   -0.894343   \n",
       "2      113  information received since the federal open ma...   -0.739048   \n",
       "3      253  at today's meeting the governing council of th...    0.192724   \n",
       "4      324  at today's meeting the governing council of th...   -0.428457   \n",
       "..     ...                                                ...         ...   \n",
       "255    179  at today's meeting (which was held in the form...    1.279790   \n",
       "256    320  at today's meeting the governing council of th...   -0.428457   \n",
       "257    294  at today's meeting the governing council of th...    1.435086   \n",
       "258    285  at today's meeting, the governing council of t...    1.435086   \n",
       "259    418  at today's meeting the governing council of th...   -1.127286   \n",
       "\n",
       "        y_std  urate_us_std  inf_us_std  effr_us_std  rate_change  \n",
       "0    1.281827           NaN         NaN          NaN            0  \n",
       "1   -0.893030      1.477048   -0.047189    -0.756328            0  \n",
       "2   -0.737683     -0.499284   -0.946329    -0.678779            0  \n",
       "3    0.194398           NaN         NaN          NaN            0  \n",
       "4   -0.426989           NaN         NaN          NaN            0  \n",
       "..        ...           ...         ...          ...          ...  \n",
       "255  1.592521           NaN         NaN          NaN            1  \n",
       "256 -0.426989           NaN         NaN          NaN            0  \n",
       "257  1.592521           NaN         NaN          NaN            1  \n",
       "258  1.437174           NaN         NaN          NaN            0  \n",
       "259 -1.126050           NaN         NaN          NaN            0  \n",
       "\n",
       "[260 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=df_shuffled.iloc[0:train_cut,:]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "7G_YT2bAtFMe",
    "outputId": "819525e2-218e-4fca-f3a7-4a84eb1eb7d9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>statement</th>\n",
       "      <th>y_std_curr</th>\n",
       "      <th>y_std</th>\n",
       "      <th>urate_us_std</th>\n",
       "      <th>inf_us_std</th>\n",
       "      <th>effr_us_std</th>\n",
       "      <th>rate_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>407</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>-1.096227</td>\n",
       "      <td>-1.094981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>233</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>0.503314</td>\n",
       "      <td>0.194398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>354</td>\n",
       "      <td>at today's meeting, which was held in bratisla...</td>\n",
       "      <td>-0.739048</td>\n",
       "      <td>-0.737683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>164</td>\n",
       "      <td>the federal reserve is committed to using its ...</td>\n",
       "      <td>-0.894343</td>\n",
       "      <td>-0.893030</td>\n",
       "      <td>-1.042775</td>\n",
       "      <td>4.007804</td>\n",
       "      <td>-0.762790</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>136</td>\n",
       "      <td>information received since the federal open ma...</td>\n",
       "      <td>0.348019</td>\n",
       "      <td>0.349745</td>\n",
       "      <td>-1.141592</td>\n",
       "      <td>0.269350</td>\n",
       "      <td>0.600777</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>352</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>-0.583753</td>\n",
       "      <td>-0.582336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>216</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>0.969200</td>\n",
       "      <td>0.971133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>279</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>1.279790</td>\n",
       "      <td>1.281827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>377</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>-1.018579</td>\n",
       "      <td>-1.017308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>337</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                          statement  y_std_curr  \\\n",
       "260    407  at today's meeting the governing council of th...   -1.096227   \n",
       "261    233  at today's meeting the governing council of th...    0.503314   \n",
       "262    354  at today's meeting, which was held in bratisla...   -0.739048   \n",
       "263    164  the federal reserve is committed to using its ...   -0.894343   \n",
       "264    136  information received since the federal open ma...    0.348019   \n",
       "..     ...                                                ...         ...   \n",
       "342    352  at today's meeting the governing council of th...   -0.583753   \n",
       "343    216  at today's meeting the governing council of th...    0.969200   \n",
       "344    279  at today's meeting the governing council of th...    1.279790   \n",
       "345    377  at today's meeting the governing council of th...   -1.018579   \n",
       "346    337  at today's meeting the governing council of th...   -0.428457   \n",
       "\n",
       "        y_std  urate_us_std  inf_us_std  effr_us_std  rate_change  \n",
       "260 -1.094981           NaN         NaN          NaN            0  \n",
       "261  0.194398           NaN         NaN          NaN            1  \n",
       "262 -0.737683           NaN         NaN          NaN            0  \n",
       "263 -0.893030     -1.042775    4.007804    -0.762790            0  \n",
       "264  0.349745     -1.141592    0.269350     0.600777            0  \n",
       "..        ...           ...         ...          ...          ...  \n",
       "342 -0.582336           NaN         NaN          NaN            0  \n",
       "343  0.971133           NaN         NaN          NaN            0  \n",
       "344  1.281827           NaN         NaN          NaN            0  \n",
       "345 -1.017308           NaN         NaN          NaN            0  \n",
       "346 -0.426989           NaN         NaN          NaN            0  \n",
       "\n",
       "[87 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val=df_shuffled.iloc[train_cut:val_cut,:]\n",
    "df_val       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "D_QhAmpdtuhp",
    "outputId": "70bd484b-f749-47e3-eef9-35b73a4c1182"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>statement</th>\n",
       "      <th>y_std_curr</th>\n",
       "      <th>y_std</th>\n",
       "      <th>urate_us_std</th>\n",
       "      <th>inf_us_std</th>\n",
       "      <th>effr_us_std</th>\n",
       "      <th>rate_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>236</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>0.192724</td>\n",
       "      <td>0.194398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>207</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>1.745676</td>\n",
       "      <td>1.747868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>212</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>1.279790</td>\n",
       "      <td>1.281827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>295</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>1.590381</td>\n",
       "      <td>1.592521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>397</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>-1.096227</td>\n",
       "      <td>-1.094981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>71</td>\n",
       "      <td>information received since the federal open ma...</td>\n",
       "      <td>-0.894343</td>\n",
       "      <td>-0.893030</td>\n",
       "      <td>1.724089</td>\n",
       "      <td>-0.732240</td>\n",
       "      <td>-0.711091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>106</td>\n",
       "      <td>information received since the federal open ma...</td>\n",
       "      <td>-0.894343</td>\n",
       "      <td>-0.893030</td>\n",
       "      <td>-0.153426</td>\n",
       "      <td>-0.657313</td>\n",
       "      <td>-0.769253</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>270</td>\n",
       "      <td>at today's meeting, which was held in madrid, ...</td>\n",
       "      <td>0.658609</td>\n",
       "      <td>0.660439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>348</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>-0.583753</td>\n",
       "      <td>-0.582336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>102</td>\n",
       "      <td>information received since the federal open ma...</td>\n",
       "      <td>-0.894343</td>\n",
       "      <td>-0.893030</td>\n",
       "      <td>0.093616</td>\n",
       "      <td>-0.129469</td>\n",
       "      <td>-0.756328</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                          statement  y_std_curr  \\\n",
       "347    236  at today's meeting the governing council of th...    0.192724   \n",
       "348    207  at today's meeting the governing council of th...    1.745676   \n",
       "349    212  at today's meeting the governing council of th...    1.279790   \n",
       "350    295  at today's meeting the governing council of th...    1.590381   \n",
       "351    397  at today's meeting the governing council of th...   -1.096227   \n",
       "..     ...                                                ...         ...   \n",
       "429     71  information received since the federal open ma...   -0.894343   \n",
       "430    106  information received since the federal open ma...   -0.894343   \n",
       "431    270  at today's meeting, which was held in madrid, ...    0.658609   \n",
       "432    348  at today's meeting the governing council of th...   -0.583753   \n",
       "433    102  information received since the federal open ma...   -0.894343   \n",
       "\n",
       "        y_std  urate_us_std  inf_us_std  effr_us_std  rate_change  \n",
       "347  0.194398           NaN         NaN          NaN            0  \n",
       "348  1.747868           NaN         NaN          NaN            0  \n",
       "349  1.281827           NaN         NaN          NaN            0  \n",
       "350  1.592521           NaN         NaN          NaN            0  \n",
       "351 -1.094981           NaN         NaN          NaN            0  \n",
       "..        ...           ...         ...          ...          ...  \n",
       "429 -0.893030      1.724089   -0.732240    -0.711091            0  \n",
       "430 -0.893030     -0.153426   -0.657313    -0.769253            0  \n",
       "431  0.660439           NaN         NaN          NaN            0  \n",
       "432 -0.582336           NaN         NaN          NaN            0  \n",
       "433 -0.893030      0.093616   -0.129469    -0.756328            0  \n",
       "\n",
       "[87 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test=df_shuffled.iloc[val_cut:df_shuffled.shape[0],:]\n",
    "df_test  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtWZGAEhurwC"
   },
   "source": [
    "# Part I.  Model with embeddings derived from our corpus.  \n",
    "\n",
    "In this model, our own corpus is the source of the embedding layer.  By using our own embeddings we may be making training less efficient and generalizable than if we used a pre-trained model.  Given the small size of our data set, however, training is still very fast and because of the highly specialized nature of our corpus, self-created embeddings could be more predictive.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VigM-PBEudv_"
   },
   "source": [
    "The next section of code was demonstrated by Sucky in:\n",
    "https://towardsdatascience.com/a-complete-step-by-step-tutorial-on-sentiment-analysis-in-keras-and-tensorflow-ea420cc8913f. It offers a straightforward way to create embeddings in Keras and incorporate them into a neural network.\n",
    "\n",
    "The first step is to ensure that the data are in the correct format:  the statement should be a string and the target variables, y_std_curr and y_std should be floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6WICo1HGvrSB",
    "outputId": "4df1176d-c34f-41cf-be5c-b2d65a202bed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87 entries, 347 to 433\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   index         87 non-null     int64  \n",
      " 1   statement     87 non-null     object \n",
      " 2   y_std_curr    87 non-null     float64\n",
      " 3   y_std         87 non-null     float64\n",
      " 4   urate_us_std  30 non-null     float64\n",
      " 5   inf_us_std    30 non-null     float64\n",
      " 6   effr_us_std   30 non-null     float64\n",
      " 7   rate_change   87 non-null     int64  \n",
      "dtypes: float64(5), int64(2), object(1)\n",
      "memory usage: 5.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1DrcofC2yKO6",
    "outputId": "40e34167-672b-48e1-e934-c0332b1c4304"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 260 entries, 0 to 259\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   index         260 non-null    int64  \n",
      " 1   statement     260 non-null    object \n",
      " 2   y_std_curr    260 non-null    float64\n",
      " 3   y_std         260 non-null    float64\n",
      " 4   urate_us_std  104 non-null    float64\n",
      " 5   inf_us_std    104 non-null    float64\n",
      " 6   effr_us_std   104 non-null    float64\n",
      " 7   rate_change   260 non-null    int64  \n",
      "dtypes: float64(5), int64(2), object(1)\n",
      "memory usage: 16.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i8GkL-lVx4h6",
    "outputId": "8da8fa95-0cb6-4431-afd1-abdab6f0bcae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87 entries, 260 to 346\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   index         87 non-null     int64  \n",
      " 1   statement     87 non-null     object \n",
      " 2   y_std_curr    87 non-null     float64\n",
      " 3   y_std         87 non-null     float64\n",
      " 4   urate_us_std  35 non-null     float64\n",
      " 5   inf_us_std    35 non-null     float64\n",
      " 6   effr_us_std   35 non-null     float64\n",
      " 7   rate_change   87 non-null     int64  \n",
      "dtypes: float64(5), int64(2), object(1)\n",
      "memory usage: 5.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_val.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_v6l6_9wySCE"
   },
   "source": [
    "# Interest rate level prediction - predicting policy at next meeting\n",
    "\n",
    "In the next section we try to predict the value of the interest rate using various models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "PLYxULkF49_4"
   },
   "outputs": [],
   "source": [
    "train_statement = df_train.statement\n",
    "train_label = df_train.rate_change\n",
    "#train_label=df_train.rate_next\n",
    "\n",
    "test_statement = df_test.statement\n",
    "test_label = df_test.rate_change\n",
    "#test_label = df_test.rate_next\n",
    "\n",
    "val_statement = df_val.statement\n",
    "#val_label = df_val.rate_next\n",
    "val_label = df_val.rate_change\n",
    "\n",
    "training_sentences = []\n",
    "training_labels = []\n",
    "testing_sentences = []\n",
    "testing_labels = []\n",
    "val_sentences = []\n",
    "val_labels = []\n",
    "\n",
    "for row in train_statement:\n",
    "    training_sentences.append(str(row))\n",
    "for row in train_label:\n",
    "    training_labels.append(row)\n",
    "\n",
    "for row in test_statement:\n",
    "    testing_sentences.append(str(row))\n",
    "for row in test_label:\n",
    "    testing_labels.append(row)\n",
    "\n",
    "for row in val_statement:\n",
    "    val_sentences.append(str(row))\n",
    "for row in val_label:\n",
    "    val_labels.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PRq1Ro0Q4C9d",
    "outputId": "967ba85e-8d97-4b05-b06b-0475bc37c2a6"
   },
   "outputs": [],
   "source": [
    "#print(val_sentences[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MqyG6LA0-Rbf",
    "outputId": "b894f67f-be69-4c7f-ba1f-8289d75c90db"
   },
   "outputs": [],
   "source": [
    "#print(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "p3sV3KW7_MRj"
   },
   "outputs": [],
   "source": [
    "#Convert labels from lists to numpy arrays.  We deal with the statements below.\n",
    "training_labels_final = np.array(training_labels)\n",
    "val_labels_final = np.array(val_labels)\n",
    "test_labels_final = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GECt1MoZ5-ek",
    "outputId": "31d27f68-ad63-4eb9-ecf8-825e2d734653"
   },
   "outputs": [],
   "source": [
    "#print(val_labels_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sd7uVBbiWW8j"
   },
   "source": [
    "# Embedding based on the corpus\n",
    "\n",
    "We first examine embeddings based on the corpus.  \n",
    "\n",
    "* The embedding will look at the first 1200 words in each statement. Since the maximum length in our dataset is only about 1,000 words, this is not binding.  However, we choose a larger value to accomodate potentially longer statements in the future.\n",
    "\n",
    "* There is no need to truncate statements in the current file, but to accomodate future data we set the tokenizer to truncate words at the end of each statement.\n",
    "\n",
    "* To ensure the embeddings are all the same length, statements padded with zeros to make them all 1500 in length.\n",
    "\n",
    "* We choose a vocab_size for the corpus\n",
    "\n",
    "* The 'OOV' token represents words that occur with low frequency and are not part of the vocabulary.\n",
    "\n",
    "* An embedding dimension of 16 means that the embedding will be a matrix of 1500 (number of tokens) by 16 (size of the vector for each token).  These vectors can be thought of as the 'features' for each token, and help the model understand the similarity between tokens and statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "1dJsVBZp5wgc"
   },
   "outputs": [],
   "source": [
    "max_length = 1200 #Number of tokens per statement\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "\n",
    "vocab_size = 5000 #choose 5000 words to constitute vocabulary\n",
    "oov_tok = '<OOV>' #indicate out of vocabularly words\n",
    "\n",
    "embedding_dim = 16 #number of features per word in vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXJ2YPOBvh2-"
   },
   "source": [
    "We next tokenize the text and develop the vocabulary, which given by word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "wHFQvZHq4-J0"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lahsZxxJ6jVt",
    "outputId": "b4059bc4-3e10-42aa-81fc-8e083e504d7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 855, 1718, 1155, 329, 247, 179, 182, 828]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the indexes for select words from the word index\n",
    "test_list=['<OOV>','inflationary','war','macroeconomic','euro','debt','current','voting','projections']\n",
    "[word_index[i] for i in test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XTtVODLZ8Y_Z",
    "outputId": "4c7d529d-3fcd-4d1e-82a8-2ba500f31dac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1923"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wK6R12s_-gD5"
   },
   "source": [
    "Assure that the arrays fed into the neural network are all the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "y9PFBhRj6nbQ"
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded = pad_sequences(sequences, maxlen=max_length, truncating=trunc_type)\n",
    "\n",
    "val_sequences = tokenizer.texts_to_sequences(val_sentences)\n",
    "val_padded = pad_sequences(val_sequences, maxlen=max_length)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyORPwqpvBpD"
   },
   "source": [
    "Let's take a look at these sequences arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EK-QzS4buLo8",
    "outputId": "9d2a7aa4-7018-4d8b-cfde-e2e14f373b0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(260, 1200) (87, 1200) (87, 1200)\n"
     ]
    }
   ],
   "source": [
    "print(padded.shape, val_padded.shape, test_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nBUweP3Su-X-",
    "outputId": "12955c5e-2488-4293-9dd9-7c79a7888f95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ..., 134, 829,  77],\n",
       "       [  0,   0,   0, ...,  91, 202, 145],\n",
       "       [  0,   0,   0, ..., 120,  54,  24],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  72, 133, 134],\n",
       "       [  0,   0,   0, ..., 134, 829,  77],\n",
       "       [  0,   0,   0, ...,  72, 217,  77]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzYsgfWyJTYc"
   },
   "source": [
    "# Model A\n",
    "\n",
    "This model was demonstrated by Sucky in a blog post.  The 1D Global Average Pooling layer simply flattens the embedding layer to be a vector.  (We found that the model did much worse without this layer). Each element of the vector is connected to a 6-node dense layer.  The relu was chosen as an activation function due to its ability to mitigate the vanishing gradient problem.  A linear activation was chosen in the final layer because the target is a continuous variable that can take positive or negative values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "lC5t_QqOJSOr"
   },
   "outputs": [],
   "source": [
    "\n",
    "modela = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "qzhigJyKJSZh"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "modela.compile(loss='binary_crossentropy', \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ok5oiBKoJSco",
    "outputId": "61fefbad-020f-40f5-90c5-ef4b730122a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1200, 16)          80000     \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 16)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 102       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,109\n",
      "Trainable params: 80,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modela.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Jr1za8GJSgF",
    "outputId": "8e4aa727-8b23-4308-f579-7a07f755abf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 1s 34ms/step - loss: 0.6933 - precision: 0.2241 - val_loss: 0.6904 - val_precision: 0.0000e+00\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6895 - precision: 0.0000e+00 - val_loss: 0.6876 - val_precision: 0.0000e+00\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6870 - precision: 0.0000e+00 - val_loss: 0.6848 - val_precision: 0.0000e+00\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6845 - precision: 0.0000e+00 - val_loss: 0.6821 - val_precision: 0.0000e+00\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6821 - precision: 0.0000e+00 - val_loss: 0.6796 - val_precision: 0.0000e+00\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6798 - precision: 0.0000e+00 - val_loss: 0.6771 - val_precision: 0.0000e+00\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6774 - precision: 0.0000e+00 - val_loss: 0.6746 - val_precision: 0.0000e+00\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6751 - precision: 0.0000e+00 - val_loss: 0.6722 - val_precision: 0.0000e+00\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6730 - precision: 0.0000e+00 - val_loss: 0.6700 - val_precision: 0.0000e+00\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6709 - precision: 0.0000e+00 - val_loss: 0.6677 - val_precision: 0.0000e+00\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6688 - precision: 0.0000e+00 - val_loss: 0.6652 - val_precision: 0.0000e+00\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6665 - precision: 0.0000e+00 - val_loss: 0.6628 - val_precision: 0.0000e+00\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6642 - precision: 0.0000e+00 - val_loss: 0.6604 - val_precision: 0.0000e+00\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6621 - precision: 0.0000e+00 - val_loss: 0.6581 - val_precision: 0.0000e+00\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6599 - precision: 0.0000e+00 - val_loss: 0.6558 - val_precision: 0.0000e+00\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.6578 - precision: 0.0000e+00 - val_loss: 0.6536 - val_precision: 0.0000e+00\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6558 - precision: 0.0000e+00 - val_loss: 0.6512 - val_precision: 0.0000e+00\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6535 - precision: 0.0000e+00 - val_loss: 0.6488 - val_precision: 0.0000e+00\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6513 - precision: 0.0000e+00 - val_loss: 0.6465 - val_precision: 0.0000e+00\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6493 - precision: 0.0000e+00 - val_loss: 0.6443 - val_precision: 0.0000e+00\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6472 - precision: 0.0000e+00 - val_loss: 0.6421 - val_precision: 0.0000e+00\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6452 - precision: 0.0000e+00 - val_loss: 0.6398 - val_precision: 0.0000e+00\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6431 - precision: 0.0000e+00 - val_loss: 0.6376 - val_precision: 0.0000e+00\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6410 - precision: 0.0000e+00 - val_loss: 0.6354 - val_precision: 0.0000e+00\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6391 - precision: 0.0000e+00 - val_loss: 0.6333 - val_precision: 0.0000e+00\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6374 - precision: 0.0000e+00 - val_loss: 0.6314 - val_precision: 0.0000e+00\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6354 - precision: 0.0000e+00 - val_loss: 0.6294 - val_precision: 0.0000e+00\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6338 - precision: 0.0000e+00 - val_loss: 0.6273 - val_precision: 0.0000e+00\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6318 - precision: 0.0000e+00 - val_loss: 0.6253 - val_precision: 0.0000e+00\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6293 - precision: 0.0000e+00 - val_loss: 0.6178 - val_precision: 0.0000e+00\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6178 - precision: 0.0000e+00 - val_loss: 0.5991 - val_precision: 0.0000e+00\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5997 - precision: 0.0000e+00 - val_loss: 0.5795 - val_precision: 0.0000e+00\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5826 - precision: 0.0000e+00 - val_loss: 0.5596 - val_precision: 0.0000e+00\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5652 - precision: 0.0000e+00 - val_loss: 0.5408 - val_precision: 0.0000e+00\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5498 - precision: 0.0000e+00 - val_loss: 0.5233 - val_precision: 0.0000e+00\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5366 - precision: 0.0000e+00 - val_loss: 0.5113 - val_precision: 0.0000e+00\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5286 - precision: 0.0000e+00 - val_loss: 0.5003 - val_precision: 0.0000e+00\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5189 - precision: 0.0000e+00 - val_loss: 0.4925 - val_precision: 0.0000e+00\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5146 - precision: 0.0000e+00 - val_loss: 0.4866 - val_precision: 0.0000e+00\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5106 - precision: 0.0000e+00 - val_loss: 0.4830 - val_precision: 0.0000e+00\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5089 - precision: 0.0000e+00 - val_loss: 0.4794 - val_precision: 0.0000e+00\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5073 - precision: 0.0000e+00 - val_loss: 0.4775 - val_precision: 0.0000e+00\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5056 - precision: 0.0000e+00 - val_loss: 0.4772 - val_precision: 0.0000e+00\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5049 - precision: 0.0000e+00 - val_loss: 0.4763 - val_precision: 0.0000e+00\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5040 - precision: 0.0000e+00 - val_loss: 0.4754 - val_precision: 0.0000e+00\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5032 - precision: 0.0000e+00 - val_loss: 0.4743 - val_precision: 0.0000e+00\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5024 - precision: 0.0000e+00 - val_loss: 0.4734 - val_precision: 0.0000e+00\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5018 - precision: 0.0000e+00 - val_loss: 0.4728 - val_precision: 0.0000e+00\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5010 - precision: 0.0000e+00 - val_loss: 0.4725 - val_precision: 0.0000e+00\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5004 - precision: 0.0000e+00 - val_loss: 0.4721 - val_precision: 0.0000e+00\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4997 - precision: 0.0000e+00 - val_loss: 0.4714 - val_precision: 0.0000e+00\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4990 - precision: 0.0000e+00 - val_loss: 0.4708 - val_precision: 0.0000e+00\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4985 - precision: 0.0000e+00 - val_loss: 0.4703 - val_precision: 0.0000e+00\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4976 - precision: 0.0000e+00 - val_loss: 0.4705 - val_precision: 0.0000e+00\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4966 - precision: 0.0000e+00 - val_loss: 0.4704 - val_precision: 0.0000e+00\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4962 - precision: 0.0000e+00 - val_loss: 0.4697 - val_precision: 0.0000e+00\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4953 - precision: 0.0000e+00 - val_loss: 0.4695 - val_precision: 0.0000e+00\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4946 - precision: 0.0000e+00 - val_loss: 0.4688 - val_precision: 0.0000e+00\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4938 - precision: 0.0000e+00 - val_loss: 0.4684 - val_precision: 0.0000e+00\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4929 - precision: 0.0000e+00 - val_loss: 0.4683 - val_precision: 0.0000e+00\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4922 - precision: 0.0000e+00 - val_loss: 0.4679 - val_precision: 0.0000e+00\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4916 - precision: 0.0000e+00 - val_loss: 0.4676 - val_precision: 0.0000e+00\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4909 - precision: 0.0000e+00 - val_loss: 0.4668 - val_precision: 0.0000e+00\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4902 - precision: 0.0000e+00 - val_loss: 0.4668 - val_precision: 0.0000e+00\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4893 - precision: 0.0000e+00 - val_loss: 0.4664 - val_precision: 0.0000e+00\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4886 - precision: 0.0000e+00 - val_loss: 0.4661 - val_precision: 0.0000e+00\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4878 - precision: 0.0000e+00 - val_loss: 0.4658 - val_precision: 0.0000e+00\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4870 - precision: 0.0000e+00 - val_loss: 0.4655 - val_precision: 0.0000e+00\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4865 - precision: 0.0000e+00 - val_loss: 0.4645 - val_precision: 0.0000e+00\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4853 - precision: 0.0000e+00 - val_loss: 0.4645 - val_precision: 0.0000e+00\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4844 - precision: 0.0000e+00 - val_loss: 0.4637 - val_precision: 0.0000e+00\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4839 - precision: 0.0000e+00 - val_loss: 0.4638 - val_precision: 0.0000e+00\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4828 - precision: 0.0000e+00 - val_loss: 0.4628 - val_precision: 0.0000e+00\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4820 - precision: 0.0000e+00 - val_loss: 0.4618 - val_precision: 0.0000e+00\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4812 - precision: 0.0000e+00 - val_loss: 0.4607 - val_precision: 0.0000e+00\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4805 - precision: 0.0000e+00 - val_loss: 0.4603 - val_precision: 0.0000e+00\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4797 - precision: 0.0000e+00 - val_loss: 0.4608 - val_precision: 0.0000e+00\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4786 - precision: 0.0000e+00 - val_loss: 0.4602 - val_precision: 0.0000e+00\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4779 - precision: 0.0000e+00 - val_loss: 0.4593 - val_precision: 0.0000e+00\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4770 - precision: 0.0000e+00 - val_loss: 0.4586 - val_precision: 0.0000e+00\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4761 - precision: 0.0000e+00 - val_loss: 0.4581 - val_precision: 0.0000e+00\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4751 - precision: 0.0000e+00 - val_loss: 0.4581 - val_precision: 0.0000e+00\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4743 - precision: 0.0000e+00 - val_loss: 0.4579 - val_precision: 0.0000e+00\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4732 - precision: 0.0000e+00 - val_loss: 0.4578 - val_precision: 0.0000e+00\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4710 - precision: 0.0000e+00 - val_loss: 0.4571 - val_precision: 0.0000e+00\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4667 - precision: 0.0000e+00 - val_loss: 0.4550 - val_precision: 0.0000e+00\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4650 - precision: 0.0000e+00 - val_loss: 0.4561 - val_precision: 0.0000e+00\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4584 - precision: 0.0000e+00 - val_loss: 0.4518 - val_precision: 0.0000e+00\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4535 - precision: 0.0000e+00 - val_loss: 0.4467 - val_precision: 0.0000e+00\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4496 - precision: 0.0000e+00 - val_loss: 0.4486 - val_precision: 0.0000e+00\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4460 - precision: 0.0000e+00 - val_loss: 0.4459 - val_precision: 0.0000e+00\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4416 - precision: 0.0000e+00 - val_loss: 0.4421 - val_precision: 0.0000e+00\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4377 - precision: 0.0000e+00 - val_loss: 0.4393 - val_precision: 0.0000e+00\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4338 - precision: 0.0000e+00 - val_loss: 0.4353 - val_precision: 0.0000e+00\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4289 - precision: 0.0000e+00 - val_loss: 0.4359 - val_precision: 1.0000\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4269 - precision: 1.0000 - val_loss: 0.4357 - val_precision: 1.0000\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4217 - precision: 1.0000 - val_loss: 0.4281 - val_precision: 1.0000\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4169 - precision: 1.0000 - val_loss: 0.4273 - val_precision: 1.0000\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4134 - precision: 1.0000 - val_loss: 0.4251 - val_precision: 1.0000\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4106 - precision: 1.0000 - val_loss: 0.4221 - val_precision: 1.0000\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4065 - precision: 1.0000 - val_loss: 0.4200 - val_precision: 1.0000\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4033 - precision: 1.0000 - val_loss: 0.4201 - val_precision: 1.0000\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4005 - precision: 1.0000 - val_loss: 0.4171 - val_precision: 1.0000\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3967 - precision: 1.0000 - val_loss: 0.4147 - val_precision: 1.0000\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3933 - precision: 1.0000 - val_loss: 0.4129 - val_precision: 1.0000\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3898 - precision: 1.0000 - val_loss: 0.4131 - val_precision: 1.0000\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3879 - precision: 0.8824 - val_loss: 0.4167 - val_precision: 1.0000\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3836 - precision: 0.9333 - val_loss: 0.4071 - val_precision: 1.0000\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3841 - precision: 1.0000 - val_loss: 0.4058 - val_precision: 1.0000\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3798 - precision: 0.9333 - val_loss: 0.4074 - val_precision: 1.0000\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3781 - precision: 0.8947 - val_loss: 0.4148 - val_precision: 0.6667\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3741 - precision: 0.8947 - val_loss: 0.4051 - val_precision: 1.0000\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3713 - precision: 0.9444 - val_loss: 0.4072 - val_precision: 0.8000\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3701 - precision: 0.9048 - val_loss: 0.4076 - val_precision: 0.8000\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3674 - precision: 0.9048 - val_loss: 0.4039 - val_precision: 0.8000\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3658 - precision: 0.9048 - val_loss: 0.4044 - val_precision: 0.8000\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3629 - precision: 0.8750 - val_loss: 0.4115 - val_precision: 0.6250\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3623 - precision: 0.9091 - val_loss: 0.4039 - val_precision: 0.5714\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3590 - precision: 0.9130 - val_loss: 0.4043 - val_precision: 0.6250\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3575 - precision: 0.8462 - val_loss: 0.4056 - val_precision: 0.6667\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3568 - precision: 0.8519 - val_loss: 0.4074 - val_precision: 0.6667\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3534 - precision: 0.8462 - val_loss: 0.4014 - val_precision: 0.6250\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3530 - precision: 0.8462 - val_loss: 0.4006 - val_precision: 0.6250\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3516 - precision: 0.8462 - val_loss: 0.3999 - val_precision: 0.6250\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3502 - precision: 0.8400 - val_loss: 0.3992 - val_precision: 0.6250\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3490 - precision: 0.8462 - val_loss: 0.4007 - val_precision: 0.6667\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3482 - precision: 0.8214 - val_loss: 0.4094 - val_precision: 0.5833\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3485 - precision: 0.8276 - val_loss: 0.4083 - val_precision: 0.5833\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3451 - precision: 0.8519 - val_loss: 0.3983 - val_precision: 0.6667\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3434 - precision: 0.8519 - val_loss: 0.3988 - val_precision: 0.6667\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3421 - precision: 0.8519 - val_loss: 0.3980 - val_precision: 0.6667\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3413 - precision: 0.8462 - val_loss: 0.3955 - val_precision: 0.6250\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3402 - precision: 0.8519 - val_loss: 0.3994 - val_precision: 0.6667\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3384 - precision: 0.8571 - val_loss: 0.4004 - val_precision: 0.6667\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3393 - precision: 0.8571 - val_loss: 0.3954 - val_precision: 0.6667\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3368 - precision: 0.8519 - val_loss: 0.3996 - val_precision: 0.6667\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3362 - precision: 0.8519 - val_loss: 0.3997 - val_precision: 0.6667\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3357 - precision: 0.8276 - val_loss: 0.4043 - val_precision: 0.5833\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3337 - precision: 0.8214 - val_loss: 0.3966 - val_precision: 0.6667\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3333 - precision: 0.8519 - val_loss: 0.3966 - val_precision: 0.6667\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3329 - precision: 0.8571 - val_loss: 0.4062 - val_precision: 0.5833\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3317 - precision: 0.8333 - val_loss: 0.3986 - val_precision: 0.7000\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3305 - precision: 0.8276 - val_loss: 0.4007 - val_precision: 0.5833\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3290 - precision: 0.8276 - val_loss: 0.3996 - val_precision: 0.5833\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3284 - precision: 0.8276 - val_loss: 0.4008 - val_precision: 0.5833\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3286 - precision: 0.8276 - val_loss: 0.3949 - val_precision: 0.6667\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3274 - precision: 0.8571 - val_loss: 0.3993 - val_precision: 0.5833\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3267 - precision: 0.8276 - val_loss: 0.4036 - val_precision: 0.5833\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3257 - precision: 0.8276 - val_loss: 0.3987 - val_precision: 0.5833\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3244 - precision: 0.8276 - val_loss: 0.3978 - val_precision: 0.5833\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3228 - precision: 0.8333 - val_loss: 0.4045 - val_precision: 0.5833\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3235 - precision: 0.8387 - val_loss: 0.3995 - val_precision: 0.5833\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3218 - precision: 0.8333 - val_loss: 0.4006 - val_precision: 0.5833\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3221 - precision: 0.8276 - val_loss: 0.3977 - val_precision: 0.5833\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3202 - precision: 0.8333 - val_loss: 0.4127 - val_precision: 0.5833\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3222 - precision: 0.8387 - val_loss: 0.4047 - val_precision: 0.5833\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3201 - precision: 0.8333 - val_loss: 0.3982 - val_precision: 0.5833\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3179 - precision: 0.8333 - val_loss: 0.4038 - val_precision: 0.5833\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3192 - precision: 0.8387 - val_loss: 0.4046 - val_precision: 0.5833\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3162 - precision: 0.8621 - val_loss: 0.3957 - val_precision: 0.7000\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3210 - precision: 0.8519 - val_loss: 0.3957 - val_precision: 0.7000\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3148 - precision: 0.8214 - val_loss: 0.4023 - val_precision: 0.5833\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3143 - precision: 0.8333 - val_loss: 0.4000 - val_precision: 0.5833\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3134 - precision: 0.8387 - val_loss: 0.4013 - val_precision: 0.5833\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3132 - precision: 0.8333 - val_loss: 0.3984 - val_precision: 0.5833\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3135 - precision: 0.8276 - val_loss: 0.3980 - val_precision: 0.5833\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3122 - precision: 0.8276 - val_loss: 0.3975 - val_precision: 0.5833\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3126 - precision: 0.8519 - val_loss: 0.3960 - val_precision: 0.6364\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3114 - precision: 0.8519 - val_loss: 0.3962 - val_precision: 0.6364\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3108 - precision: 0.8519 - val_loss: 0.3960 - val_precision: 0.6364\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3106 - precision: 0.8276 - val_loss: 0.3988 - val_precision: 0.5833\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3090 - precision: 0.8571 - val_loss: 0.3976 - val_precision: 0.5833\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3100 - precision: 0.8387 - val_loss: 0.4054 - val_precision: 0.5833\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3094 - precision: 0.8387 - val_loss: 0.3988 - val_precision: 0.5833\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3074 - precision: 0.8387 - val_loss: 0.4038 - val_precision: 0.5833\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3072 - precision: 0.8387 - val_loss: 0.4007 - val_precision: 0.5833\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3058 - precision: 0.8387 - val_loss: 0.4051 - val_precision: 0.5833\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3053 - precision: 0.8387 - val_loss: 0.3996 - val_precision: 0.5833\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3043 - precision: 0.8333 - val_loss: 0.3984 - val_precision: 0.5833\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3064 - precision: 0.8387 - val_loss: 0.4057 - val_precision: 0.5833\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3031 - precision: 0.8387 - val_loss: 0.3991 - val_precision: 0.5833\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3046 - precision: 0.8571 - val_loss: 0.3953 - val_precision: 0.6364\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3034 - precision: 0.8519 - val_loss: 0.3971 - val_precision: 0.5833\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3026 - precision: 0.8333 - val_loss: 0.4026 - val_precision: 0.5833\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3013 - precision: 0.8438 - val_loss: 0.4083 - val_precision: 0.5833\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3023 - precision: 0.8438 - val_loss: 0.4001 - val_precision: 0.5833\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2997 - precision: 0.8438 - val_loss: 0.4000 - val_precision: 0.5833\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2993 - precision: 0.8667 - val_loss: 0.3996 - val_precision: 0.5833\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2988 - precision: 0.8438 - val_loss: 0.4036 - val_precision: 0.5833\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2981 - precision: 0.8387 - val_loss: 0.4005 - val_precision: 0.5833\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2991 - precision: 0.8485 - val_loss: 0.4111 - val_precision: 0.5833\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2986 - precision: 0.8485 - val_loss: 0.4085 - val_precision: 0.5833\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2962 - precision: 0.8485 - val_loss: 0.4036 - val_precision: 0.5833\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2951 - precision: 0.8485 - val_loss: 0.4020 - val_precision: 0.5833\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2961 - precision: 0.8438 - val_loss: 0.4035 - val_precision: 0.5833\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2937 - precision: 0.8485 - val_loss: 0.4116 - val_precision: 0.5833\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2984 - precision: 0.8485 - val_loss: 0.4217 - val_precision: 0.5833\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2925 - precision: 0.8485 - val_loss: 0.4032 - val_precision: 0.5833\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2942 - precision: 0.8889 - val_loss: 0.3968 - val_precision: 0.6250\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2991 - precision: 0.9231 - val_loss: 0.3968 - val_precision: 0.6667\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2935 - precision: 0.8276 - val_loss: 0.4135 - val_precision: 0.5833\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2940 - precision: 0.8485 - val_loss: 0.4155 - val_precision: 0.5833\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2910 - precision: 0.8485 - val_loss: 0.4026 - val_precision: 0.5833\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2897 - precision: 0.8667 - val_loss: 0.4072 - val_precision: 0.5833\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2886 - precision: 0.8485 - val_loss: 0.4092 - val_precision: 0.5833\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2881 - precision: 0.8485 - val_loss: 0.4035 - val_precision: 0.5833\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2901 - precision: 0.8667 - val_loss: 0.4001 - val_precision: 0.6364\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2880 - precision: 0.8667 - val_loss: 0.4052 - val_precision: 0.5833\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2914 - precision: 0.8485 - val_loss: 0.4254 - val_precision: 0.5833\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2894 - precision: 0.8485 - val_loss: 0.4063 - val_precision: 0.5833\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2863 - precision: 0.8438 - val_loss: 0.4021 - val_precision: 0.5833\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2859 - precision: 0.8667 - val_loss: 0.4042 - val_precision: 0.5833\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2847 - precision: 0.8485 - val_loss: 0.4198 - val_precision: 0.5833\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2863 - precision: 0.8485 - val_loss: 0.4187 - val_precision: 0.5833\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2843 - precision: 0.8485 - val_loss: 0.4055 - val_precision: 0.5833\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2886 - precision: 0.8966 - val_loss: 0.4015 - val_precision: 0.7000\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2871 - precision: 0.8621 - val_loss: 0.4105 - val_precision: 0.5833\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2819 - precision: 0.8485 - val_loss: 0.4113 - val_precision: 0.5833\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2812 - precision: 0.8485 - val_loss: 0.4083 - val_precision: 0.5833\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2807 - precision: 0.8750 - val_loss: 0.4048 - val_precision: 0.5833\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2813 - precision: 0.8750 - val_loss: 0.4077 - val_precision: 0.5833\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2796 - precision: 0.9000 - val_loss: 0.4025 - val_precision: 0.6364\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2823 - precision: 0.8929 - val_loss: 0.4010 - val_precision: 0.6364\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2834 - precision: 0.8966 - val_loss: 0.4062 - val_precision: 0.5833\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2777 - precision: 0.9032 - val_loss: 0.4080 - val_precision: 0.5833\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2783 - precision: 0.8966 - val_loss: 0.4028 - val_precision: 0.6364\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2777 - precision: 0.8929 - val_loss: 0.4029 - val_precision: 0.6364\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2783 - precision: 0.8966 - val_loss: 0.4083 - val_precision: 0.5833\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2759 - precision: 0.8750 - val_loss: 0.4130 - val_precision: 0.5833\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2758 - precision: 0.8750 - val_loss: 0.4071 - val_precision: 0.5833\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2749 - precision: 0.9000 - val_loss: 0.4067 - val_precision: 0.5833\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2745 - precision: 0.9032 - val_loss: 0.4061 - val_precision: 0.5833\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2741 - precision: 0.9032 - val_loss: 0.4098 - val_precision: 0.5833\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2739 - precision: 0.9000 - val_loss: 0.4064 - val_precision: 0.5833\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2733 - precision: 0.9032 - val_loss: 0.4143 - val_precision: 0.5833\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2730 - precision: 0.8750 - val_loss: 0.4125 - val_precision: 0.5833\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2716 - precision: 0.9032 - val_loss: 0.4059 - val_precision: 0.5833\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2726 - precision: 0.9000 - val_loss: 0.4069 - val_precision: 0.5833\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2723 - precision: 0.8966 - val_loss: 0.4041 - val_precision: 0.6364\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2739 - precision: 0.8966 - val_loss: 0.4062 - val_precision: 0.6364\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2688 - precision: 0.9062 - val_loss: 0.4302 - val_precision: 0.5833\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2778 - precision: 0.8571 - val_loss: 0.4351 - val_precision: 0.5833\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2743 - precision: 0.8824 - val_loss: 0.4163 - val_precision: 0.5833\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2678 - precision: 0.8710 - val_loss: 0.4067 - val_precision: 0.6364\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2722 - precision: 0.8966 - val_loss: 0.4060 - val_precision: 0.6364\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2692 - precision: 0.8966 - val_loss: 0.4151 - val_precision: 0.5833\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2673 - precision: 0.8750 - val_loss: 0.4133 - val_precision: 0.5833\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2701 - precision: 0.8966 - val_loss: 0.4058 - val_precision: 0.6364\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2708 - precision: 0.8966 - val_loss: 0.4086 - val_precision: 0.5833\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2666 - precision: 0.8966 - val_loss: 0.4100 - val_precision: 0.5833\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2657 - precision: 0.9000 - val_loss: 0.4103 - val_precision: 0.5833\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2655 - precision: 0.9000 - val_loss: 0.4130 - val_precision: 0.5833\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2639 - precision: 0.9032 - val_loss: 0.4197 - val_precision: 0.5833\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2648 - precision: 0.8824 - val_loss: 0.4255 - val_precision: 0.5833\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2645 - precision: 0.8788 - val_loss: 0.4186 - val_precision: 0.5833\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2632 - precision: 0.8750 - val_loss: 0.4195 - val_precision: 0.5833\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2701 - precision: 0.9000 - val_loss: 0.4099 - val_precision: 0.6364\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2617 - precision: 0.9310 - val_loss: 0.4175 - val_precision: 0.5833\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2614 - precision: 0.8788 - val_loss: 0.4244 - val_precision: 0.5833\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2650 - precision: 0.8857 - val_loss: 0.4336 - val_precision: 0.5833\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2610 - precision: 0.8824 - val_loss: 0.4152 - val_precision: 0.5833\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2602 - precision: 0.9032 - val_loss: 0.4181 - val_precision: 0.5833\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2620 - precision: 0.9062 - val_loss: 0.4137 - val_precision: 0.5833\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2600 - precision: 0.9310 - val_loss: 0.4143 - val_precision: 0.5833\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2592 - precision: 0.9355 - val_loss: 0.4164 - val_precision: 0.5833\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2587 - precision: 0.9333 - val_loss: 0.4142 - val_precision: 0.5833\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2599 - precision: 0.9310 - val_loss: 0.4133 - val_precision: 0.5833\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2560 - precision: 0.9062 - val_loss: 0.4242 - val_precision: 0.5833\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2576 - precision: 0.8857 - val_loss: 0.4240 - val_precision: 0.5833\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2576 - precision: 0.9355 - val_loss: 0.4145 - val_precision: 0.5833\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2568 - precision: 0.9333 - val_loss: 0.4165 - val_precision: 0.5833\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2549 - precision: 0.8788 - val_loss: 0.4225 - val_precision: 0.5833\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2554 - precision: 0.9355 - val_loss: 0.4191 - val_precision: 0.5833\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2557 - precision: 0.9333 - val_loss: 0.4176 - val_precision: 0.5833\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2583 - precision: 0.8857 - val_loss: 0.4297 - val_precision: 0.5833\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2550 - precision: 0.9062 - val_loss: 0.4188 - val_precision: 0.5833\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2537 - precision: 0.9333 - val_loss: 0.4170 - val_precision: 0.5833\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2567 - precision: 0.9333 - val_loss: 0.4224 - val_precision: 0.5833\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2529 - precision: 0.9355 - val_loss: 0.4220 - val_precision: 0.5833\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2550 - precision: 0.8824 - val_loss: 0.4308 - val_precision: 0.5833\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2509 - precision: 0.8824 - val_loss: 0.4183 - val_precision: 0.5833\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2537 - precision: 0.9310 - val_loss: 0.4153 - val_precision: 0.6364\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2539 - precision: 0.9333 - val_loss: 0.4205 - val_precision: 0.5833\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2519 - precision: 0.9333 - val_loss: 0.4189 - val_precision: 0.5833\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2507 - precision: 0.9355 - val_loss: 0.4257 - val_precision: 0.5833\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2500 - precision: 0.9394 - val_loss: 0.4246 - val_precision: 0.5833\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2491 - precision: 0.9355 - val_loss: 0.4213 - val_precision: 0.5833\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2491 - precision: 0.9333 - val_loss: 0.4198 - val_precision: 0.5833\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2486 - precision: 0.9333 - val_loss: 0.4223 - val_precision: 0.5833\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2479 - precision: 0.9355 - val_loss: 0.4243 - val_precision: 0.5833\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2475 - precision: 0.9355 - val_loss: 0.4274 - val_precision: 0.5833\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2520 - precision: 0.8857 - val_loss: 0.4433 - val_precision: 0.5833\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2517 - precision: 0.8857 - val_loss: 0.4267 - val_precision: 0.5833\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2464 - precision: 0.9375 - val_loss: 0.4284 - val_precision: 0.5833\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2482 - precision: 0.9118 - val_loss: 0.4412 - val_precision: 0.5833\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2463 - precision: 0.9394 - val_loss: 0.4254 - val_precision: 0.5833\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2475 - precision: 0.9310 - val_loss: 0.4173 - val_precision: 0.6000\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2462 - precision: 0.9333 - val_loss: 0.4231 - val_precision: 0.5833\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2449 - precision: 0.9394 - val_loss: 0.4303 - val_precision: 0.5833\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2438 - precision: 0.9394 - val_loss: 0.4290 - val_precision: 0.5833\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300 #chosen after trial and error\n",
    "history = modela.fit(padded, training_labels_final, \n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(val_padded, val_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "joSWFGt0JSki",
    "outputId": "014c7dba-b00c-4ec3-dfce-5620f2b7c7ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "precision = history.history['precision']\n",
    "val_precision = history.history['val_precision']\n",
    "epochs=range(len(precision))\n",
    "plt.plot(epochs, precision, 'r')\n",
    "plt.plot(epochs, val_precision, 'b')\n",
    "plt.title('Training and validation Precision')\n",
    "plt.ylim((0,1.5))\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k724fI6sK9bi",
    "outputId": "9cc6d7c2-2606-4727-f042-c3c35c788fbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4887 - precision: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.48865702748298645, 0.6666666865348816]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modela.evaluate(test_padded, test_labels_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4PO_JgTJHOT"
   },
   "source": [
    "\n",
    "# Model B experiment with a 1-D convolution layer.  \n",
    "\n",
    "The length of the convolutional window is 3, meaning that the convolutional filter will examine small chunks of 3 elements in the vectorized texts. We specify 16 filters, each filter can identify different features of the text. We chose these hyperparams by trial and error. \n",
    "\n",
    "Overall, the performance of the 1D Convolutional layer is very sensitive to the number of filters and kernels.  The RMSE for Model B is .53 compared to .33 for Model A after 300 epochs (not shown).  Increasing training time to 500 epochs resulted in an RMSE of .51 in the test set, although validation performance improved a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "B3O-MaSi6t42"
   },
   "outputs": [],
   "source": [
    "#This model has a convolutional layer\n",
    "modelb = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Conv1D(16, 3, activation=\"relu\"),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "E7HiYjv668SI"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "modelb.compile(loss='binary_crossentropy', \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2PvHtIjm68Vf",
    "outputId": "1147583e-967e-4eff-bb11-b06262e04272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1200, 16)          80000     \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 1198, 16)          784       \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 16)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 102       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,893\n",
      "Trainable params: 80,893\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AubDKBKQ-QP0",
    "outputId": "5429a036-9748-47d4-8feb-98313d746af1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "9/9 [==============================] - 1s 32ms/step - loss: 0.6860 - precision: 0.0000e+00 - val_loss: 0.6765 - val_precision: 0.0000e+00\n",
      "Epoch 2/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6723 - precision: 0.0000e+00 - val_loss: 0.6608 - val_precision: 0.0000e+00\n",
      "Epoch 3/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6573 - precision: 0.0000e+00 - val_loss: 0.6421 - val_precision: 0.0000e+00\n",
      "Epoch 4/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6399 - precision: 0.0000e+00 - val_loss: 0.6198 - val_precision: 0.0000e+00\n",
      "Epoch 5/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6197 - precision: 0.0000e+00 - val_loss: 0.5958 - val_precision: 0.0000e+00\n",
      "Epoch 6/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5969 - precision: 0.0000e+00 - val_loss: 0.5680 - val_precision: 0.0000e+00\n",
      "Epoch 7/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5704 - precision: 0.0000e+00 - val_loss: 0.5387 - val_precision: 0.0000e+00\n",
      "Epoch 8/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5448 - precision: 0.0000e+00 - val_loss: 0.5131 - val_precision: 0.0000e+00\n",
      "Epoch 9/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5289 - precision: 0.0000e+00 - val_loss: 0.5003 - val_precision: 0.0000e+00\n",
      "Epoch 10/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5198 - precision: 0.0000e+00 - val_loss: 0.4901 - val_precision: 0.0000e+00\n",
      "Epoch 11/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5135 - precision: 0.0000e+00 - val_loss: 0.4805 - val_precision: 0.0000e+00\n",
      "Epoch 12/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5080 - precision: 0.0000e+00 - val_loss: 0.4768 - val_precision: 0.0000e+00\n",
      "Epoch 13/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5058 - precision: 0.0000e+00 - val_loss: 0.4755 - val_precision: 0.0000e+00\n",
      "Epoch 14/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5048 - precision: 0.0000e+00 - val_loss: 0.4746 - val_precision: 0.0000e+00\n",
      "Epoch 15/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5036 - precision: 0.0000e+00 - val_loss: 0.4740 - val_precision: 0.0000e+00\n",
      "Epoch 16/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5026 - precision: 0.0000e+00 - val_loss: 0.4745 - val_precision: 0.0000e+00\n",
      "Epoch 17/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5016 - precision: 0.0000e+00 - val_loss: 0.4723 - val_precision: 0.0000e+00\n",
      "Epoch 18/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5007 - precision: 0.0000e+00 - val_loss: 0.4706 - val_precision: 0.0000e+00\n",
      "Epoch 19/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4996 - precision: 0.0000e+00 - val_loss: 0.4704 - val_precision: 0.0000e+00\n",
      "Epoch 20/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4982 - precision: 0.0000e+00 - val_loss: 0.4700 - val_precision: 0.0000e+00\n",
      "Epoch 21/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4974 - precision: 0.0000e+00 - val_loss: 0.4699 - val_precision: 0.0000e+00\n",
      "Epoch 22/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4962 - precision: 0.0000e+00 - val_loss: 0.4684 - val_precision: 0.0000e+00\n",
      "Epoch 23/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4952 - precision: 0.0000e+00 - val_loss: 0.4672 - val_precision: 0.0000e+00\n",
      "Epoch 24/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4940 - precision: 0.0000e+00 - val_loss: 0.4668 - val_precision: 0.0000e+00\n",
      "Epoch 25/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4924 - precision: 0.0000e+00 - val_loss: 0.4666 - val_precision: 0.0000e+00\n",
      "Epoch 26/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4909 - precision: 0.0000e+00 - val_loss: 0.4678 - val_precision: 0.0000e+00\n",
      "Epoch 27/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.4905 - precision: 0.0000e+00 - val_loss: 0.4680 - val_precision: 0.0000e+00\n",
      "Epoch 28/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4905 - precision: 0.0000e+00 - val_loss: 0.4658 - val_precision: 0.0000e+00\n",
      "Epoch 29/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4881 - precision: 0.0000e+00 - val_loss: 0.4640 - val_precision: 0.0000e+00\n",
      "Epoch 30/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4862 - precision: 0.0000e+00 - val_loss: 0.4644 - val_precision: 0.0000e+00\n",
      "Epoch 31/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4851 - precision: 0.0000e+00 - val_loss: 0.4626 - val_precision: 0.0000e+00\n",
      "Epoch 32/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4838 - precision: 0.0000e+00 - val_loss: 0.4623 - val_precision: 0.0000e+00\n",
      "Epoch 33/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4820 - precision: 0.0000e+00 - val_loss: 0.4616 - val_precision: 0.0000e+00\n",
      "Epoch 34/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4807 - precision: 0.0000e+00 - val_loss: 0.4607 - val_precision: 0.0000e+00\n",
      "Epoch 35/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4783 - precision: 0.0000e+00 - val_loss: 0.4582 - val_precision: 0.0000e+00\n",
      "Epoch 36/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4774 - precision: 0.0000e+00 - val_loss: 0.4585 - val_precision: 0.0000e+00\n",
      "Epoch 37/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4748 - precision: 0.0000e+00 - val_loss: 0.4569 - val_precision: 0.0000e+00\n",
      "Epoch 38/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4729 - precision: 0.0000e+00 - val_loss: 0.4556 - val_precision: 0.0000e+00\n",
      "Epoch 39/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4707 - precision: 0.0000e+00 - val_loss: 0.4536 - val_precision: 0.0000e+00\n",
      "Epoch 40/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.4689 - precision: 0.0000e+00 - val_loss: 0.4526 - val_precision: 0.0000e+00\n",
      "Epoch 41/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4670 - precision: 0.0000e+00 - val_loss: 0.4498 - val_precision: 0.0000e+00\n",
      "Epoch 42/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4649 - precision: 0.0000e+00 - val_loss: 0.4490 - val_precision: 0.0000e+00\n",
      "Epoch 43/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4614 - precision: 0.0000e+00 - val_loss: 0.4515 - val_precision: 0.0000e+00\n",
      "Epoch 44/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4602 - precision: 0.0000e+00 - val_loss: 0.4498 - val_precision: 0.0000e+00\n",
      "Epoch 45/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4569 - precision: 0.0000e+00 - val_loss: 0.4465 - val_precision: 0.0000e+00\n",
      "Epoch 46/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4539 - precision: 0.0000e+00 - val_loss: 0.4423 - val_precision: 0.0000e+00\n",
      "Epoch 47/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.4519 - precision: 0.0000e+00 - val_loss: 0.4398 - val_precision: 0.0000e+00\n",
      "Epoch 48/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4490 - precision: 0.0000e+00 - val_loss: 0.4385 - val_precision: 0.0000e+00\n",
      "Epoch 49/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4447 - precision: 0.0000e+00 - val_loss: 0.4377 - val_precision: 0.0000e+00\n",
      "Epoch 50/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4409 - precision: 0.0000e+00 - val_loss: 0.4366 - val_precision: 0.0000e+00\n",
      "Epoch 51/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4375 - precision: 0.0000e+00 - val_loss: 0.4329 - val_precision: 0.0000e+00\n",
      "Epoch 52/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4336 - precision: 0.0000e+00 - val_loss: 0.4303 - val_precision: 0.0000e+00\n",
      "Epoch 53/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4304 - precision: 0.0000e+00 - val_loss: 0.4281 - val_precision: 0.0000e+00\n",
      "Epoch 54/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4256 - precision: 0.0000e+00 - val_loss: 0.4329 - val_precision: 0.0000e+00\n",
      "Epoch 55/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4232 - precision: 0.0000e+00 - val_loss: 0.4310 - val_precision: 0.0000e+00\n",
      "Epoch 56/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4202 - precision: 0.0000e+00 - val_loss: 0.4221 - val_precision: 0.0000e+00\n",
      "Epoch 57/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4148 - precision: 0.0000e+00 - val_loss: 0.4203 - val_precision: 0.0000e+00\n",
      "Epoch 58/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4122 - precision: 0.0000e+00 - val_loss: 0.4172 - val_precision: 0.0000e+00\n",
      "Epoch 59/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4085 - precision: 0.0000e+00 - val_loss: 0.4166 - val_precision: 0.0000e+00\n",
      "Epoch 60/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4054 - precision: 0.0000e+00 - val_loss: 0.4201 - val_precision: 0.0000e+00\n",
      "Epoch 61/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4033 - precision: 0.0000e+00 - val_loss: 0.4163 - val_precision: 0.0000e+00\n",
      "Epoch 62/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.4004 - precision: 0.0000e+00 - val_loss: 0.4138 - val_precision: 0.0000e+00\n",
      "Epoch 63/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3989 - precision: 0.0000e+00 - val_loss: 0.4102 - val_precision: 0.0000e+00\n",
      "Epoch 64/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3975 - precision: 0.0000e+00 - val_loss: 0.4129 - val_precision: 0.0000e+00\n",
      "Epoch 65/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3944 - precision: 0.0000e+00 - val_loss: 0.4103 - val_precision: 0.0000e+00\n",
      "Epoch 66/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3924 - precision: 0.0000e+00 - val_loss: 0.4103 - val_precision: 0.0000e+00\n",
      "Epoch 67/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3909 - precision: 0.0000e+00 - val_loss: 0.4120 - val_precision: 0.0000e+00\n",
      "Epoch 68/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3890 - precision: 0.0000e+00 - val_loss: 0.4109 - val_precision: 0.0000e+00\n",
      "Epoch 69/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3890 - precision: 0.0000e+00 - val_loss: 0.4073 - val_precision: 0.0000e+00\n",
      "Epoch 70/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3859 - precision: 0.0000e+00 - val_loss: 0.4116 - val_precision: 1.0000\n",
      "Epoch 71/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3822 - precision: 1.0000 - val_loss: 0.4066 - val_precision: 1.0000\n",
      "Epoch 72/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3810 - precision: 1.0000 - val_loss: 0.4081 - val_precision: 1.0000\n",
      "Epoch 73/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3775 - precision: 1.0000 - val_loss: 0.4046 - val_precision: 1.0000\n",
      "Epoch 74/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3757 - precision: 1.0000 - val_loss: 0.4032 - val_precision: 1.0000\n",
      "Epoch 75/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3742 - precision: 1.0000 - val_loss: 0.4025 - val_precision: 1.0000\n",
      "Epoch 76/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3709 - precision: 1.0000 - val_loss: 0.4045 - val_precision: 0.6667\n",
      "Epoch 77/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3697 - precision: 0.8750 - val_loss: 0.4131 - val_precision: 0.7500\n",
      "Epoch 78/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3672 - precision: 0.8750 - val_loss: 0.4052 - val_precision: 0.7143\n",
      "Epoch 79/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3650 - precision: 1.0000 - val_loss: 0.3990 - val_precision: 1.0000\n",
      "Epoch 80/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3622 - precision: 1.0000 - val_loss: 0.3996 - val_precision: 0.8000\n",
      "Epoch 81/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3596 - precision: 0.9545 - val_loss: 0.4021 - val_precision: 0.7143\n",
      "Epoch 82/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3570 - precision: 0.8800 - val_loss: 0.4053 - val_precision: 0.6667\n",
      "Epoch 83/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3557 - precision: 0.8800 - val_loss: 0.4017 - val_precision: 0.7143\n",
      "Epoch 84/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3539 - precision: 0.8800 - val_loss: 0.4077 - val_precision: 0.6364\n",
      "Epoch 85/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3548 - precision: 0.8276 - val_loss: 0.4095 - val_precision: 0.6364\n",
      "Epoch 86/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3515 - precision: 0.8462 - val_loss: 0.4020 - val_precision: 0.6250\n",
      "Epoch 87/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3481 - precision: 0.8800 - val_loss: 0.4014 - val_precision: 0.6667\n",
      "Epoch 88/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3462 - precision: 0.8462 - val_loss: 0.4034 - val_precision: 0.6364\n",
      "Epoch 89/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3441 - precision: 0.9167 - val_loss: 0.3970 - val_precision: 0.6250\n",
      "Epoch 90/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3416 - precision: 0.8800 - val_loss: 0.4012 - val_precision: 0.6364\n",
      "Epoch 91/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3399 - precision: 0.8519 - val_loss: 0.4008 - val_precision: 0.6364\n",
      "Epoch 92/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3375 - precision: 0.8846 - val_loss: 0.3981 - val_precision: 0.6364\n",
      "Epoch 93/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3346 - precision: 0.8800 - val_loss: 0.3959 - val_precision: 0.6364\n",
      "Epoch 94/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3322 - precision: 0.8800 - val_loss: 0.3958 - val_precision: 0.6364\n",
      "Epoch 95/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3302 - precision: 0.8846 - val_loss: 0.3974 - val_precision: 0.6364\n",
      "Epoch 96/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3281 - precision: 0.8519 - val_loss: 0.3966 - val_precision: 0.6364\n",
      "Epoch 97/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3263 - precision: 0.8276 - val_loss: 0.3968 - val_precision: 0.5833\n",
      "Epoch 98/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3247 - precision: 0.8214 - val_loss: 0.3949 - val_precision: 0.6364\n",
      "Epoch 99/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3225 - precision: 0.8846 - val_loss: 0.3950 - val_precision: 0.6364\n",
      "Epoch 100/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3213 - precision: 0.8929 - val_loss: 0.3963 - val_precision: 0.5833\n",
      "Epoch 101/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3189 - precision: 0.8333 - val_loss: 0.3968 - val_precision: 0.5833\n",
      "Epoch 102/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3176 - precision: 0.8333 - val_loss: 0.3985 - val_precision: 0.5833\n",
      "Epoch 103/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3159 - precision: 0.8333 - val_loss: 0.3968 - val_precision: 0.5833\n",
      "Epoch 104/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3141 - precision: 0.8889 - val_loss: 0.3949 - val_precision: 0.5833\n",
      "Epoch 105/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3134 - precision: 0.8846 - val_loss: 0.3959 - val_precision: 0.5833\n",
      "Epoch 106/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3127 - precision: 0.8846 - val_loss: 0.3970 - val_precision: 0.5833\n",
      "Epoch 107/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3110 - precision: 0.8333 - val_loss: 0.4055 - val_precision: 0.5833\n",
      "Epoch 108/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3087 - precision: 0.8485 - val_loss: 0.3972 - val_precision: 0.5833\n",
      "Epoch 109/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3081 - precision: 0.8621 - val_loss: 0.3948 - val_precision: 0.6364\n",
      "Epoch 110/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3062 - precision: 0.8846 - val_loss: 0.3952 - val_precision: 0.5833\n",
      "Epoch 111/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3040 - precision: 0.8966 - val_loss: 0.3978 - val_precision: 0.5833\n",
      "Epoch 112/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3022 - precision: 0.8667 - val_loss: 0.3977 - val_precision: 0.5833\n",
      "Epoch 113/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3007 - precision: 0.8710 - val_loss: 0.4004 - val_precision: 0.5833\n",
      "Epoch 114/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2989 - precision: 0.8710 - val_loss: 0.3979 - val_precision: 0.5833\n",
      "Epoch 115/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2980 - precision: 0.8667 - val_loss: 0.3968 - val_precision: 0.5833\n",
      "Epoch 116/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2965 - precision: 0.8710 - val_loss: 0.3994 - val_precision: 0.5833\n",
      "Epoch 117/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2949 - precision: 0.8750 - val_loss: 0.4073 - val_precision: 0.5833\n",
      "Epoch 118/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2938 - precision: 0.8750 - val_loss: 0.4062 - val_precision: 0.5833\n",
      "Epoch 119/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2921 - precision: 0.8750 - val_loss: 0.4077 - val_precision: 0.5833\n",
      "Epoch 120/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2916 - precision: 0.8485 - val_loss: 0.4125 - val_precision: 0.5833\n",
      "Epoch 121/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2909 - precision: 0.8235 - val_loss: 0.4126 - val_precision: 0.5833\n",
      "Epoch 122/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2873 - precision: 0.8750 - val_loss: 0.4053 - val_precision: 0.5833\n",
      "Epoch 123/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2869 - precision: 0.8750 - val_loss: 0.4040 - val_precision: 0.5833\n",
      "Epoch 124/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2856 - precision: 0.8750 - val_loss: 0.4047 - val_precision: 0.5833\n",
      "Epoch 125/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2838 - precision: 0.8750 - val_loss: 0.4043 - val_precision: 0.5833\n",
      "Epoch 126/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2838 - precision: 0.8750 - val_loss: 0.4037 - val_precision: 0.5833\n",
      "Epoch 127/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2816 - precision: 0.8750 - val_loss: 0.4105 - val_precision: 0.5833\n",
      "Epoch 128/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2814 - precision: 0.8750 - val_loss: 0.4124 - val_precision: 0.5833\n",
      "Epoch 129/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2789 - precision: 0.8750 - val_loss: 0.4082 - val_precision: 0.5833\n",
      "Epoch 130/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2772 - precision: 0.8750 - val_loss: 0.4091 - val_precision: 0.5833\n",
      "Epoch 131/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2759 - precision: 0.8750 - val_loss: 0.4074 - val_precision: 0.5833\n",
      "Epoch 132/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2754 - precision: 0.8750 - val_loss: 0.4039 - val_precision: 0.5833\n",
      "Epoch 133/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2743 - precision: 0.9032 - val_loss: 0.4076 - val_precision: 0.5833\n",
      "Epoch 134/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2723 - precision: 0.8750 - val_loss: 0.4162 - val_precision: 0.5833\n",
      "Epoch 135/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2717 - precision: 0.8750 - val_loss: 0.4094 - val_precision: 0.5833\n",
      "Epoch 136/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2699 - precision: 0.9032 - val_loss: 0.4115 - val_precision: 0.5833\n",
      "Epoch 137/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2686 - precision: 0.8750 - val_loss: 0.4118 - val_precision: 0.5833\n",
      "Epoch 138/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2683 - precision: 0.8750 - val_loss: 0.4177 - val_precision: 0.5833\n",
      "Epoch 139/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2660 - precision: 0.8750 - val_loss: 0.4128 - val_precision: 0.5833\n",
      "Epoch 140/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2645 - precision: 0.9032 - val_loss: 0.4120 - val_precision: 0.5833\n",
      "Epoch 141/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2637 - precision: 0.9032 - val_loss: 0.4183 - val_precision: 0.5833\n",
      "Epoch 142/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2623 - precision: 0.8750 - val_loss: 0.4162 - val_precision: 0.5833\n",
      "Epoch 143/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2608 - precision: 0.8788 - val_loss: 0.4184 - val_precision: 0.5833\n",
      "Epoch 144/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2594 - precision: 0.8788 - val_loss: 0.4169 - val_precision: 0.5833\n",
      "Epoch 145/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2583 - precision: 0.8788 - val_loss: 0.4190 - val_precision: 0.5833\n",
      "Epoch 146/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2578 - precision: 0.8788 - val_loss: 0.4144 - val_precision: 0.5833\n",
      "Epoch 147/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2562 - precision: 0.9062 - val_loss: 0.4226 - val_precision: 0.5833\n",
      "Epoch 148/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2558 - precision: 0.8824 - val_loss: 0.4264 - val_precision: 0.5833\n",
      "Epoch 149/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2540 - precision: 0.9062 - val_loss: 0.4179 - val_precision: 0.5833\n",
      "Epoch 150/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2521 - precision: 0.9333 - val_loss: 0.4172 - val_precision: 0.5833\n",
      "Epoch 151/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2502 - precision: 0.9062 - val_loss: 0.4220 - val_precision: 0.5833\n",
      "Epoch 152/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2501 - precision: 0.9091 - val_loss: 0.4213 - val_precision: 0.5833\n",
      "Epoch 153/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2483 - precision: 0.9375 - val_loss: 0.4221 - val_precision: 0.5833\n",
      "Epoch 154/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2476 - precision: 0.9355 - val_loss: 0.4213 - val_precision: 0.5833\n",
      "Epoch 155/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2464 - precision: 0.8857 - val_loss: 0.4370 - val_precision: 0.5833\n",
      "Epoch 156/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2471 - precision: 0.8889 - val_loss: 0.4309 - val_precision: 0.5833\n",
      "Epoch 157/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2446 - precision: 0.9118 - val_loss: 0.4244 - val_precision: 0.5833\n",
      "Epoch 158/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2421 - precision: 0.9375 - val_loss: 0.4257 - val_precision: 0.5833\n",
      "Epoch 159/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2421 - precision: 0.9394 - val_loss: 0.4292 - val_precision: 0.5833\n",
      "Epoch 160/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2395 - precision: 0.9412 - val_loss: 0.4257 - val_precision: 0.5833\n",
      "Epoch 161/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2411 - precision: 0.9355 - val_loss: 0.4248 - val_precision: 0.5833\n",
      "Epoch 162/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2371 - precision: 0.9375 - val_loss: 0.4285 - val_precision: 0.5833\n",
      "Epoch 163/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2364 - precision: 0.9394 - val_loss: 0.4289 - val_precision: 0.5833\n",
      "Epoch 164/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2352 - precision: 0.9375 - val_loss: 0.4290 - val_precision: 0.5833\n",
      "Epoch 165/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2346 - precision: 0.9375 - val_loss: 0.4285 - val_precision: 0.5833\n",
      "Epoch 166/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2345 - precision: 0.9375 - val_loss: 0.4287 - val_precision: 0.5833\n",
      "Epoch 167/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2331 - precision: 0.9375 - val_loss: 0.4282 - val_precision: 0.5833\n",
      "Epoch 168/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2328 - precision: 0.9375 - val_loss: 0.4288 - val_precision: 0.5833\n",
      "Epoch 169/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2311 - precision: 0.9375 - val_loss: 0.4308 - val_precision: 0.5833\n",
      "Epoch 170/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2301 - precision: 0.9375 - val_loss: 0.4320 - val_precision: 0.5833\n",
      "Epoch 171/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2294 - precision: 0.9375 - val_loss: 0.4328 - val_precision: 0.5833\n",
      "Epoch 172/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2293 - precision: 0.9375 - val_loss: 0.4301 - val_precision: 0.6364\n",
      "Epoch 173/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2287 - precision: 0.9375 - val_loss: 0.4358 - val_precision: 0.5833\n",
      "Epoch 174/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2266 - precision: 0.9375 - val_loss: 0.4360 - val_precision: 0.5833\n",
      "Epoch 175/500\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2259 - precision: 0.9375 - val_loss: 0.4397 - val_precision: 0.5833\n",
      "Epoch 176/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2247 - precision: 0.9412 - val_loss: 0.4388 - val_precision: 0.5833\n",
      "Epoch 177/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2231 - precision: 0.9394 - val_loss: 0.4400 - val_precision: 0.5833\n",
      "Epoch 178/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2225 - precision: 0.9394 - val_loss: 0.4402 - val_precision: 0.5833\n",
      "Epoch 179/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2215 - precision: 0.9394 - val_loss: 0.4405 - val_precision: 0.5833\n",
      "Epoch 180/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2214 - precision: 0.9394 - val_loss: 0.4426 - val_precision: 0.5833\n",
      "Epoch 181/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2195 - precision: 0.9394 - val_loss: 0.4416 - val_precision: 0.5833\n",
      "Epoch 182/500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2192 - precision: 0.9394 - val_loss: 0.4423 - val_precision: 0.5833\n",
      "Epoch 183/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2182 - precision: 0.9394 - val_loss: 0.4428 - val_precision: 0.5833\n",
      "Epoch 184/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2179 - precision: 0.9412 - val_loss: 0.4460 - val_precision: 0.5833\n",
      "Epoch 185/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2166 - precision: 0.9412 - val_loss: 0.4487 - val_precision: 0.5833\n",
      "Epoch 186/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2162 - precision: 0.9412 - val_loss: 0.4478 - val_precision: 0.5833\n",
      "Epoch 187/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2146 - precision: 0.9412 - val_loss: 0.4473 - val_precision: 0.5833\n",
      "Epoch 188/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2142 - precision: 0.9412 - val_loss: 0.4484 - val_precision: 0.5833\n",
      "Epoch 189/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2135 - precision: 0.9429 - val_loss: 0.4501 - val_precision: 0.5833\n",
      "Epoch 190/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2133 - precision: 0.9697 - val_loss: 0.4474 - val_precision: 0.6000\n",
      "Epoch 191/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2131 - precision: 0.9697 - val_loss: 0.4525 - val_precision: 0.5833\n",
      "Epoch 192/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.2116 - precision: 0.9429 - val_loss: 0.4548 - val_precision: 0.5833\n",
      "Epoch 193/500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2102 - precision: 0.9429 - val_loss: 0.4551 - val_precision: 0.5833\n",
      "Epoch 194/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2093 - precision: 0.9429 - val_loss: 0.4549 - val_precision: 0.5833\n",
      "Epoch 195/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2094 - precision: 0.9429 - val_loss: 0.4559 - val_precision: 0.5833\n",
      "Epoch 196/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2078 - precision: 0.9429 - val_loss: 0.4579 - val_precision: 0.5833\n",
      "Epoch 197/500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2080 - precision: 0.9189 - val_loss: 0.4628 - val_precision: 0.5833\n",
      "Epoch 198/500\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2075 - precision: 0.9189 - val_loss: 0.4599 - val_precision: 0.5833\n",
      "Epoch 199/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2073 - precision: 0.9688 - val_loss: 0.4545 - val_precision: 0.5000\n",
      "Epoch 200/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2107 - precision: 1.0000 - val_loss: 0.4556 - val_precision: 0.5000\n",
      "Epoch 201/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2079 - precision: 1.0000 - val_loss: 0.4601 - val_precision: 0.6000\n",
      "Epoch 202/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2040 - precision: 0.9444 - val_loss: 0.4651 - val_precision: 0.5455\n",
      "Epoch 203/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2035 - precision: 0.9444 - val_loss: 0.4651 - val_precision: 0.5455\n",
      "Epoch 204/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2026 - precision: 0.9444 - val_loss: 0.4677 - val_precision: 0.5833\n",
      "Epoch 205/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2016 - precision: 0.9444 - val_loss: 0.4661 - val_precision: 0.5455\n",
      "Epoch 206/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2015 - precision: 1.0000 - val_loss: 0.4661 - val_precision: 0.5455\n",
      "Epoch 207/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2018 - precision: 1.0000 - val_loss: 0.4666 - val_precision: 0.5455\n",
      "Epoch 208/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2005 - precision: 1.0000 - val_loss: 0.4699 - val_precision: 0.5455\n",
      "Epoch 209/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2032 - precision: 0.9444 - val_loss: 0.4843 - val_precision: 0.5385\n",
      "Epoch 210/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2022 - precision: 0.9189 - val_loss: 0.4742 - val_precision: 0.5833\n",
      "Epoch 211/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1993 - precision: 1.0000 - val_loss: 0.4721 - val_precision: 0.5455\n",
      "Epoch 212/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1984 - precision: 1.0000 - val_loss: 0.4736 - val_precision: 0.5455\n",
      "Epoch 213/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1979 - precision: 0.9459 - val_loss: 0.4853 - val_precision: 0.5833\n",
      "Epoch 214/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1990 - precision: 0.9211 - val_loss: 0.4851 - val_precision: 0.5833\n",
      "Epoch 215/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1981 - precision: 0.9714 - val_loss: 0.4776 - val_precision: 0.5455\n",
      "Epoch 216/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2006 - precision: 1.0000 - val_loss: 0.4748 - val_precision: 0.5556\n",
      "Epoch 217/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1977 - precision: 0.9714 - val_loss: 0.4807 - val_precision: 0.5000\n",
      "Epoch 218/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1947 - precision: 0.9730 - val_loss: 0.4781 - val_precision: 0.5000\n",
      "Epoch 219/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1941 - precision: 0.9714 - val_loss: 0.4776 - val_precision: 0.5000\n",
      "Epoch 220/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1940 - precision: 0.9714 - val_loss: 0.4790 - val_precision: 0.5000\n",
      "Epoch 221/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1941 - precision: 0.9444 - val_loss: 0.4836 - val_precision: 0.5000\n",
      "Epoch 222/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1922 - precision: 0.9714 - val_loss: 0.4814 - val_precision: 0.5000\n",
      "Epoch 223/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1938 - precision: 0.9706 - val_loss: 0.4814 - val_precision: 0.5556\n",
      "Epoch 224/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1953 - precision: 1.0000 - val_loss: 0.4827 - val_precision: 0.5000\n",
      "Epoch 225/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1917 - precision: 0.9714 - val_loss: 0.4828 - val_precision: 0.5000\n",
      "Epoch 226/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1923 - precision: 0.9714 - val_loss: 0.4818 - val_precision: 0.5556\n",
      "Epoch 227/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1913 - precision: 0.9714 - val_loss: 0.4833 - val_precision: 0.5556\n",
      "Epoch 228/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1913 - precision: 0.9714 - val_loss: 0.4876 - val_precision: 0.4545\n",
      "Epoch 229/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1895 - precision: 0.9730 - val_loss: 0.4906 - val_precision: 0.4545\n",
      "Epoch 230/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1892 - precision: 0.9730 - val_loss: 0.4899 - val_precision: 0.5000\n",
      "Epoch 231/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1886 - precision: 0.9714 - val_loss: 0.4910 - val_precision: 0.5000\n",
      "Epoch 232/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1883 - precision: 0.9714 - val_loss: 0.4918 - val_precision: 0.5000\n",
      "Epoch 233/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1878 - precision: 0.9714 - val_loss: 0.4923 - val_precision: 0.5000\n",
      "Epoch 234/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1878 - precision: 0.9714 - val_loss: 0.4933 - val_precision: 0.4545\n",
      "Epoch 235/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1873 - precision: 0.9722 - val_loss: 0.4996 - val_precision: 0.4167\n",
      "Epoch 236/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1872 - precision: 0.9737 - val_loss: 0.5003 - val_precision: 0.4167\n",
      "Epoch 237/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1862 - precision: 0.9730 - val_loss: 0.4977 - val_precision: 0.4545\n",
      "Epoch 238/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1855 - precision: 0.9730 - val_loss: 0.4972 - val_precision: 0.4545\n",
      "Epoch 239/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1861 - precision: 0.9714 - val_loss: 0.4966 - val_precision: 0.5000\n",
      "Epoch 240/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1870 - precision: 0.9714 - val_loss: 0.4981 - val_precision: 0.5000\n",
      "Epoch 241/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1838 - precision: 0.9730 - val_loss: 0.5087 - val_precision: 0.4615\n",
      "Epoch 242/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1868 - precision: 0.9286 - val_loss: 0.5155 - val_precision: 0.5000\n",
      "Epoch 243/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1872 - precision: 0.9268 - val_loss: 0.5114 - val_precision: 0.4167\n",
      "Epoch 244/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1845 - precision: 0.9737 - val_loss: 0.5043 - val_precision: 0.4167\n",
      "Epoch 245/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1840 - precision: 0.9722 - val_loss: 0.5037 - val_precision: 0.5000\n",
      "Epoch 246/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1829 - precision: 0.9722 - val_loss: 0.5072 - val_precision: 0.4545\n",
      "Epoch 247/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1821 - precision: 0.9730 - val_loss: 0.5074 - val_precision: 0.5000\n",
      "Epoch 248/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1843 - precision: 0.9714 - val_loss: 0.5043 - val_precision: 0.5000\n",
      "Epoch 249/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1848 - precision: 0.9730 - val_loss: 0.5074 - val_precision: 0.4167\n",
      "Epoch 250/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1810 - precision: 0.9730 - val_loss: 0.5084 - val_precision: 0.4167\n",
      "Epoch 251/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1808 - precision: 0.9730 - val_loss: 0.5101 - val_precision: 0.4545\n",
      "Epoch 252/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1803 - precision: 0.9730 - val_loss: 0.5114 - val_precision: 0.4167\n",
      "Epoch 253/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.1797 - precision: 0.9730 - val_loss: 0.5143 - val_precision: 0.4167\n",
      "Epoch 254/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1796 - precision: 0.9737 - val_loss: 0.5194 - val_precision: 0.4167\n",
      "Epoch 255/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1794 - precision: 0.9737 - val_loss: 0.5195 - val_precision: 0.4167\n",
      "Epoch 256/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1792 - precision: 0.9737 - val_loss: 0.5209 - val_precision: 0.4167\n",
      "Epoch 257/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1812 - precision: 0.9730 - val_loss: 0.5198 - val_precision: 0.4545\n",
      "Epoch 258/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1782 - precision: 0.9730 - val_loss: 0.5219 - val_precision: 0.4167\n",
      "Epoch 259/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1779 - precision: 0.9744 - val_loss: 0.5252 - val_precision: 0.4167\n",
      "Epoch 260/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1788 - precision: 0.9744 - val_loss: 0.5306 - val_precision: 0.4615\n",
      "Epoch 261/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1774 - precision: 0.9744 - val_loss: 0.5246 - val_precision: 0.4167\n",
      "Epoch 262/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1766 - precision: 0.9737 - val_loss: 0.5247 - val_precision: 0.4167\n",
      "Epoch 263/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1786 - precision: 0.9737 - val_loss: 0.5219 - val_precision: 0.4167\n",
      "Epoch 264/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1764 - precision: 0.9737 - val_loss: 0.5225 - val_precision: 0.4545\n",
      "Epoch 265/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1766 - precision: 0.9730 - val_loss: 0.5255 - val_precision: 0.4545\n",
      "Epoch 266/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1761 - precision: 0.9730 - val_loss: 0.5256 - val_precision: 0.4545\n",
      "Epoch 267/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1766 - precision: 0.9730 - val_loss: 0.5267 - val_precision: 0.4545\n",
      "Epoch 268/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1742 - precision: 0.9737 - val_loss: 0.5337 - val_precision: 0.4167\n",
      "Epoch 269/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1751 - precision: 0.9744 - val_loss: 0.5359 - val_precision: 0.4167\n",
      "Epoch 270/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1751 - precision: 0.9744 - val_loss: 0.5303 - val_precision: 0.4167\n",
      "Epoch 271/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1739 - precision: 0.9737 - val_loss: 0.5309 - val_precision: 0.4167\n",
      "Epoch 272/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1731 - precision: 0.9737 - val_loss: 0.5322 - val_precision: 0.4167\n",
      "Epoch 273/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1728 - precision: 0.9737 - val_loss: 0.5325 - val_precision: 0.4167\n",
      "Epoch 274/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1738 - precision: 0.9737 - val_loss: 0.5322 - val_precision: 0.4167\n",
      "Epoch 275/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1739 - precision: 0.9737 - val_loss: 0.5375 - val_precision: 0.4167\n",
      "Epoch 276/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1724 - precision: 0.9737 - val_loss: 0.5348 - val_precision: 0.4167\n",
      "Epoch 277/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1719 - precision: 0.9737 - val_loss: 0.5349 - val_precision: 0.4167\n",
      "Epoch 278/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1729 - precision: 0.9737 - val_loss: 0.5356 - val_precision: 0.4167\n",
      "Epoch 279/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1711 - precision: 0.9737 - val_loss: 0.5369 - val_precision: 0.4167\n",
      "Epoch 280/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1715 - precision: 0.9737 - val_loss: 0.5441 - val_precision: 0.4167\n",
      "Epoch 281/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1704 - precision: 0.9744 - val_loss: 0.5403 - val_precision: 0.4167\n",
      "Epoch 282/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1711 - precision: 0.9737 - val_loss: 0.5389 - val_precision: 0.4545\n",
      "Epoch 283/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1717 - precision: 0.9737 - val_loss: 0.5427 - val_precision: 0.4167\n",
      "Epoch 284/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1705 - precision: 0.9737 - val_loss: 0.5412 - val_precision: 0.4167\n",
      "Epoch 285/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1696 - precision: 0.9737 - val_loss: 0.5439 - val_precision: 0.4167\n",
      "Epoch 286/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1691 - precision: 0.9737 - val_loss: 0.5453 - val_precision: 0.4167\n",
      "Epoch 287/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1692 - precision: 0.9737 - val_loss: 0.5482 - val_precision: 0.4167\n",
      "Epoch 288/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1680 - precision: 0.9744 - val_loss: 0.5466 - val_precision: 0.4167\n",
      "Epoch 289/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1680 - precision: 0.9737 - val_loss: 0.5466 - val_precision: 0.4167\n",
      "Epoch 290/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1682 - precision: 0.9737 - val_loss: 0.5469 - val_precision: 0.4167\n",
      "Epoch 291/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1679 - precision: 0.9737 - val_loss: 0.5498 - val_precision: 0.4167\n",
      "Epoch 292/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1685 - precision: 0.9750 - val_loss: 0.5668 - val_precision: 0.4615\n",
      "Epoch 293/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1698 - precision: 0.9756 - val_loss: 0.5585 - val_precision: 0.4167\n",
      "Epoch 294/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1668 - precision: 0.9750 - val_loss: 0.5556 - val_precision: 0.4167\n",
      "Epoch 295/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1670 - precision: 0.9756 - val_loss: 0.5594 - val_precision: 0.4167\n",
      "Epoch 296/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1664 - precision: 0.9744 - val_loss: 0.5521 - val_precision: 0.4167\n",
      "Epoch 297/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1667 - precision: 0.9737 - val_loss: 0.5488 - val_precision: 0.4167\n",
      "Epoch 298/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1668 - precision: 0.9737 - val_loss: 0.5530 - val_precision: 0.4167\n",
      "Epoch 299/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1658 - precision: 0.9737 - val_loss: 0.5594 - val_precision: 0.4167\n",
      "Epoch 300/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1655 - precision: 0.9750 - val_loss: 0.5637 - val_precision: 0.4167\n",
      "Epoch 301/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1653 - precision: 0.9750 - val_loss: 0.5638 - val_precision: 0.4167\n",
      "Epoch 302/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1642 - precision: 0.9750 - val_loss: 0.5592 - val_precision: 0.4167\n",
      "Epoch 303/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1642 - precision: 0.9737 - val_loss: 0.5590 - val_precision: 0.4167\n",
      "Epoch 304/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1658 - precision: 0.9750 - val_loss: 0.5665 - val_precision: 0.3846\n",
      "Epoch 305/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1640 - precision: 0.9750 - val_loss: 0.5653 - val_precision: 0.4167\n",
      "Epoch 306/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1645 - precision: 0.9762 - val_loss: 0.5763 - val_precision: 0.4286\n",
      "Epoch 307/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1635 - precision: 0.9756 - val_loss: 0.5670 - val_precision: 0.4167\n",
      "Epoch 308/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1622 - precision: 0.9737 - val_loss: 0.5630 - val_precision: 0.4167\n",
      "Epoch 309/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1641 - precision: 0.9762 - val_loss: 0.5795 - val_precision: 0.3571\n",
      "Epoch 310/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1648 - precision: 0.9762 - val_loss: 0.5697 - val_precision: 0.4167\n",
      "Epoch 311/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1620 - precision: 0.9756 - val_loss: 0.5665 - val_precision: 0.4167\n",
      "Epoch 312/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1642 - precision: 0.9750 - val_loss: 0.5662 - val_precision: 0.4167\n",
      "Epoch 313/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1621 - precision: 0.9750 - val_loss: 0.5728 - val_precision: 0.4167\n",
      "Epoch 314/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1620 - precision: 0.9762 - val_loss: 0.5790 - val_precision: 0.3846\n",
      "Epoch 315/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1647 - precision: 0.9130 - val_loss: 0.5836 - val_precision: 0.3571\n",
      "Epoch 316/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1631 - precision: 0.9318 - val_loss: 0.5795 - val_precision: 0.3846\n",
      "Epoch 317/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1608 - precision: 0.9762 - val_loss: 0.5731 - val_precision: 0.4167\n",
      "Epoch 318/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1620 - precision: 0.9762 - val_loss: 0.5787 - val_precision: 0.3846\n",
      "Epoch 319/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1633 - precision: 0.9333 - val_loss: 0.5853 - val_precision: 0.3571\n",
      "Epoch 320/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1599 - precision: 0.9762 - val_loss: 0.5755 - val_precision: 0.3846\n",
      "Epoch 321/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1589 - precision: 0.9750 - val_loss: 0.5738 - val_precision: 0.4167\n",
      "Epoch 322/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1593 - precision: 0.9756 - val_loss: 0.5801 - val_precision: 0.4167\n",
      "Epoch 323/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1588 - precision: 0.9756 - val_loss: 0.5844 - val_precision: 0.3846\n",
      "Epoch 324/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1595 - precision: 0.9762 - val_loss: 0.5819 - val_precision: 0.4167\n",
      "Epoch 325/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1584 - precision: 0.9756 - val_loss: 0.5809 - val_precision: 0.4167\n",
      "Epoch 326/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1580 - precision: 0.9750 - val_loss: 0.5819 - val_precision: 0.4167\n",
      "Epoch 327/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1591 - precision: 0.9762 - val_loss: 0.5888 - val_precision: 0.3846\n",
      "Epoch 328/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1593 - precision: 0.9762 - val_loss: 0.5877 - val_precision: 0.3846\n",
      "Epoch 329/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1612 - precision: 0.9333 - val_loss: 0.5986 - val_precision: 0.4000\n",
      "Epoch 330/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1601 - precision: 0.9545 - val_loss: 0.5841 - val_precision: 0.3846\n",
      "Epoch 331/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1569 - precision: 0.9756 - val_loss: 0.5819 - val_precision: 0.4167\n",
      "Epoch 332/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1566 - precision: 0.9756 - val_loss: 0.5862 - val_precision: 0.4167\n",
      "Epoch 333/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1563 - precision: 0.9756 - val_loss: 0.5915 - val_precision: 0.3846\n",
      "Epoch 334/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1566 - precision: 0.9767 - val_loss: 0.6175 - val_precision: 0.4375\n",
      "Epoch 335/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1601 - precision: 0.9535 - val_loss: 0.6035 - val_precision: 0.4286\n",
      "Epoch 336/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1568 - precision: 0.9756 - val_loss: 0.5929 - val_precision: 0.4167\n",
      "Epoch 337/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1566 - precision: 0.9750 - val_loss: 0.5903 - val_precision: 0.4167\n",
      "Epoch 338/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1562 - precision: 0.9750 - val_loss: 0.5915 - val_precision: 0.4167\n",
      "Epoch 339/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1555 - precision: 0.9756 - val_loss: 0.5923 - val_precision: 0.4167\n",
      "Epoch 340/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1562 - precision: 0.9756 - val_loss: 0.5879 - val_precision: 0.4167\n",
      "Epoch 341/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1558 - precision: 0.9756 - val_loss: 0.5908 - val_precision: 0.4167\n",
      "Epoch 342/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1553 - precision: 0.9756 - val_loss: 0.5933 - val_precision: 0.4167\n",
      "Epoch 343/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1548 - precision: 0.9756 - val_loss: 0.5970 - val_precision: 0.3846\n",
      "Epoch 344/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1543 - precision: 0.9756 - val_loss: 0.5990 - val_precision: 0.3846\n",
      "Epoch 345/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1539 - precision: 0.9756 - val_loss: 0.5997 - val_precision: 0.3846\n",
      "Epoch 346/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1532 - precision: 0.9756 - val_loss: 0.6139 - val_precision: 0.4286\n",
      "Epoch 347/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1565 - precision: 0.9535 - val_loss: 0.6135 - val_precision: 0.4286\n",
      "Epoch 348/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1518 - precision: 0.9756 - val_loss: 0.6020 - val_precision: 0.4167\n",
      "Epoch 349/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1561 - precision: 0.9756 - val_loss: 0.5998 - val_precision: 0.5000\n",
      "Epoch 350/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1550 - precision: 0.9756 - val_loss: 0.6008 - val_precision: 0.4167\n",
      "Epoch 351/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1546 - precision: 0.9535 - val_loss: 0.6158 - val_precision: 0.4000\n",
      "Epoch 352/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1547 - precision: 0.9545 - val_loss: 0.6101 - val_precision: 0.3571\n",
      "Epoch 353/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1537 - precision: 0.9762 - val_loss: 0.6034 - val_precision: 0.3846\n",
      "Epoch 354/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1529 - precision: 0.9762 - val_loss: 0.6162 - val_precision: 0.3846\n",
      "Epoch 355/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1529 - precision: 0.9756 - val_loss: 0.6160 - val_precision: 0.3846\n",
      "Epoch 356/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1521 - precision: 0.9756 - val_loss: 0.6150 - val_precision: 0.3846\n",
      "Epoch 357/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1518 - precision: 0.9756 - val_loss: 0.6107 - val_precision: 0.3846\n",
      "Epoch 358/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1515 - precision: 0.9756 - val_loss: 0.6076 - val_precision: 0.3846\n",
      "Epoch 359/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1513 - precision: 0.9756 - val_loss: 0.6070 - val_precision: 0.3846\n",
      "Epoch 360/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1507 - precision: 0.9756 - val_loss: 0.6058 - val_precision: 0.3846\n",
      "Epoch 361/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1511 - precision: 0.9756 - val_loss: 0.6067 - val_precision: 0.3846\n",
      "Epoch 362/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1513 - precision: 0.9524 - val_loss: 0.6069 - val_precision: 0.3846\n",
      "Epoch 363/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1512 - precision: 0.9762 - val_loss: 0.6107 - val_precision: 0.3846\n",
      "Epoch 364/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1502 - precision: 0.9756 - val_loss: 0.6108 - val_precision: 0.3846\n",
      "Epoch 365/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1506 - precision: 0.9756 - val_loss: 0.6138 - val_precision: 0.3846\n",
      "Epoch 366/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1499 - precision: 0.9762 - val_loss: 0.6182 - val_precision: 0.3846\n",
      "Epoch 367/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1500 - precision: 0.9535 - val_loss: 0.6195 - val_precision: 0.3846\n",
      "Epoch 368/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1499 - precision: 0.9762 - val_loss: 0.6163 - val_precision: 0.3846\n",
      "Epoch 369/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1497 - precision: 0.9756 - val_loss: 0.6171 - val_precision: 0.3846\n",
      "Epoch 370/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1500 - precision: 0.9756 - val_loss: 0.6157 - val_precision: 0.3846\n",
      "Epoch 371/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1478 - precision: 0.9762 - val_loss: 0.6224 - val_precision: 0.3571\n",
      "Epoch 372/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1494 - precision: 0.9535 - val_loss: 0.6246 - val_precision: 0.4000\n",
      "Epoch 373/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1493 - precision: 0.9762 - val_loss: 0.6170 - val_precision: 0.3846\n",
      "Epoch 374/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1489 - precision: 0.9756 - val_loss: 0.6176 - val_precision: 0.3846\n",
      "Epoch 375/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1498 - precision: 0.9756 - val_loss: 0.6196 - val_precision: 0.3846\n",
      "Epoch 376/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.1502 - precision: 0.9545 - val_loss: 0.6403 - val_precision: 0.4000\n",
      "Epoch 377/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1514 - precision: 0.9556 - val_loss: 0.6238 - val_precision: 0.4000\n",
      "Epoch 378/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1489 - precision: 0.9524 - val_loss: 0.6170 - val_precision: 0.3846\n",
      "Epoch 379/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1501 - precision: 0.9756 - val_loss: 0.6185 - val_precision: 0.3846\n",
      "Epoch 380/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.1496 - precision: 0.9756 - val_loss: 0.6222 - val_precision: 0.3846\n",
      "Epoch 381/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1503 - precision: 0.9535 - val_loss: 0.6387 - val_precision: 0.4000\n",
      "Epoch 382/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1511 - precision: 0.9535 - val_loss: 0.6268 - val_precision: 0.3846\n",
      "Epoch 383/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1489 - precision: 0.9535 - val_loss: 0.6311 - val_precision: 0.3571\n",
      "Epoch 384/500\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.1477 - precision: 0.9535 - val_loss: 0.6272 - val_precision: 0.3846\n",
      "Epoch 385/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1470 - precision: 0.9535 - val_loss: 0.6259 - val_precision: 0.3846\n",
      "Epoch 386/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1494 - precision: 0.9756 - val_loss: 0.6253 - val_precision: 0.4545\n",
      "Epoch 387/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1494 - precision: 0.9756 - val_loss: 0.6277 - val_precision: 0.3846\n",
      "Epoch 388/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1450 - precision: 0.9535 - val_loss: 0.6421 - val_precision: 0.4000\n",
      "Epoch 389/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.1480 - precision: 0.9535 - val_loss: 0.6422 - val_precision: 0.4000\n",
      "Epoch 390/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1483 - precision: 0.9535 - val_loss: 0.6328 - val_precision: 0.3846\n",
      "Epoch 391/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1463 - precision: 0.9535 - val_loss: 0.6318 - val_precision: 0.3846\n",
      "Epoch 392/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1460 - precision: 0.9535 - val_loss: 0.6313 - val_precision: 0.3846\n",
      "Epoch 393/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1478 - precision: 0.9762 - val_loss: 0.6259 - val_precision: 0.4167\n",
      "Epoch 394/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1456 - precision: 0.9762 - val_loss: 0.6329 - val_precision: 0.3571\n",
      "Epoch 395/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1462 - precision: 0.9535 - val_loss: 0.6373 - val_precision: 0.3571\n",
      "Epoch 396/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.1461 - precision: 0.9545 - val_loss: 0.6389 - val_precision: 0.3571\n",
      "Epoch 397/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1457 - precision: 0.9545 - val_loss: 0.6376 - val_precision: 0.3846\n",
      "Epoch 398/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1448 - precision: 0.9535 - val_loss: 0.6368 - val_precision: 0.3846\n",
      "Epoch 399/500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1464 - precision: 0.9756 - val_loss: 0.6390 - val_precision: 0.4545\n",
      "Epoch 400/500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1471 - precision: 0.9756 - val_loss: 0.6599 - val_precision: 0.4286\n",
      "Epoch 401/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1464 - precision: 0.9756 - val_loss: 0.6678 - val_precision: 0.4000\n",
      "Epoch 402/500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1468 - precision: 0.9545 - val_loss: 0.6682 - val_precision: 0.4000\n",
      "Epoch 403/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1461 - precision: 0.9545 - val_loss: 0.6516 - val_precision: 0.3571\n",
      "Epoch 404/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1446 - precision: 0.9545 - val_loss: 0.6432 - val_precision: 0.3846\n",
      "Epoch 405/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1441 - precision: 0.9535 - val_loss: 0.6456 - val_precision: 0.3571\n",
      "Epoch 406/500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1444 - precision: 0.9535 - val_loss: 0.6470 - val_precision: 0.3571\n",
      "Epoch 407/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1442 - precision: 0.9545 - val_loss: 0.6505 - val_precision: 0.3571\n",
      "Epoch 408/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1439 - precision: 0.9545 - val_loss: 0.6484 - val_precision: 0.3571\n",
      "Epoch 409/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1445 - precision: 0.9535 - val_loss: 0.6409 - val_precision: 0.3846\n",
      "Epoch 410/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1457 - precision: 0.9524 - val_loss: 0.6480 - val_precision: 0.3571\n",
      "Epoch 411/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1453 - precision: 0.9545 - val_loss: 0.6516 - val_precision: 0.3571\n",
      "Epoch 412/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1445 - precision: 0.9545 - val_loss: 0.6510 - val_precision: 0.3571\n",
      "Epoch 413/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1452 - precision: 0.9756 - val_loss: 0.6486 - val_precision: 0.4167\n",
      "Epoch 414/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1451 - precision: 0.9756 - val_loss: 0.6524 - val_precision: 0.4167\n",
      "Epoch 415/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1436 - precision: 0.9756 - val_loss: 0.6584 - val_precision: 0.3571\n",
      "Epoch 416/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1437 - precision: 0.9535 - val_loss: 0.6769 - val_precision: 0.4000\n",
      "Epoch 417/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1464 - precision: 0.9149 - val_loss: 0.6677 - val_precision: 0.4000\n",
      "Epoch 418/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1448 - precision: 0.9348 - val_loss: 0.6645 - val_precision: 0.4000\n",
      "Epoch 419/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1437 - precision: 0.9545 - val_loss: 0.6540 - val_precision: 0.3571\n",
      "Epoch 420/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1469 - precision: 0.9524 - val_loss: 0.6521 - val_precision: 0.4167\n",
      "Epoch 421/500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1445 - precision: 0.9762 - val_loss: 0.6586 - val_precision: 0.3571\n",
      "Epoch 422/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1431 - precision: 0.9545 - val_loss: 0.6603 - val_precision: 0.3571\n",
      "Epoch 423/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1425 - precision: 0.9545 - val_loss: 0.6571 - val_precision: 0.3571\n",
      "Epoch 424/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1423 - precision: 0.9545 - val_loss: 0.6564 - val_precision: 0.3846\n",
      "Epoch 425/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1429 - precision: 0.9524 - val_loss: 0.6581 - val_precision: 0.3846\n",
      "Epoch 426/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.1468 - precision: 0.9750 - val_loss: 0.6577 - val_precision: 0.4545\n",
      "Epoch 427/500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1435 - precision: 0.9767 - val_loss: 0.6652 - val_precision: 0.3571\n",
      "Epoch 428/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1426 - precision: 0.9545 - val_loss: 0.6663 - val_precision: 0.3571\n",
      "Epoch 429/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1418 - precision: 0.9545 - val_loss: 0.6574 - val_precision: 0.3571\n",
      "Epoch 430/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1447 - precision: 0.9762 - val_loss: 0.6547 - val_precision: 0.4167\n",
      "Epoch 431/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1424 - precision: 0.9756 - val_loss: 0.6592 - val_precision: 0.3571\n",
      "Epoch 432/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1432 - precision: 0.9333 - val_loss: 0.6714 - val_precision: 0.4000\n",
      "Epoch 433/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1425 - precision: 0.9348 - val_loss: 0.6661 - val_precision: 0.3571\n",
      "Epoch 434/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1417 - precision: 0.9545 - val_loss: 0.6661 - val_precision: 0.3571\n",
      "Epoch 435/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1443 - precision: 0.9333 - val_loss: 0.6755 - val_precision: 0.4000\n",
      "Epoch 436/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1429 - precision: 0.9149 - val_loss: 0.6729 - val_precision: 0.3571\n",
      "Epoch 437/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1432 - precision: 0.9149 - val_loss: 0.6704 - val_precision: 0.3571\n",
      "Epoch 438/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1413 - precision: 0.9545 - val_loss: 0.6647 - val_precision: 0.3571\n",
      "Epoch 439/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1412 - precision: 0.9545 - val_loss: 0.6640 - val_precision: 0.3846\n",
      "Epoch 440/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1414 - precision: 0.9762 - val_loss: 0.6671 - val_precision: 0.3846\n",
      "Epoch 441/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1424 - precision: 0.9545 - val_loss: 0.6837 - val_precision: 0.4000\n",
      "Epoch 442/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1422 - precision: 0.9348 - val_loss: 0.6757 - val_precision: 0.3571\n",
      "Epoch 443/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1404 - precision: 0.9545 - val_loss: 0.6678 - val_precision: 0.3846\n",
      "Epoch 444/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1411 - precision: 0.9762 - val_loss: 0.6667 - val_precision: 0.4167\n",
      "Epoch 445/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1427 - precision: 0.9762 - val_loss: 0.6694 - val_precision: 0.3846\n",
      "Epoch 446/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1418 - precision: 0.9756 - val_loss: 0.6667 - val_precision: 0.3846\n",
      "Epoch 447/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1409 - precision: 0.9762 - val_loss: 0.6692 - val_precision: 0.3846\n",
      "Epoch 448/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1406 - precision: 0.9762 - val_loss: 0.6736 - val_precision: 0.3846\n",
      "Epoch 449/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1411 - precision: 0.9545 - val_loss: 0.6885 - val_precision: 0.3571\n",
      "Epoch 450/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1461 - precision: 0.8980 - val_loss: 0.7073 - val_precision: 0.3529\n",
      "Epoch 451/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1433 - precision: 0.9167 - val_loss: 0.6749 - val_precision: 0.3571\n",
      "Epoch 452/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1441 - precision: 0.9767 - val_loss: 0.6681 - val_precision: 0.4167\n",
      "Epoch 453/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1402 - precision: 0.9762 - val_loss: 0.6741 - val_precision: 0.3571\n",
      "Epoch 454/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1401 - precision: 0.9333 - val_loss: 0.6807 - val_precision: 0.3571\n",
      "Epoch 455/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1399 - precision: 0.9545 - val_loss: 0.6804 - val_precision: 0.3571\n",
      "Epoch 456/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1406 - precision: 0.9130 - val_loss: 0.6951 - val_precision: 0.4000\n",
      "Epoch 457/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1429 - precision: 0.9149 - val_loss: 0.6850 - val_precision: 0.3571\n",
      "Epoch 458/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1392 - precision: 0.9556 - val_loss: 0.6747 - val_precision: 0.3846\n",
      "Epoch 459/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1407 - precision: 0.9762 - val_loss: 0.6770 - val_precision: 0.3846\n",
      "Epoch 460/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1401 - precision: 0.9545 - val_loss: 0.6872 - val_precision: 0.3571\n",
      "Epoch 461/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1394 - precision: 0.9348 - val_loss: 0.6868 - val_precision: 0.3571\n",
      "Epoch 462/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1387 - precision: 0.9545 - val_loss: 0.6838 - val_precision: 0.3571\n",
      "Epoch 463/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1389 - precision: 0.9545 - val_loss: 0.6812 - val_precision: 0.3846\n",
      "Epoch 464/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1393 - precision: 0.9762 - val_loss: 0.6825 - val_precision: 0.3846\n",
      "Epoch 465/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1382 - precision: 0.9545 - val_loss: 0.6900 - val_precision: 0.3571\n",
      "Epoch 466/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1399 - precision: 0.9545 - val_loss: 0.6839 - val_precision: 0.3846\n",
      "Epoch 467/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1401 - precision: 0.9545 - val_loss: 0.6869 - val_precision: 0.3571\n",
      "Epoch 468/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1397 - precision: 0.9535 - val_loss: 0.6858 - val_precision: 0.3846\n",
      "Epoch 469/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1394 - precision: 0.9762 - val_loss: 0.6876 - val_precision: 0.3846\n",
      "Epoch 470/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1387 - precision: 0.9762 - val_loss: 0.6919 - val_precision: 0.3571\n",
      "Epoch 471/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1377 - precision: 0.9545 - val_loss: 0.6941 - val_precision: 0.3571\n",
      "Epoch 472/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1380 - precision: 0.9545 - val_loss: 0.6913 - val_precision: 0.3571\n",
      "Epoch 473/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1379 - precision: 0.9545 - val_loss: 0.6883 - val_precision: 0.3571\n",
      "Epoch 474/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1375 - precision: 0.9545 - val_loss: 0.6859 - val_precision: 0.4167\n",
      "Epoch 475/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1403 - precision: 0.9762 - val_loss: 0.6823 - val_precision: 0.3846\n",
      "Epoch 476/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1382 - precision: 0.9545 - val_loss: 0.6851 - val_precision: 0.3571\n",
      "Epoch 477/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1370 - precision: 0.9545 - val_loss: 0.6925 - val_precision: 0.3571\n",
      "Epoch 478/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.1385 - precision: 0.9348 - val_loss: 0.7018 - val_precision: 0.4000\n",
      "Epoch 479/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1381 - precision: 0.9348 - val_loss: 0.6969 - val_precision: 0.3571\n",
      "Epoch 480/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1379 - precision: 0.9348 - val_loss: 0.7022 - val_precision: 0.4000\n",
      "Epoch 481/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1402 - precision: 0.9348 - val_loss: 0.6959 - val_precision: 0.4000\n",
      "Epoch 482/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1447 - precision: 0.9184 - val_loss: 0.7195 - val_precision: 0.3889\n",
      "Epoch 483/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1434 - precision: 0.8846 - val_loss: 0.6871 - val_precision: 0.4000\n",
      "Epoch 484/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.1365 - precision: 0.9348 - val_loss: 0.6765 - val_precision: 0.3571\n",
      "Epoch 485/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1382 - precision: 0.9545 - val_loss: 0.6784 - val_precision: 0.4167\n",
      "Epoch 486/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1386 - precision: 0.9556 - val_loss: 0.6899 - val_precision: 0.3571\n",
      "Epoch 487/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1377 - precision: 0.9348 - val_loss: 0.6956 - val_precision: 0.4000\n",
      "Epoch 488/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1382 - precision: 0.9348 - val_loss: 0.6925 - val_precision: 0.3571\n",
      "Epoch 489/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1365 - precision: 0.9348 - val_loss: 0.6849 - val_precision: 0.3571\n",
      "Epoch 490/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1366 - precision: 0.9545 - val_loss: 0.6856 - val_precision: 0.3571\n",
      "Epoch 491/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1368 - precision: 0.9545 - val_loss: 0.6909 - val_precision: 0.3571\n",
      "Epoch 492/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1367 - precision: 0.9545 - val_loss: 0.6938 - val_precision: 0.3571\n",
      "Epoch 493/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1366 - precision: 0.9545 - val_loss: 0.6964 - val_precision: 0.3571\n",
      "Epoch 494/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1363 - precision: 0.9545 - val_loss: 0.6963 - val_precision: 0.3571\n",
      "Epoch 495/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1382 - precision: 0.9535 - val_loss: 0.6949 - val_precision: 0.4167\n",
      "Epoch 496/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1361 - precision: 0.9535 - val_loss: 0.7012 - val_precision: 0.3571\n",
      "Epoch 497/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1365 - precision: 0.9348 - val_loss: 0.7060 - val_precision: 0.3571\n",
      "Epoch 498/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1361 - precision: 0.9348 - val_loss: 0.7023 - val_precision: 0.3571\n",
      "Epoch 499/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1356 - precision: 0.9348 - val_loss: 0.7017 - val_precision: 0.3571\n",
      "Epoch 500/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1365 - precision: 0.9348 - val_loss: 0.7060 - val_precision: 0.4000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "history = modelb.fit(padded, training_labels_final, \n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(val_padded, val_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "zznkunIyBt9Q",
    "outputId": "223a6f2f-9b8e-4071-e31c-70134f3a0d15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "precision = history.history['precision']\n",
    "val_precision = history.history['val_precision']\n",
    "epochs=range(len(precision))\n",
    "plt.plot(epochs, precision, 'r')\n",
    "plt.plot(epochs, val_precision, 'b')\n",
    "plt.title('Training and validation Precision')\n",
    "plt.ylim((0,1.5))\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c5mZK0lJ8eSR",
    "outputId": "7312e877-4e9c-4604-cd0d-3471e0350912",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8958 - precision: 0.6364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8957670331001282, 0.6363636255264282]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelb.evaluate(test_padded, test_labels_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_k1wZhYND2H"
   },
   "source": [
    "# Part II. Pre-trained embedding specialized for Central Banks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UE75Z1v6ND2H"
   },
   "source": [
    "### First we apply the central bank-specific embeddings by Zahner and Baumgaertner predicting the next rate.  We will first explore the embeddings then run the models.  We find there are over 72,000 word vectors and 300 features per word.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "MErAW7f3ND2I"
   },
   "outputs": [],
   "source": [
    "zb = pd.read_csv('word_embeddings_3b.csv') #, header=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jfz9L4GyYjiL",
    "outputId": "a656809e-b61b-4ff4-c6ec-fb1b547c3526"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73082, 301)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "YnBXoREAND2I",
    "outputId": "252cbc74-4227-474d-843a-938e8ec41f28"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V291</th>\n",
       "      <th>V292</th>\n",
       "      <th>V293</th>\n",
       "      <th>V294</th>\n",
       "      <th>V295</th>\n",
       "      <th>V296</th>\n",
       "      <th>V297</th>\n",
       "      <th>V298</th>\n",
       "      <th>V299</th>\n",
       "      <th>V300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>0.080156</td>\n",
       "      <td>0.088501</td>\n",
       "      <td>-0.076703</td>\n",
       "      <td>-0.065645</td>\n",
       "      <td>0.027367</td>\n",
       "      <td>0.060499</td>\n",
       "      <td>0.018841</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>-0.072163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025759</td>\n",
       "      <td>0.030279</td>\n",
       "      <td>0.019642</td>\n",
       "      <td>-0.030535</td>\n",
       "      <td>0.058834</td>\n",
       "      <td>-0.092278</td>\n",
       "      <td>-0.028259</td>\n",
       "      <td>-0.026270</td>\n",
       "      <td>-0.033166</td>\n",
       "      <td>0.061495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>-0.038091</td>\n",
       "      <td>-0.049348</td>\n",
       "      <td>-0.028680</td>\n",
       "      <td>-0.018713</td>\n",
       "      <td>0.063518</td>\n",
       "      <td>0.057007</td>\n",
       "      <td>0.021474</td>\n",
       "      <td>0.084622</td>\n",
       "      <td>-0.108604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004401</td>\n",
       "      <td>0.030320</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>-0.081768</td>\n",
       "      <td>0.011895</td>\n",
       "      <td>0.025118</td>\n",
       "      <td>0.029903</td>\n",
       "      <td>0.029950</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>-0.065045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.061148</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>-0.058344</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>0.039084</td>\n",
       "      <td>0.056894</td>\n",
       "      <td>-0.048181</td>\n",
       "      <td>0.049727</td>\n",
       "      <td>-0.075358</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038889</td>\n",
       "      <td>0.069039</td>\n",
       "      <td>0.018876</td>\n",
       "      <td>-0.050831</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>0.018375</td>\n",
       "      <td>0.052614</td>\n",
       "      <td>0.057787</td>\n",
       "      <td>-0.000694</td>\n",
       "      <td>-0.043442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.</td>\n",
       "      <td>-0.099335</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>-0.048134</td>\n",
       "      <td>-0.010280</td>\n",
       "      <td>-0.000963</td>\n",
       "      <td>0.022920</td>\n",
       "      <td>-0.026348</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>-0.068051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032482</td>\n",
       "      <td>0.063615</td>\n",
       "      <td>-0.020517</td>\n",
       "      <td>-0.017632</td>\n",
       "      <td>0.029572</td>\n",
       "      <td>0.061214</td>\n",
       "      <td>0.075277</td>\n",
       "      <td>0.135811</td>\n",
       "      <td>-0.011819</td>\n",
       "      <td>-0.106832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>-0.092714</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>-0.048257</td>\n",
       "      <td>0.010404</td>\n",
       "      <td>0.047617</td>\n",
       "      <td>0.060156</td>\n",
       "      <td>-0.019659</td>\n",
       "      <td>0.040367</td>\n",
       "      <td>-0.107395</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036493</td>\n",
       "      <td>0.109343</td>\n",
       "      <td>-0.000342</td>\n",
       "      <td>-0.072286</td>\n",
       "      <td>0.045893</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.056748</td>\n",
       "      <td>0.037754</td>\n",
       "      <td>-0.022448</td>\n",
       "      <td>-0.029516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  </s>  0.080156  0.088501 -0.076703 -0.065645  0.027367  0.060499  0.018841   \n",
       "1   the -0.038091 -0.049348 -0.028680 -0.018713  0.063518  0.057007  0.021474   \n",
       "2   NaN -0.061148 -0.000166 -0.058344  0.014657  0.039084  0.056894 -0.048181   \n",
       "3     . -0.099335  0.001326 -0.048134 -0.010280 -0.000963  0.022920 -0.026348   \n",
       "4    of -0.092714  0.016854 -0.048257  0.010404  0.047617  0.060156 -0.019659   \n",
       "\n",
       "         V8        V9  ...      V291      V292      V293      V294      V295  \\\n",
       "0  0.004232 -0.072163  ... -0.025759  0.030279  0.019642 -0.030535  0.058834   \n",
       "1  0.084622 -0.108604  ...  0.004401  0.030320  0.001037 -0.081768  0.011895   \n",
       "2  0.049727 -0.075358  ... -0.038889  0.069039  0.018876 -0.050831  0.029056   \n",
       "3  0.010025 -0.068051  ... -0.032482  0.063615 -0.020517 -0.017632  0.029572   \n",
       "4  0.040367 -0.107395  ... -0.036493  0.109343 -0.000342 -0.072286  0.045893   \n",
       "\n",
       "       V296      V297      V298      V299      V300  \n",
       "0 -0.092278 -0.028259 -0.026270 -0.033166  0.061495  \n",
       "1  0.025118  0.029903  0.029950  0.002812 -0.065045  \n",
       "2  0.018375  0.052614  0.057787 -0.000694 -0.043442  \n",
       "3  0.061214  0.075277  0.135811 -0.011819 -0.106832  \n",
       "4  0.002628  0.056748  0.037754 -0.022448 -0.029516  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "Egu7UblMND2J"
   },
   "outputs": [],
   "source": [
    "zb=zb.set_index('word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "r2qwWbayND2J"
   },
   "outputs": [],
   "source": [
    "zb_transposed = zb.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "MvNwD17GND2K",
    "outputId": "ad932ccd-bf90-4031-9896-6e497659559e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>word</th>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "      <th>the</th>\n",
       "      <th>NaN</th>\n",
       "      <th>.</th>\n",
       "      <th>of</th>\n",
       "      <th>to</th>\n",
       "      <th>and</th>\n",
       "      <th>in</th>\n",
       "      <th>[decimal]</th>\n",
       "      <th>a</th>\n",
       "      <th>...</th>\n",
       "      <th>cop25</th>\n",
       "      <th>alistair</th>\n",
       "      <th>effectuation</th>\n",
       "      <th>fhfas</th>\n",
       "      <th>vaciago</th>\n",
       "      <th>just-i</th>\n",
       "      <th>ancona</th>\n",
       "      <th>1999–2001</th>\n",
       "      <th>ctos</th>\n",
       "      <th>altcoins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>0.080156</td>\n",
       "      <td>-0.038091</td>\n",
       "      <td>-0.061148</td>\n",
       "      <td>-0.099335</td>\n",
       "      <td>-0.092714</td>\n",
       "      <td>0.019735</td>\n",
       "      <td>-0.015383</td>\n",
       "      <td>0.009759</td>\n",
       "      <td>-0.047645</td>\n",
       "      <td>0.060641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078843</td>\n",
       "      <td>-0.023943</td>\n",
       "      <td>0.021798</td>\n",
       "      <td>0.034371</td>\n",
       "      <td>-0.039774</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>-0.061320</td>\n",
       "      <td>-0.033173</td>\n",
       "      <td>-0.207396</td>\n",
       "      <td>0.019181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>0.088501</td>\n",
       "      <td>-0.049348</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>0.017912</td>\n",
       "      <td>0.014828</td>\n",
       "      <td>-0.050921</td>\n",
       "      <td>-0.077989</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026619</td>\n",
       "      <td>-0.013862</td>\n",
       "      <td>0.074990</td>\n",
       "      <td>-0.068248</td>\n",
       "      <td>0.046751</td>\n",
       "      <td>0.017442</td>\n",
       "      <td>-0.031018</td>\n",
       "      <td>-0.095737</td>\n",
       "      <td>0.106908</td>\n",
       "      <td>0.013239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>-0.076703</td>\n",
       "      <td>-0.028680</td>\n",
       "      <td>-0.058344</td>\n",
       "      <td>-0.048134</td>\n",
       "      <td>-0.048257</td>\n",
       "      <td>-0.018683</td>\n",
       "      <td>-0.044502</td>\n",
       "      <td>-0.004150</td>\n",
       "      <td>0.003544</td>\n",
       "      <td>-0.009209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120499</td>\n",
       "      <td>0.074515</td>\n",
       "      <td>0.022469</td>\n",
       "      <td>-0.012830</td>\n",
       "      <td>0.029337</td>\n",
       "      <td>-0.059405</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.104349</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>-0.034064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>-0.065645</td>\n",
       "      <td>-0.018713</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>-0.010280</td>\n",
       "      <td>0.010404</td>\n",
       "      <td>-0.022496</td>\n",
       "      <td>-0.005357</td>\n",
       "      <td>-0.009244</td>\n",
       "      <td>0.034186</td>\n",
       "      <td>-0.019526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041775</td>\n",
       "      <td>-0.004044</td>\n",
       "      <td>0.053189</td>\n",
       "      <td>-0.057841</td>\n",
       "      <td>0.028182</td>\n",
       "      <td>-0.011910</td>\n",
       "      <td>0.006949</td>\n",
       "      <td>-0.006095</td>\n",
       "      <td>-0.042527</td>\n",
       "      <td>0.041970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>0.027367</td>\n",
       "      <td>0.063518</td>\n",
       "      <td>0.039084</td>\n",
       "      <td>-0.000963</td>\n",
       "      <td>0.047617</td>\n",
       "      <td>0.073557</td>\n",
       "      <td>0.016352</td>\n",
       "      <td>0.076654</td>\n",
       "      <td>0.046362</td>\n",
       "      <td>0.011457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062888</td>\n",
       "      <td>-0.030928</td>\n",
       "      <td>0.072676</td>\n",
       "      <td>-0.003460</td>\n",
       "      <td>0.053458</td>\n",
       "      <td>0.047244</td>\n",
       "      <td>0.068072</td>\n",
       "      <td>0.091003</td>\n",
       "      <td>0.006158</td>\n",
       "      <td>-0.034872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73082 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "word      </s>       the       NaN         .        of        to       and  \\\n",
       "V1    0.080156 -0.038091 -0.061148 -0.099335 -0.092714  0.019735 -0.015383   \n",
       "V2    0.088501 -0.049348 -0.000166  0.001326  0.016854  0.017912  0.014828   \n",
       "V3   -0.076703 -0.028680 -0.058344 -0.048134 -0.048257 -0.018683 -0.044502   \n",
       "V4   -0.065645 -0.018713  0.014657 -0.010280  0.010404 -0.022496 -0.005357   \n",
       "V5    0.027367  0.063518  0.039084 -0.000963  0.047617  0.073557  0.016352   \n",
       "\n",
       "word        in  [decimal]         a  ...     cop25  alistair  effectuation  \\\n",
       "V1    0.009759  -0.047645  0.060641  ... -0.078843 -0.023943      0.021798   \n",
       "V2   -0.050921  -0.077989 -0.000283  ... -0.026619 -0.013862      0.074990   \n",
       "V3   -0.004150   0.003544 -0.009209  ...  0.120499  0.074515      0.022469   \n",
       "V4   -0.009244   0.034186 -0.019526  ...  0.041775 -0.004044      0.053189   \n",
       "V5    0.076654   0.046362  0.011457  ...  0.062888 -0.030928      0.072676   \n",
       "\n",
       "word     fhfas   vaciago    just-i    ancona  1999–2001      ctos  altcoins  \n",
       "V1    0.034371 -0.039774  0.003213 -0.061320  -0.033173 -0.207396  0.019181  \n",
       "V2   -0.068248  0.046751  0.017442 -0.031018  -0.095737  0.106908  0.013239  \n",
       "V3   -0.012830  0.029337 -0.059405  0.003367   0.104349  0.015193 -0.034064  \n",
       "V4   -0.057841  0.028182 -0.011910  0.006949  -0.006095 -0.042527  0.041970  \n",
       "V5   -0.003460  0.053458  0.047244  0.068072   0.091003  0.006158 -0.034872  \n",
       "\n",
       "[5 rows x 73082 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zb_transposed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "nxkUhBxIND2K"
   },
   "outputs": [],
   "source": [
    "list_of_columns = zb.values.tolist() # was df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "2vNAz2WYND2L"
   },
   "outputs": [],
   "source": [
    "words=list(zb_transposed.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "7SrlSBrAND2X",
    "outputId": "13067689-3893-4dd5-c5fc-b5ae23a29fee"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V291</th>\n",
       "      <th>V292</th>\n",
       "      <th>V293</th>\n",
       "      <th>V294</th>\n",
       "      <th>V295</th>\n",
       "      <th>V296</th>\n",
       "      <th>V297</th>\n",
       "      <th>V298</th>\n",
       "      <th>V299</th>\n",
       "      <th>V300</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "      <td>0.080156</td>\n",
       "      <td>0.088501</td>\n",
       "      <td>-0.076703</td>\n",
       "      <td>-0.065645</td>\n",
       "      <td>0.027367</td>\n",
       "      <td>0.060499</td>\n",
       "      <td>0.018841</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>-0.072163</td>\n",
       "      <td>0.044426</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025759</td>\n",
       "      <td>0.030279</td>\n",
       "      <td>0.019642</td>\n",
       "      <td>-0.030535</td>\n",
       "      <td>0.058834</td>\n",
       "      <td>-0.092278</td>\n",
       "      <td>-0.028259</td>\n",
       "      <td>-0.026270</td>\n",
       "      <td>-0.033166</td>\n",
       "      <td>0.061495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>-0.038091</td>\n",
       "      <td>-0.049348</td>\n",
       "      <td>-0.028680</td>\n",
       "      <td>-0.018713</td>\n",
       "      <td>0.063518</td>\n",
       "      <td>0.057007</td>\n",
       "      <td>0.021474</td>\n",
       "      <td>0.084622</td>\n",
       "      <td>-0.108604</td>\n",
       "      <td>-0.092650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004401</td>\n",
       "      <td>0.030320</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>-0.081768</td>\n",
       "      <td>0.011895</td>\n",
       "      <td>0.025118</td>\n",
       "      <td>0.029903</td>\n",
       "      <td>0.029950</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>-0.065045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>-0.061148</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>-0.058344</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>0.039084</td>\n",
       "      <td>0.056894</td>\n",
       "      <td>-0.048181</td>\n",
       "      <td>0.049727</td>\n",
       "      <td>-0.075358</td>\n",
       "      <td>-0.038712</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038889</td>\n",
       "      <td>0.069039</td>\n",
       "      <td>0.018876</td>\n",
       "      <td>-0.050831</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>0.018375</td>\n",
       "      <td>0.052614</td>\n",
       "      <td>0.057787</td>\n",
       "      <td>-0.000694</td>\n",
       "      <td>-0.043442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>-0.099335</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>-0.048134</td>\n",
       "      <td>-0.010280</td>\n",
       "      <td>-0.000963</td>\n",
       "      <td>0.022920</td>\n",
       "      <td>-0.026348</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>-0.068051</td>\n",
       "      <td>-0.049312</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032482</td>\n",
       "      <td>0.063615</td>\n",
       "      <td>-0.020517</td>\n",
       "      <td>-0.017632</td>\n",
       "      <td>0.029572</td>\n",
       "      <td>0.061214</td>\n",
       "      <td>0.075277</td>\n",
       "      <td>0.135811</td>\n",
       "      <td>-0.011819</td>\n",
       "      <td>-0.106832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>-0.092714</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>-0.048257</td>\n",
       "      <td>0.010404</td>\n",
       "      <td>0.047617</td>\n",
       "      <td>0.060156</td>\n",
       "      <td>-0.019659</td>\n",
       "      <td>0.040367</td>\n",
       "      <td>-0.107395</td>\n",
       "      <td>-0.068698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036493</td>\n",
       "      <td>0.109343</td>\n",
       "      <td>-0.000342</td>\n",
       "      <td>-0.072286</td>\n",
       "      <td>0.045893</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.056748</td>\n",
       "      <td>0.037754</td>\n",
       "      <td>-0.022448</td>\n",
       "      <td>-0.029516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            V1        V2        V3        V4        V5        V6        V7  \\\n",
       "word                                                                         \n",
       "</s>  0.080156  0.088501 -0.076703 -0.065645  0.027367  0.060499  0.018841   \n",
       "the  -0.038091 -0.049348 -0.028680 -0.018713  0.063518  0.057007  0.021474   \n",
       "NaN  -0.061148 -0.000166 -0.058344  0.014657  0.039084  0.056894 -0.048181   \n",
       ".    -0.099335  0.001326 -0.048134 -0.010280 -0.000963  0.022920 -0.026348   \n",
       "of   -0.092714  0.016854 -0.048257  0.010404  0.047617  0.060156 -0.019659   \n",
       "\n",
       "            V8        V9       V10  ...      V291      V292      V293  \\\n",
       "word                                ...                                 \n",
       "</s>  0.004232 -0.072163  0.044426  ... -0.025759  0.030279  0.019642   \n",
       "the   0.084622 -0.108604 -0.092650  ...  0.004401  0.030320  0.001037   \n",
       "NaN   0.049727 -0.075358 -0.038712  ... -0.038889  0.069039  0.018876   \n",
       ".     0.010025 -0.068051 -0.049312  ... -0.032482  0.063615 -0.020517   \n",
       "of    0.040367 -0.107395 -0.068698  ... -0.036493  0.109343 -0.000342   \n",
       "\n",
       "          V294      V295      V296      V297      V298      V299      V300  \n",
       "word                                                                        \n",
       "</s> -0.030535  0.058834 -0.092278 -0.028259 -0.026270 -0.033166  0.061495  \n",
       "the  -0.081768  0.011895  0.025118  0.029903  0.029950  0.002812 -0.065045  \n",
       "NaN  -0.050831  0.029056  0.018375  0.052614  0.057787 -0.000694 -0.043442  \n",
       ".    -0.017632  0.029572  0.061214  0.075277  0.135811 -0.011819 -0.106832  \n",
       "of   -0.072286  0.045893  0.002628  0.056748  0.037754 -0.022448 -0.029516  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zb.head() #df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "QI_ecS6dND2X",
    "outputId": "ccd5b625-1066-4d1d-c050-39c81f348d98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inflation'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HhraL6JSND2X",
    "outputId": "fab23ba2-49ed-4acd-f8ad-a84f9401890e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 72096 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {} \n",
    "\n",
    "for i in range(len(words)):\n",
    "    embeddings_index[words[i]]=list_of_columns[i]\n",
    "    \n",
    "\n",
    "#word_column = df['word']\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0IejIYOIXGmo"
   },
   "source": [
    "# Prepare pretrained embeddings for the model and see how many words in our vocabulary are in the pre-trained model.\n",
    "\n",
    "Source:  https://keras.io/examples/nlp/pretrained_word_embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "_Be6537tND2c",
    "outputId": "e64ae5d5-f897-4ca9-a996-f703bf22b5b7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#vocab_size=2000\n",
    "num_tokens = len(range(vocab_size)) + 2\n",
    "embedding_dim = 300 #number of features per word in pre-trained model\n",
    "hits = 0 \n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "        #print(word, end =\"\")\n",
    "        #print(word)\n",
    "#print(\"Converted %d words (%d misses)\" % (hits, misses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "MrPgV4GcND2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "oQdKS4TmND2d"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "modela_zb = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], input_length = max_length, trainable=False),\n",
    "    #tf.keras.layers.Embedding(vocab_size+2,embedding_dim,embeddings_initializer=keras.initializers.Constant(embedding_matrix),input_length=max_length, trainable=False),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "]) # the two embedding statements here do exactly the same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "Hci2jJu8ND2d"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "modela_zb.compile(loss='binary_crossentropy', \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "L31FAi1-ND2e",
    "outputId": "a0416723-e27f-4a0f-fd24-3ef9ab73abf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1200, 300)         1500600   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 300)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 1806      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,502,413\n",
      "Trainable params: 1,813\n",
      "Non-trainable params: 1,500,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modela_zb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "eDWQkWpNND2e",
    "outputId": "e68d8dc3-fb1d-4a39-aa88-404464fb7558"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 1s 52ms/step - loss: 0.6845 - precision: 0.0000e+00 - val_loss: 0.6787 - val_precision: 0.0000e+00\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.6732 - precision: 0.0000e+00 - val_loss: 0.6681 - val_precision: 0.0000e+00\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.6629 - precision: 0.0000e+00 - val_loss: 0.6576 - val_precision: 0.0000e+00\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.6525 - precision: 0.0000e+00 - val_loss: 0.6475 - val_precision: 0.0000e+00\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.6429 - precision: 0.0000e+00 - val_loss: 0.6382 - val_precision: 0.0000e+00\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.6338 - precision: 0.0000e+00 - val_loss: 0.6289 - val_precision: 0.0000e+00\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.6244 - precision: 0.0000e+00 - val_loss: 0.6202 - val_precision: 0.0000e+00\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.6157 - precision: 0.0000e+00 - val_loss: 0.6118 - val_precision: 0.0000e+00\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.6081 - precision: 0.0000e+00 - val_loss: 0.6043 - val_precision: 0.0000e+00\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.6010 - precision: 0.0000e+00 - val_loss: 0.5968 - val_precision: 0.0000e+00\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.5937 - precision: 0.0000e+00 - val_loss: 0.5888 - val_precision: 0.0000e+00\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5864 - precision: 0.0000e+00 - val_loss: 0.5812 - val_precision: 0.0000e+00\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.5792 - precision: 0.0000e+00 - val_loss: 0.5742 - val_precision: 0.0000e+00\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5729 - precision: 0.0000e+00 - val_loss: 0.5676 - val_precision: 0.0000e+00\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5671 - precision: 0.0000e+00 - val_loss: 0.5613 - val_precision: 0.0000e+00\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.5618 - precision: 0.0000e+00 - val_loss: 0.5558 - val_precision: 0.0000e+00\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5571 - precision: 0.0000e+00 - val_loss: 0.5499 - val_precision: 0.0000e+00\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5523 - precision: 0.0000e+00 - val_loss: 0.5442 - val_precision: 0.0000e+00\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.5476 - precision: 0.0000e+00 - val_loss: 0.5399 - val_precision: 0.0000e+00\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5443 - precision: 0.0000e+00 - val_loss: 0.5357 - val_precision: 0.0000e+00\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.5409 - precision: 0.0000e+00 - val_loss: 0.5318 - val_precision: 0.0000e+00\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5379 - precision: 0.0000e+00 - val_loss: 0.5276 - val_precision: 0.0000e+00\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.5346 - precision: 0.0000e+00 - val_loss: 0.5238 - val_precision: 0.0000e+00\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.5320 - precision: 0.0000e+00 - val_loss: 0.5205 - val_precision: 0.0000e+00\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.5300 - precision: 0.0000e+00 - val_loss: 0.5178 - val_precision: 0.0000e+00\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.5284 - precision: 0.0000e+00 - val_loss: 0.5164 - val_precision: 0.0000e+00\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5273 - precision: 0.0000e+00 - val_loss: 0.5147 - val_precision: 0.0000e+00\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.5264 - precision: 0.0000e+00 - val_loss: 0.5123 - val_precision: 0.0000e+00\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.5246 - precision: 0.0000e+00 - val_loss: 0.5101 - val_precision: 0.0000e+00\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.5233 - precision: 0.0000e+00 - val_loss: 0.5089 - val_precision: 0.0000e+00\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5224 - precision: 0.0000e+00 - val_loss: 0.5070 - val_precision: 0.0000e+00\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5211 - precision: 0.0000e+00 - val_loss: 0.5056 - val_precision: 0.0000e+00\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5203 - precision: 0.0000e+00 - val_loss: 0.5044 - val_precision: 0.0000e+00\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.5196 - precision: 0.0000e+00 - val_loss: 0.5031 - val_precision: 0.0000e+00\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5188 - precision: 0.0000e+00 - val_loss: 0.5015 - val_precision: 0.0000e+00\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5181 - precision: 0.0000e+00 - val_loss: 0.5007 - val_precision: 0.0000e+00\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5177 - precision: 0.0000e+00 - val_loss: 0.4995 - val_precision: 0.0000e+00\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5169 - precision: 0.0000e+00 - val_loss: 0.4986 - val_precision: 0.0000e+00\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5165 - precision: 0.0000e+00 - val_loss: 0.4975 - val_precision: 0.0000e+00\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.5160 - precision: 0.0000e+00 - val_loss: 0.4968 - val_precision: 0.0000e+00\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5156 - precision: 0.0000e+00 - val_loss: 0.4956 - val_precision: 0.0000e+00\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.5153 - precision: 0.0000e+00 - val_loss: 0.4948 - val_precision: 0.0000e+00\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5148 - precision: 0.0000e+00 - val_loss: 0.4945 - val_precision: 0.0000e+00\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5145 - precision: 0.0000e+00 - val_loss: 0.4939 - val_precision: 0.0000e+00\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5142 - precision: 0.0000e+00 - val_loss: 0.4933 - val_precision: 0.0000e+00\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.5139 - precision: 0.0000e+00 - val_loss: 0.4925 - val_precision: 0.0000e+00\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.5135 - precision: 0.0000e+00 - val_loss: 0.4917 - val_precision: 0.0000e+00\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.5132 - precision: 0.0000e+00 - val_loss: 0.4912 - val_precision: 0.0000e+00\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5129 - precision: 0.0000e+00 - val_loss: 0.4908 - val_precision: 0.0000e+00\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.5127 - precision: 0.0000e+00 - val_loss: 0.4904 - val_precision: 0.0000e+00\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5124 - precision: 0.0000e+00 - val_loss: 0.4898 - val_precision: 0.0000e+00\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5121 - precision: 0.0000e+00 - val_loss: 0.4892 - val_precision: 0.0000e+00\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5119 - precision: 0.0000e+00 - val_loss: 0.4886 - val_precision: 0.0000e+00\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.5117 - precision: 0.0000e+00 - val_loss: 0.4886 - val_precision: 0.0000e+00\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5116 - precision: 0.0000e+00 - val_loss: 0.4885 - val_precision: 0.0000e+00\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.5115 - precision: 0.0000e+00 - val_loss: 0.4879 - val_precision: 0.0000e+00\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5112 - precision: 0.0000e+00 - val_loss: 0.4876 - val_precision: 0.0000e+00\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5111 - precision: 0.0000e+00 - val_loss: 0.4871 - val_precision: 0.0000e+00\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.5109 - precision: 0.0000e+00 - val_loss: 0.4869 - val_precision: 0.0000e+00\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.5107 - precision: 0.0000e+00 - val_loss: 0.4870 - val_precision: 0.0000e+00\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5106 - precision: 0.0000e+00 - val_loss: 0.4868 - val_precision: 0.0000e+00\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5105 - precision: 0.0000e+00 - val_loss: 0.4866 - val_precision: 0.0000e+00\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5103 - precision: 0.0000e+00 - val_loss: 0.4861 - val_precision: 0.0000e+00\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.5102 - precision: 0.0000e+00 - val_loss: 0.4861 - val_precision: 0.0000e+00\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5100 - precision: 0.0000e+00 - val_loss: 0.4859 - val_precision: 0.0000e+00\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5099 - precision: 0.0000e+00 - val_loss: 0.4858 - val_precision: 0.0000e+00\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5098 - precision: 0.0000e+00 - val_loss: 0.4856 - val_precision: 0.0000e+00\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5097 - precision: 0.0000e+00 - val_loss: 0.4855 - val_precision: 0.0000e+00\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5096 - precision: 0.0000e+00 - val_loss: 0.4850 - val_precision: 0.0000e+00\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.5094 - precision: 0.0000e+00 - val_loss: 0.4850 - val_precision: 0.0000e+00\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5092 - precision: 0.0000e+00 - val_loss: 0.4847 - val_precision: 0.0000e+00\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5092 - precision: 0.0000e+00 - val_loss: 0.4849 - val_precision: 0.0000e+00\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5090 - precision: 0.0000e+00 - val_loss: 0.4845 - val_precision: 0.0000e+00\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.5088 - precision: 0.0000e+00 - val_loss: 0.4840 - val_precision: 0.0000e+00\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.5087 - precision: 0.0000e+00 - val_loss: 0.4835 - val_precision: 0.0000e+00\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.5085 - precision: 0.0000e+00 - val_loss: 0.4834 - val_precision: 0.0000e+00\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.5083 - precision: 0.0000e+00 - val_loss: 0.4838 - val_precision: 0.0000e+00\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.5082 - precision: 0.0000e+00 - val_loss: 0.4836 - val_precision: 0.0000e+00\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5081 - precision: 0.0000e+00 - val_loss: 0.4832 - val_precision: 0.0000e+00\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5082 - precision: 0.0000e+00 - val_loss: 0.4828 - val_precision: 0.0000e+00\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.5079 - precision: 0.0000e+00 - val_loss: 0.4826 - val_precision: 0.0000e+00\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5078 - precision: 0.0000e+00 - val_loss: 0.4825 - val_precision: 0.0000e+00\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.5078 - precision: 0.0000e+00 - val_loss: 0.4826 - val_precision: 0.0000e+00\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5077 - precision: 0.0000e+00 - val_loss: 0.4828 - val_precision: 0.0000e+00\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5075 - precision: 0.0000e+00 - val_loss: 0.4830 - val_precision: 0.0000e+00\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5075 - precision: 0.0000e+00 - val_loss: 0.4828 - val_precision: 0.0000e+00\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5075 - precision: 0.0000e+00 - val_loss: 0.4829 - val_precision: 0.0000e+00\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5073 - precision: 0.0000e+00 - val_loss: 0.4830 - val_precision: 0.0000e+00\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.5073 - precision: 0.0000e+00 - val_loss: 0.4830 - val_precision: 0.0000e+00\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5072 - precision: 0.0000e+00 - val_loss: 0.4831 - val_precision: 0.0000e+00\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5071 - precision: 0.0000e+00 - val_loss: 0.4830 - val_precision: 0.0000e+00\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5070 - precision: 0.0000e+00 - val_loss: 0.4828 - val_precision: 0.0000e+00\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5070 - precision: 0.0000e+00 - val_loss: 0.4827 - val_precision: 0.0000e+00\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.5068 - precision: 0.0000e+00 - val_loss: 0.4824 - val_precision: 0.0000e+00\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5067 - precision: 0.0000e+00 - val_loss: 0.4822 - val_precision: 0.0000e+00\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5066 - precision: 0.0000e+00 - val_loss: 0.4825 - val_precision: 0.0000e+00\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.5065 - precision: 0.0000e+00 - val_loss: 0.4825 - val_precision: 0.0000e+00\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5064 - precision: 0.0000e+00 - val_loss: 0.4824 - val_precision: 0.0000e+00\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.5063 - precision: 0.0000e+00 - val_loss: 0.4820 - val_precision: 0.0000e+00\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5061 - precision: 0.0000e+00 - val_loss: 0.4816 - val_precision: 0.0000e+00\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5059 - precision: 0.0000e+00 - val_loss: 0.4812 - val_precision: 0.0000e+00\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.5058 - precision: 0.0000e+00 - val_loss: 0.4808 - val_precision: 0.0000e+00\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5058 - precision: 0.0000e+00 - val_loss: 0.4804 - val_precision: 0.0000e+00\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5057 - precision: 0.0000e+00 - val_loss: 0.4800 - val_precision: 0.0000e+00\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5056 - precision: 0.0000e+00 - val_loss: 0.4798 - val_precision: 0.0000e+00\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.5055 - precision: 0.0000e+00 - val_loss: 0.4795 - val_precision: 0.0000e+00\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5054 - precision: 0.0000e+00 - val_loss: 0.4794 - val_precision: 0.0000e+00\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5053 - precision: 0.0000e+00 - val_loss: 0.4791 - val_precision: 0.0000e+00\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.5053 - precision: 0.0000e+00 - val_loss: 0.4787 - val_precision: 0.0000e+00\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5053 - precision: 0.0000e+00 - val_loss: 0.4785 - val_precision: 0.0000e+00\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5054 - precision: 0.0000e+00 - val_loss: 0.4787 - val_precision: 0.0000e+00\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.5050 - precision: 0.0000e+00 - val_loss: 0.4785 - val_precision: 0.0000e+00\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5048 - precision: 0.0000e+00 - val_loss: 0.4786 - val_precision: 0.0000e+00\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.5048 - precision: 0.0000e+00 - val_loss: 0.4788 - val_precision: 0.0000e+00\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5046 - precision: 0.0000e+00 - val_loss: 0.4788 - val_precision: 0.0000e+00\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5045 - precision: 0.0000e+00 - val_loss: 0.4788 - val_precision: 0.0000e+00\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.5043 - precision: 0.0000e+00 - val_loss: 0.4790 - val_precision: 0.0000e+00\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5044 - precision: 0.0000e+00 - val_loss: 0.4788 - val_precision: 0.0000e+00\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5042 - precision: 0.0000e+00 - val_loss: 0.4788 - val_precision: 0.0000e+00\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5041 - precision: 0.0000e+00 - val_loss: 0.4789 - val_precision: 0.0000e+00\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5040 - precision: 0.0000e+00 - val_loss: 0.4789 - val_precision: 0.0000e+00\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5040 - precision: 0.0000e+00 - val_loss: 0.4790 - val_precision: 0.0000e+00\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5039 - precision: 0.0000e+00 - val_loss: 0.4789 - val_precision: 0.0000e+00\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5038 - precision: 0.0000e+00 - val_loss: 0.4786 - val_precision: 0.0000e+00\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5039 - precision: 0.0000e+00 - val_loss: 0.4782 - val_precision: 0.0000e+00\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5036 - precision: 0.0000e+00 - val_loss: 0.4785 - val_precision: 0.0000e+00\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5035 - precision: 0.0000e+00 - val_loss: 0.4785 - val_precision: 0.0000e+00\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5035 - precision: 0.0000e+00 - val_loss: 0.4788 - val_precision: 0.0000e+00\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5034 - precision: 0.0000e+00 - val_loss: 0.4789 - val_precision: 0.0000e+00\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5033 - precision: 0.0000e+00 - val_loss: 0.4788 - val_precision: 0.0000e+00\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5032 - precision: 0.0000e+00 - val_loss: 0.4785 - val_precision: 0.0000e+00\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5031 - precision: 0.0000e+00 - val_loss: 0.4780 - val_precision: 0.0000e+00\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5030 - precision: 0.0000e+00 - val_loss: 0.4780 - val_precision: 0.0000e+00\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5029 - precision: 0.0000e+00 - val_loss: 0.4781 - val_precision: 0.0000e+00\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5029 - precision: 0.0000e+00 - val_loss: 0.4777 - val_precision: 0.0000e+00\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5027 - precision: 0.0000e+00 - val_loss: 0.4775 - val_precision: 0.0000e+00\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.5026 - precision: 0.0000e+00 - val_loss: 0.4773 - val_precision: 0.0000e+00\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5026 - precision: 0.0000e+00 - val_loss: 0.4774 - val_precision: 0.0000e+00\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5025 - precision: 0.0000e+00 - val_loss: 0.4771 - val_precision: 0.0000e+00\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5023 - precision: 0.0000e+00 - val_loss: 0.4768 - val_precision: 0.0000e+00\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5023 - precision: 0.0000e+00 - val_loss: 0.4768 - val_precision: 0.0000e+00\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5022 - precision: 0.0000e+00 - val_loss: 0.4768 - val_precision: 0.0000e+00\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5022 - precision: 0.0000e+00 - val_loss: 0.4768 - val_precision: 0.0000e+00\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5021 - precision: 0.0000e+00 - val_loss: 0.4765 - val_precision: 0.0000e+00\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5020 - precision: 0.0000e+00 - val_loss: 0.4763 - val_precision: 0.0000e+00\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.5020 - precision: 0.0000e+00 - val_loss: 0.4760 - val_precision: 0.0000e+00\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5019 - precision: 0.0000e+00 - val_loss: 0.4760 - val_precision: 0.0000e+00\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5018 - precision: 0.0000e+00 - val_loss: 0.4760 - val_precision: 0.0000e+00\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5018 - precision: 0.0000e+00 - val_loss: 0.4760 - val_precision: 0.0000e+00\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5016 - precision: 0.0000e+00 - val_loss: 0.4758 - val_precision: 0.0000e+00\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5015 - precision: 0.0000e+00 - val_loss: 0.4759 - val_precision: 0.0000e+00\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5015 - precision: 0.0000e+00 - val_loss: 0.4760 - val_precision: 0.0000e+00\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5014 - precision: 0.0000e+00 - val_loss: 0.4763 - val_precision: 0.0000e+00\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5014 - precision: 0.0000e+00 - val_loss: 0.4761 - val_precision: 0.0000e+00\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5013 - precision: 0.0000e+00 - val_loss: 0.4764 - val_precision: 0.0000e+00\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5013 - precision: 0.0000e+00 - val_loss: 0.4763 - val_precision: 0.0000e+00\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5012 - precision: 0.0000e+00 - val_loss: 0.4761 - val_precision: 0.0000e+00\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.5011 - precision: 0.0000e+00 - val_loss: 0.4762 - val_precision: 0.0000e+00\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5011 - precision: 0.0000e+00 - val_loss: 0.4761 - val_precision: 0.0000e+00\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5009 - precision: 0.0000e+00 - val_loss: 0.4755 - val_precision: 0.0000e+00\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5009 - precision: 0.0000e+00 - val_loss: 0.4750 - val_precision: 0.0000e+00\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5009 - precision: 0.0000e+00 - val_loss: 0.4748 - val_precision: 0.0000e+00\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5008 - precision: 0.0000e+00 - val_loss: 0.4745 - val_precision: 0.0000e+00\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5007 - precision: 0.0000e+00 - val_loss: 0.4744 - val_precision: 0.0000e+00\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5007 - precision: 0.0000e+00 - val_loss: 0.4742 - val_precision: 0.0000e+00\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5007 - precision: 0.0000e+00 - val_loss: 0.4740 - val_precision: 0.0000e+00\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5006 - precision: 0.0000e+00 - val_loss: 0.4741 - val_precision: 0.0000e+00\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5006 - precision: 0.0000e+00 - val_loss: 0.4739 - val_precision: 0.0000e+00\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.5005 - precision: 0.0000e+00 - val_loss: 0.4737 - val_precision: 0.0000e+00\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5005 - precision: 0.0000e+00 - val_loss: 0.4735 - val_precision: 0.0000e+00\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.5004 - precision: 0.0000e+00 - val_loss: 0.4735 - val_precision: 0.0000e+00\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.5003 - precision: 0.0000e+00 - val_loss: 0.4733 - val_precision: 0.0000e+00\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.5003 - precision: 0.0000e+00 - val_loss: 0.4733 - val_precision: 0.0000e+00\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.5003 - precision: 0.0000e+00 - val_loss: 0.4731 - val_precision: 0.0000e+00\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.5003 - precision: 0.0000e+00 - val_loss: 0.4730 - val_precision: 0.0000e+00\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5003 - precision: 0.0000e+00 - val_loss: 0.4729 - val_precision: 0.0000e+00\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5002 - precision: 0.0000e+00 - val_loss: 0.4729 - val_precision: 0.0000e+00\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.5002 - precision: 0.0000e+00 - val_loss: 0.4728 - val_precision: 0.0000e+00\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5002 - precision: 0.0000e+00 - val_loss: 0.4727 - val_precision: 0.0000e+00\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.5001 - precision: 0.0000e+00 - val_loss: 0.4727 - val_precision: 0.0000e+00\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5001 - precision: 0.0000e+00 - val_loss: 0.4725 - val_precision: 0.0000e+00\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5003 - precision: 0.0000e+00 - val_loss: 0.4723 - val_precision: 0.0000e+00\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5001 - precision: 0.0000e+00 - val_loss: 0.4722 - val_precision: 0.0000e+00\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5000 - precision: 0.0000e+00 - val_loss: 0.4721 - val_precision: 0.0000e+00\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.5000 - precision: 0.0000e+00 - val_loss: 0.4721 - val_precision: 0.0000e+00\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4998 - precision: 0.0000e+00 - val_loss: 0.4722 - val_precision: 0.0000e+00\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.5003 - precision: 0.0000e+00 - val_loss: 0.4730 - val_precision: 0.0000e+00\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.4993 - precision: 0.0000e+00 - val_loss: 0.4730 - val_precision: 0.0000e+00\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4992 - precision: 0.0000e+00 - val_loss: 0.4731 - val_precision: 0.0000e+00\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.4993 - precision: 0.0000e+00 - val_loss: 0.4728 - val_precision: 0.0000e+00\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4991 - precision: 0.0000e+00 - val_loss: 0.4729 - val_precision: 0.0000e+00\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.4989 - precision: 0.0000e+00 - val_loss: 0.4731 - val_precision: 0.0000e+00\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4988 - precision: 0.0000e+00 - val_loss: 0.4733 - val_precision: 0.0000e+00\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.4988 - precision: 0.0000e+00 - val_loss: 0.4732 - val_precision: 0.0000e+00\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4988 - precision: 0.0000e+00 - val_loss: 0.4730 - val_precision: 0.0000e+00\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4987 - precision: 0.0000e+00 - val_loss: 0.4732 - val_precision: 0.0000e+00\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4989 - precision: 0.0000e+00 - val_loss: 0.4736 - val_precision: 0.0000e+00\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4986 - precision: 0.0000e+00 - val_loss: 0.4734 - val_precision: 0.0000e+00\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4985 - precision: 0.0000e+00 - val_loss: 0.4731 - val_precision: 0.0000e+00\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4985 - precision: 0.0000e+00 - val_loss: 0.4730 - val_precision: 0.0000e+00\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.4986 - precision: 0.0000e+00 - val_loss: 0.4733 - val_precision: 0.0000e+00\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4984 - precision: 0.0000e+00 - val_loss: 0.4732 - val_precision: 0.0000e+00\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4983 - precision: 0.0000e+00 - val_loss: 0.4733 - val_precision: 0.0000e+00\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.4983 - precision: 0.0000e+00 - val_loss: 0.4736 - val_precision: 0.0000e+00\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4982 - precision: 0.0000e+00 - val_loss: 0.4739 - val_precision: 0.0000e+00\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4982 - precision: 0.0000e+00 - val_loss: 0.4738 - val_precision: 0.0000e+00\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4984 - precision: 0.0000e+00 - val_loss: 0.4733 - val_precision: 0.0000e+00\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4980 - precision: 0.0000e+00 - val_loss: 0.4732 - val_precision: 0.0000e+00\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.4981 - precision: 0.0000e+00 - val_loss: 0.4735 - val_precision: 0.0000e+00\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.4982 - precision: 0.0000e+00 - val_loss: 0.4730 - val_precision: 0.0000e+00\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4979 - precision: 0.0000e+00 - val_loss: 0.4729 - val_precision: 0.0000e+00\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4978 - precision: 0.0000e+00 - val_loss: 0.4727 - val_precision: 0.0000e+00\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4980 - precision: 0.0000e+00 - val_loss: 0.4732 - val_precision: 0.0000e+00\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4976 - precision: 0.0000e+00 - val_loss: 0.4734 - val_precision: 0.0000e+00\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4977 - precision: 0.0000e+00 - val_loss: 0.4732 - val_precision: 0.0000e+00\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4975 - precision: 0.0000e+00 - val_loss: 0.4727 - val_precision: 0.0000e+00\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4975 - precision: 0.0000e+00 - val_loss: 0.4725 - val_precision: 0.0000e+00\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4974 - precision: 0.0000e+00 - val_loss: 0.4722 - val_precision: 0.0000e+00\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4976 - precision: 0.0000e+00 - val_loss: 0.4725 - val_precision: 0.0000e+00\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.4973 - precision: 0.0000e+00 - val_loss: 0.4723 - val_precision: 0.0000e+00\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4972 - precision: 0.0000e+00 - val_loss: 0.4721 - val_precision: 0.0000e+00\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.4973 - precision: 0.0000e+00 - val_loss: 0.4718 - val_precision: 0.0000e+00\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4970 - precision: 0.0000e+00 - val_loss: 0.4719 - val_precision: 0.0000e+00\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4971 - precision: 0.0000e+00 - val_loss: 0.4720 - val_precision: 0.0000e+00\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4970 - precision: 0.0000e+00 - val_loss: 0.4718 - val_precision: 0.0000e+00\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4969 - precision: 0.0000e+00 - val_loss: 0.4714 - val_precision: 0.0000e+00\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4969 - precision: 0.0000e+00 - val_loss: 0.4710 - val_precision: 0.0000e+00\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4969 - precision: 0.0000e+00 - val_loss: 0.4708 - val_precision: 0.0000e+00\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.4968 - precision: 0.0000e+00 - val_loss: 0.4708 - val_precision: 0.0000e+00\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4968 - precision: 0.0000e+00 - val_loss: 0.4707 - val_precision: 0.0000e+00\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4968 - precision: 0.0000e+00 - val_loss: 0.4708 - val_precision: 0.0000e+00\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4967 - precision: 0.0000e+00 - val_loss: 0.4706 - val_precision: 0.0000e+00\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.4966 - precision: 0.0000e+00 - val_loss: 0.4705 - val_precision: 0.0000e+00\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.4967 - precision: 0.0000e+00 - val_loss: 0.4703 - val_precision: 0.0000e+00\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4966 - precision: 0.0000e+00 - val_loss: 0.4703 - val_precision: 0.0000e+00\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4966 - precision: 0.0000e+00 - val_loss: 0.4701 - val_precision: 0.0000e+00\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4965 - precision: 0.0000e+00 - val_loss: 0.4701 - val_precision: 0.0000e+00\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4964 - precision: 0.0000e+00 - val_loss: 0.4702 - val_precision: 0.0000e+00\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.4963 - precision: 0.0000e+00 - val_loss: 0.4701 - val_precision: 0.0000e+00\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4965 - precision: 0.0000e+00 - val_loss: 0.4698 - val_precision: 0.0000e+00\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4963 - precision: 0.0000e+00 - val_loss: 0.4701 - val_precision: 0.0000e+00\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4962 - precision: 0.0000e+00 - val_loss: 0.4701 - val_precision: 0.0000e+00\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4960 - precision: 0.0000e+00 - val_loss: 0.4705 - val_precision: 0.0000e+00\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4960 - precision: 0.0000e+00 - val_loss: 0.4708 - val_precision: 0.0000e+00\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4959 - precision: 0.0000e+00 - val_loss: 0.4709 - val_precision: 0.0000e+00\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4959 - precision: 0.0000e+00 - val_loss: 0.4711 - val_precision: 0.0000e+00\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4958 - precision: 0.0000e+00 - val_loss: 0.4711 - val_precision: 0.0000e+00\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4958 - precision: 0.0000e+00 - val_loss: 0.4708 - val_precision: 0.0000e+00\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4957 - precision: 0.0000e+00 - val_loss: 0.4707 - val_precision: 0.0000e+00\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4956 - precision: 0.0000e+00 - val_loss: 0.4704 - val_precision: 0.0000e+00\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4956 - precision: 0.0000e+00 - val_loss: 0.4699 - val_precision: 0.0000e+00\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4958 - precision: 0.0000e+00 - val_loss: 0.4695 - val_precision: 0.0000e+00\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.4956 - precision: 0.0000e+00 - val_loss: 0.4695 - val_precision: 0.0000e+00\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4955 - precision: 0.0000e+00 - val_loss: 0.4694 - val_precision: 0.0000e+00\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.4954 - precision: 0.0000e+00 - val_loss: 0.4695 - val_precision: 0.0000e+00\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.4954 - precision: 0.0000e+00 - val_loss: 0.4697 - val_precision: 0.0000e+00\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.4953 - precision: 0.0000e+00 - val_loss: 0.4697 - val_precision: 0.0000e+00\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.4952 - precision: 0.0000e+00 - val_loss: 0.4699 - val_precision: 0.0000e+00\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4951 - precision: 0.0000e+00 - val_loss: 0.4700 - val_precision: 0.0000e+00\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4950 - precision: 0.0000e+00 - val_loss: 0.4705 - val_precision: 0.0000e+00\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4950 - precision: 0.0000e+00 - val_loss: 0.4704 - val_precision: 0.0000e+00\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4949 - precision: 0.0000e+00 - val_loss: 0.4703 - val_precision: 0.0000e+00\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4949 - precision: 0.0000e+00 - val_loss: 0.4704 - val_precision: 0.0000e+00\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.4948 - precision: 0.0000e+00 - val_loss: 0.4701 - val_precision: 0.0000e+00\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.4947 - precision: 0.0000e+00 - val_loss: 0.4700 - val_precision: 0.0000e+00\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.4948 - precision: 0.0000e+00 - val_loss: 0.4697 - val_precision: 0.0000e+00\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.4946 - precision: 0.0000e+00 - val_loss: 0.4694 - val_precision: 0.0000e+00\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4947 - precision: 0.0000e+00 - val_loss: 0.4692 - val_precision: 0.0000e+00\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4947 - precision: 0.0000e+00 - val_loss: 0.4689 - val_precision: 0.0000e+00\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4945 - precision: 0.0000e+00 - val_loss: 0.4687 - val_precision: 0.0000e+00\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4945 - precision: 0.0000e+00 - val_loss: 0.4685 - val_precision: 0.0000e+00\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4945 - precision: 0.0000e+00 - val_loss: 0.4686 - val_precision: 0.0000e+00\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4944 - precision: 0.0000e+00 - val_loss: 0.4685 - val_precision: 0.0000e+00\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4945 - precision: 0.0000e+00 - val_loss: 0.4683 - val_precision: 0.0000e+00\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.4943 - precision: 0.0000e+00 - val_loss: 0.4687 - val_precision: 0.0000e+00\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.4941 - precision: 0.0000e+00 - val_loss: 0.4692 - val_precision: 0.0000e+00\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.4939 - precision: 0.0000e+00 - val_loss: 0.4695 - val_precision: 0.0000e+00\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4942 - precision: 0.0000e+00 - val_loss: 0.4700 - val_precision: 0.0000e+00\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4939 - precision: 0.0000e+00 - val_loss: 0.4701 - val_precision: 0.0000e+00\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4939 - precision: 0.0000e+00 - val_loss: 0.4705 - val_precision: 0.0000e+00\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.4940 - precision: 0.0000e+00 - val_loss: 0.4705 - val_precision: 0.0000e+00\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.4939 - precision: 0.0000e+00 - val_loss: 0.4704 - val_precision: 0.0000e+00\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.4938 - precision: 0.0000e+00 - val_loss: 0.4703 - val_precision: 0.0000e+00\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.4938 - precision: 0.0000e+00 - val_loss: 0.4696 - val_precision: 0.0000e+00\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4935 - precision: 0.0000e+00 - val_loss: 0.4694 - val_precision: 0.0000e+00\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.4934 - precision: 0.0000e+00 - val_loss: 0.4691 - val_precision: 0.0000e+00\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.4934 - precision: 0.0000e+00 - val_loss: 0.4690 - val_precision: 0.0000e+00\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.4933 - precision: 0.0000e+00 - val_loss: 0.4689 - val_precision: 0.0000e+00\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4933 - precision: 0.0000e+00 - val_loss: 0.4688 - val_precision: 0.0000e+00\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4931 - precision: 0.0000e+00 - val_loss: 0.4687 - val_precision: 0.0000e+00\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.4931 - precision: 0.0000e+00 - val_loss: 0.4685 - val_precision: 0.0000e+00\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.4931 - precision: 0.0000e+00 - val_loss: 0.4689 - val_precision: 0.0000e+00\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4929 - precision: 0.0000e+00 - val_loss: 0.4691 - val_precision: 0.0000e+00\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4929 - precision: 0.0000e+00 - val_loss: 0.4692 - val_precision: 0.0000e+00\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.4929 - precision: 0.0000e+00 - val_loss: 0.4692 - val_precision: 0.0000e+00\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.4928 - precision: 0.0000e+00 - val_loss: 0.4691 - val_precision: 0.0000e+00\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4927 - precision: 0.0000e+00 - val_loss: 0.4687 - val_precision: 0.0000e+00\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.4927 - precision: 0.0000e+00 - val_loss: 0.4686 - val_precision: 0.0000e+00\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4927 - precision: 0.0000e+00 - val_loss: 0.4683 - val_precision: 0.0000e+00\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.4925 - precision: 0.0000e+00 - val_loss: 0.4681 - val_precision: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300\n",
    "history = modela_zb.fit(padded, training_labels_final, \n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(val_padded, val_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "EcgW_tGkND2e",
    "outputId": "0a03b457-f792-4def-ecad-b7d5d30d0ab2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "precision = history.history['precision']\n",
    "val_precision = history.history['val_precision']\n",
    "epochs=range(len(precision))\n",
    "plt.plot(epochs, precision, 'r')\n",
    "plt.plot(epochs, val_precision, 'b')\n",
    "plt.title('Training and validation Precision')\n",
    "plt.ylim((0,1.5))\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "b4Wzq8OXND2h",
    "outputId": "9f67441b-f341-4d0d-ed1c-9b0acdd9cc3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5362 - precision: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.536246657371521, 0.0]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modela_zb.evaluate(test_padded, test_labels_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mymobnWsND2n"
   },
   "source": [
    "### Model B with the Z&B embeddings\n",
    "\n",
    "Adds a conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "LDCmEmpnND2n"
   },
   "outputs": [],
   "source": [
    "\n",
    "modelb_zb = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], input_length = max_length, trainable=False),\n",
    "    tf.keras.layers.Conv1D(128, 5, activation=\"relu\"),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "n99gc3pzND2o"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "modelb_zb.compile(loss='binary_crossentropy', \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "13YrvnoYND2o",
    "outputId": "e5c0778c-a58e-47b6-b0c7-9c94a5c43baa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1200, 300)         1500600   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 1196, 128)         192128    \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 774       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,693,509\n",
      "Trainable params: 192,909\n",
      "Non-trainable params: 1,500,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelb_zb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "avKnzHzRND2o",
    "outputId": "1c0de298-908e-4c08-99e4-36d0d3499873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.6614 - precision: 0.0000e+00 - val_loss: 0.6196 - val_precision: 0.0000e+00\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 1s 165ms/step - loss: 0.5872 - precision: 0.0000e+00 - val_loss: 0.5616 - val_precision: 0.0000e+00\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 2s 205ms/step - loss: 0.5509 - precision: 0.0000e+00 - val_loss: 0.5328 - val_precision: 0.0000e+00\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 0.5433 - precision: 0.0000e+00 - val_loss: 0.5231 - val_precision: 0.0000e+00\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 2s 205ms/step - loss: 0.5447 - precision: 0.0000e+00 - val_loss: 0.5195 - val_precision: 0.0000e+00\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 2s 185ms/step - loss: 0.5380 - precision: 0.0000e+00 - val_loss: 0.5179 - val_precision: 0.0000e+00\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 2s 190ms/step - loss: 0.5338 - precision: 0.0000e+00 - val_loss: 0.5193 - val_precision: 0.0000e+00\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 2s 188ms/step - loss: 0.5315 - precision: 0.0000e+00 - val_loss: 0.5185 - val_precision: 0.0000e+00\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 2s 188ms/step - loss: 0.5288 - precision: 0.0000e+00 - val_loss: 0.5170 - val_precision: 0.0000e+00\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 2s 183ms/step - loss: 0.5267 - precision: 0.0000e+00 - val_loss: 0.5138 - val_precision: 0.0000e+00\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 2s 192ms/step - loss: 0.5230 - precision: 0.0000e+00 - val_loss: 0.5051 - val_precision: 0.0000e+00\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 2s 200ms/step - loss: 0.5199 - precision: 0.0000e+00 - val_loss: 0.5010 - val_precision: 0.0000e+00\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 2s 205ms/step - loss: 0.5171 - precision: 0.0000e+00 - val_loss: 0.4986 - val_precision: 0.0000e+00\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 2s 223ms/step - loss: 0.5139 - precision: 0.0000e+00 - val_loss: 0.4957 - val_precision: 0.0000e+00\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 2s 190ms/step - loss: 0.5113 - precision: 0.0000e+00 - val_loss: 0.4921 - val_precision: 0.0000e+00\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 2s 188ms/step - loss: 0.5086 - precision: 0.0000e+00 - val_loss: 0.4915 - val_precision: 0.0000e+00\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 2s 184ms/step - loss: 0.5062 - precision: 0.0000e+00 - val_loss: 0.4852 - val_precision: 0.0000e+00\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 2s 193ms/step - loss: 0.5046 - precision: 0.0000e+00 - val_loss: 0.4801 - val_precision: 0.0000e+00\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 2s 173ms/step - loss: 0.5010 - precision: 0.0000e+00 - val_loss: 0.4844 - val_precision: 0.0000e+00\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 2s 191ms/step - loss: 0.4995 - precision: 0.0000e+00 - val_loss: 0.4820 - val_precision: 0.0000e+00\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 2s 194ms/step - loss: 0.4955 - precision: 0.0000e+00 - val_loss: 0.4743 - val_precision: 0.0000e+00\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 2s 213ms/step - loss: 0.4936 - precision: 0.0000e+00 - val_loss: 0.4687 - val_precision: 0.0000e+00\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.4944 - precision: 0.0000e+00 - val_loss: 0.4672 - val_precision: 0.0000e+00\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 2s 208ms/step - loss: 0.4902 - precision: 0.0000e+00 - val_loss: 0.4680 - val_precision: 0.0000e+00\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 2s 198ms/step - loss: 0.4879 - precision: 0.0000e+00 - val_loss: 0.4706 - val_precision: 0.0000e+00\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.4926 - precision: 0.0000e+00 - val_loss: 0.4860 - val_precision: 0.0000e+00\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 2s 194ms/step - loss: 0.4968 - precision: 0.0000e+00 - val_loss: 0.4746 - val_precision: 0.0000e+00\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 2s 185ms/step - loss: 0.4912 - precision: 0.0000e+00 - val_loss: 0.4618 - val_precision: 0.0000e+00\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 2s 189ms/step - loss: 0.4902 - precision: 0.0000e+00 - val_loss: 0.4605 - val_precision: 0.0000e+00\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 2s 217ms/step - loss: 0.4855 - precision: 0.0000e+00 - val_loss: 0.4686 - val_precision: 0.0000e+00\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 2s 223ms/step - loss: 0.4857 - precision: 0.0000e+00 - val_loss: 0.4645 - val_precision: 0.0000e+00\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 2s 221ms/step - loss: 0.4823 - precision: 0.0000e+00 - val_loss: 0.4615 - val_precision: 0.0000e+00\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 2s 191ms/step - loss: 0.4821 - precision: 0.0000e+00 - val_loss: 0.4619 - val_precision: 0.0000e+00\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 2s 204ms/step - loss: 0.4813 - precision: 0.0000e+00 - val_loss: 0.4602 - val_precision: 0.0000e+00\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 2s 175ms/step - loss: 0.4808 - precision: 0.0000e+00 - val_loss: 0.4581 - val_precision: 0.0000e+00\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 2s 213ms/step - loss: 0.4809 - precision: 0.0000e+00 - val_loss: 0.4617 - val_precision: 0.0000e+00\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 2s 192ms/step - loss: 0.4795 - precision: 0.0000e+00 - val_loss: 0.4600 - val_precision: 0.0000e+00\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 2s 204ms/step - loss: 0.4795 - precision: 0.0000e+00 - val_loss: 0.4587 - val_precision: 0.0000e+00\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 2s 221ms/step - loss: 0.4779 - precision: 0.0000e+00 - val_loss: 0.4566 - val_precision: 0.0000e+00\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 2s 225ms/step - loss: 0.4785 - precision: 0.0000e+00 - val_loss: 0.4589 - val_precision: 0.0000e+00\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 2s 229ms/step - loss: 0.4764 - precision: 0.0000e+00 - val_loss: 0.4551 - val_precision: 0.0000e+00\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 2s 202ms/step - loss: 0.4760 - precision: 0.0000e+00 - val_loss: 0.4558 - val_precision: 0.0000e+00\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 2s 196ms/step - loss: 0.4753 - precision: 0.0000e+00 - val_loss: 0.4617 - val_precision: 0.0000e+00\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 2s 213ms/step - loss: 0.4743 - precision: 0.0000e+00 - val_loss: 0.4559 - val_precision: 0.0000e+00\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 2s 214ms/step - loss: 0.4721 - precision: 0.0000e+00 - val_loss: 0.4533 - val_precision: 0.0000e+00\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 2s 204ms/step - loss: 0.4718 - precision: 0.0000e+00 - val_loss: 0.4514 - val_precision: 0.0000e+00\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 2s 197ms/step - loss: 0.4714 - precision: 0.0000e+00 - val_loss: 0.4521 - val_precision: 0.0000e+00\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 2s 205ms/step - loss: 0.4695 - precision: 0.0000e+00 - val_loss: 0.4525 - val_precision: 0.0000e+00\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 0.4679 - precision: 0.0000e+00 - val_loss: 0.4527 - val_precision: 0.0000e+00\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.4675 - precision: 0.0000e+00 - val_loss: 0.4519 - val_precision: 0.0000e+00\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 2s 185ms/step - loss: 0.4667 - precision: 0.0000e+00 - val_loss: 0.4468 - val_precision: 0.0000e+00\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 2s 199ms/step - loss: 0.4655 - precision: 0.0000e+00 - val_loss: 0.4469 - val_precision: 0.0000e+00\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 0.4643 - precision: 0.0000e+00 - val_loss: 0.4461 - val_precision: 0.0000e+00\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 2s 261ms/step - loss: 0.4639 - precision: 0.0000e+00 - val_loss: 0.4557 - val_precision: 0.0000e+00\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 2s 251ms/step - loss: 0.4595 - precision: 0.0000e+00 - val_loss: 0.4444 - val_precision: 0.0000e+00\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 2s 269ms/step - loss: 0.4654 - precision: 0.0000e+00 - val_loss: 0.4421 - val_precision: 0.0000e+00\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 2s 246ms/step - loss: 0.4611 - precision: 0.0000e+00 - val_loss: 0.4460 - val_precision: 0.0000e+00\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 2s 269ms/step - loss: 0.4567 - precision: 0.0000e+00 - val_loss: 0.4462 - val_precision: 0.0000e+00\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 0.4559 - precision: 0.0000e+00 - val_loss: 0.4445 - val_precision: 0.0000e+00\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 2s 237ms/step - loss: 0.4561 - precision: 0.0000e+00 - val_loss: 0.4561 - val_precision: 0.0000e+00\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 2s 226ms/step - loss: 0.4533 - precision: 0.0000e+00 - val_loss: 0.4400 - val_precision: 0.0000e+00\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 2s 211ms/step - loss: 0.4503 - precision: 0.0000e+00 - val_loss: 0.4374 - val_precision: 0.0000e+00\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 2s 205ms/step - loss: 0.4542 - precision: 0.0000e+00 - val_loss: 0.4338 - val_precision: 0.0000e+00\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 2s 255ms/step - loss: 0.4518 - precision: 0.0000e+00 - val_loss: 0.4510 - val_precision: 0.0000e+00\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 2s 253ms/step - loss: 0.4481 - precision: 0.0000e+00 - val_loss: 0.4339 - val_precision: 0.0000e+00\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 2s 235ms/step - loss: 0.4421 - precision: 0.0000e+00 - val_loss: 0.4398 - val_precision: 0.0000e+00\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.4412 - precision: 0.0000e+00 - val_loss: 0.4366 - val_precision: 0.0000e+00\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 2s 213ms/step - loss: 0.4395 - precision: 0.0000e+00 - val_loss: 0.4362 - val_precision: 0.0000e+00\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 2s 230ms/step - loss: 0.4397 - precision: 0.0000e+00 - val_loss: 0.4295 - val_precision: 0.0000e+00\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 2s 226ms/step - loss: 0.4416 - precision: 0.0000e+00 - val_loss: 0.4389 - val_precision: 0.0000e+00\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 2s 268ms/step - loss: 0.4337 - precision: 0.0000e+00 - val_loss: 0.4267 - val_precision: 0.0000e+00\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 3s 273ms/step - loss: 0.4380 - precision: 0.7500 - val_loss: 0.4382 - val_precision: 0.0000e+00\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 2s 261ms/step - loss: 0.4371 - precision: 1.0000 - val_loss: 0.4236 - val_precision: 0.0000e+00\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.4325 - precision: 0.0000e+00 - val_loss: 0.4297 - val_precision: 0.0000e+00\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 2s 215ms/step - loss: 0.4273 - precision: 1.0000 - val_loss: 0.4289 - val_precision: 0.0000e+00\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 2s 233ms/step - loss: 0.4269 - precision: 1.0000 - val_loss: 0.4351 - val_precision: 1.0000\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 0.4308 - precision: 0.8571 - val_loss: 0.4295 - val_precision: 1.0000\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 2s 233ms/step - loss: 0.4255 - precision: 1.0000 - val_loss: 0.4193 - val_precision: 0.0000e+00\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 2s 224ms/step - loss: 0.4317 - precision: 0.0000e+00 - val_loss: 0.4197 - val_precision: 0.0000e+00\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 2s 227ms/step - loss: 0.4164 - precision: 1.0000 - val_loss: 0.4372 - val_precision: 1.0000\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 2s 217ms/step - loss: 0.4226 - precision: 0.8000 - val_loss: 0.4214 - val_precision: 1.0000\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 2s 212ms/step - loss: 0.4265 - precision: 0.7500 - val_loss: 0.4206 - val_precision: 1.0000\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 2s 213ms/step - loss: 0.4233 - precision: 0.7857 - val_loss: 0.4355 - val_precision: 1.0000\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 2s 214ms/step - loss: 0.4151 - precision: 0.8750 - val_loss: 0.4184 - val_precision: 1.0000\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 2s 193ms/step - loss: 0.4188 - precision: 1.0000 - val_loss: 0.4228 - val_precision: 1.0000\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.4137 - precision: 0.9286 - val_loss: 0.4284 - val_precision: 0.8000\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 2s 230ms/step - loss: 0.4166 - precision: 0.8235 - val_loss: 0.4242 - val_precision: 1.0000\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 3s 290ms/step - loss: 0.4124 - precision: 0.8750 - val_loss: 0.4268 - val_precision: 0.8000\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 2s 249ms/step - loss: 0.4111 - precision: 0.8667 - val_loss: 0.4174 - val_precision: 1.0000\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 2s 238ms/step - loss: 0.4079 - precision: 0.8667 - val_loss: 0.4271 - val_precision: 0.8000\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 2s 231ms/step - loss: 0.4085 - precision: 0.8824 - val_loss: 0.4181 - val_precision: 0.8000\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.4065 - precision: 0.8667 - val_loss: 0.4183 - val_precision: 0.8000\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 2s 214ms/step - loss: 0.4153 - precision: 0.7826 - val_loss: 0.4139 - val_precision: 0.8000\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.4153 - precision: 1.0000 - val_loss: 0.4089 - val_precision: 1.0000\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 2s 250ms/step - loss: 0.3978 - precision: 0.8750 - val_loss: 0.4375 - val_precision: 0.5455\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.4082 - precision: 0.7692 - val_loss: 0.4147 - val_precision: 0.8000\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 2s 223ms/step - loss: 0.3997 - precision: 0.8824 - val_loss: 0.4128 - val_precision: 0.8000\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 2s 223ms/step - loss: 0.3991 - precision: 0.8750 - val_loss: 0.4126 - val_precision: 0.8000\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.3989 - precision: 0.8824 - val_loss: 0.4115 - val_precision: 0.8000\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 2s 222ms/step - loss: 0.4007 - precision: 0.7500 - val_loss: 0.4108 - val_precision: 0.8000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100 \n",
    "history = modelb_zb.fit(padded, training_labels_final, \n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(val_padded, val_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "B5Dqph9aND2p",
    "outputId": "9acfa2e2-868a-41f9-fa0a-b2ed4edd2ee1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "precision = history.history['precision']\n",
    "val_precision = history.history['val_precision']\n",
    "epochs=range(len(precision))\n",
    "plt.plot(epochs, precision, 'r')\n",
    "plt.plot(epochs, val_precision, 'b')\n",
    "plt.title('Training and validation Precision')\n",
    "plt.ylim((0,1.5))\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "Bo7PpA5jND2p",
    "outputId": "29b58a0f-1951-4227-a07f-69a3c1b2e720"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 65ms/step - loss: 0.5157 - precision: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.515688955783844, 0.8333333134651184]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelb_zb.evaluate(test_padded, test_labels_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3mtKEPMA4o5"
   },
   "source": [
    "# Part III.  GloVE Embeddings\n",
    "\n",
    "After downloading Glove, we adapt our code to use it.  GloVE contains 400,000 tokens and comes with a variety of embedding dims.  We chose the smallest - 50 features per token.\n",
    "\n",
    "All but 45 words in our vocab were in GloVE.  The \"misses\" tended to be words with apostrophes, abbrevaitions and compound words (later we will clean our data to better match the pre-trained embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "cgdOOCOvA42C"
   },
   "outputs": [],
   "source": [
    "#file = pd.read_table('glove.6B.50d.txt') # okay this one may be too big - using 50 from now on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mk-BciFfgX9G",
    "outputId": "4eab497b-511c-4c1f-dfd6-d9a78d469616"
   },
   "outputs": [],
   "source": [
    "#!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "#!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xDgozhp9ND2q",
    "outputId": "512b9bad-67b0-4e1f-e0c3-924eb7735edf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('glove.6B.50d.txt', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g7j6F9IMND2q",
    "outputId": "26989fe0-e338-4fba-f767-528de175bf13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<OOV>\n",
      "today's\n",
      "committee's\n",
      "pepp\n",
      "tltro\n",
      "council's\n",
      "href\n",
      "reserve's\n",
      "covid\n",
      "pressconf\n",
      "eurosystem's\n",
      "ecb's\n",
      "regardingnon\n",
      "banks’\n",
      "peltros\n",
      "eurep\n",
      "households'\n",
      "bankofengland\n",
      "federalreserve\n",
      "optionality\n",
      "ltros\n",
      "tltros\n",
      "counterparties’\n",
      "10basis\n",
      "december2015\n",
      "4percent\n",
      "overbidding\n",
      "2818\n",
      "is000608\n",
      "tomaintain\n",
      " \n",
      "is010830\n",
      "is000302\n",
      "is001214\n",
      "is010201\n",
      "russia's\n",
      "board's\n",
      "summer's\n",
      "is020606\n",
      "actionsthe\n",
      "banksinformation\n",
      "is010510\n",
      "is000706\n",
      "peltro\n",
      "4½\n",
      "Converted 1878 words (45 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(range(vocab_size)) + 2 #vocab size was specified in Part I\n",
    "embedding_dim = 50 #we chose the 50-dim embedding of GloVE\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix. This matrix matches OUR vocabulary to the ELEMENTS in GloVE.\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "        #print(word, end =\"\")\n",
    "        print(word)\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "uTNAL0geND2r"
   },
   "outputs": [],
   "source": [
    "\n",
    "modela_glove = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], input_length = max_length, trainable=False),  \n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "ut_FfOsYND2r"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "modela_glove.compile(loss='binary_crossentropy', \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LlDbeiuoND2s",
    "outputId": "2738ffcb-7ced-4158-a43c-e76462195b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1200, 50)          250100    \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 50)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 306       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 250,413\n",
      "Trainable params: 313\n",
      "Non-trainable params: 250,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modela_glove.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IHSAeOJGND2s",
    "outputId": "e04b22e8-79de-4fcc-ccc1-184c8e349255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 1s 30ms/step - loss: 0.7067 - precision: 0.2346 - val_loss: 0.6942 - val_precision: 0.1429\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6860 - precision: 0.1667 - val_loss: 0.6764 - val_precision: 0.0000e+00\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6686 - precision: 0.0000e+00 - val_loss: 0.6606 - val_precision: 0.0000e+00\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6529 - precision: 0.0000e+00 - val_loss: 0.6468 - val_precision: 0.0000e+00\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6398 - precision: 0.0000e+00 - val_loss: 0.6350 - val_precision: 0.0000e+00\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6283 - precision: 0.0000e+00 - val_loss: 0.6238 - val_precision: 0.0000e+00\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6169 - precision: 0.0000e+00 - val_loss: 0.6138 - val_precision: 0.0000e+00\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6068 - precision: 0.0000e+00 - val_loss: 0.6044 - val_precision: 0.0000e+00\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5983 - precision: 0.0000e+00 - val_loss: 0.5963 - val_precision: 0.0000e+00\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5907 - precision: 0.0000e+00 - val_loss: 0.5886 - val_precision: 0.0000e+00\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5835 - precision: 0.0000e+00 - val_loss: 0.5806 - val_precision: 0.0000e+00\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5765 - precision: 0.0000e+00 - val_loss: 0.5733 - val_precision: 0.0000e+00\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5697 - precision: 0.0000e+00 - val_loss: 0.5667 - val_precision: 0.0000e+00\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5640 - precision: 0.0000e+00 - val_loss: 0.5605 - val_precision: 0.0000e+00\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5587 - precision: 0.0000e+00 - val_loss: 0.5546 - val_precision: 0.0000e+00\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5540 - precision: 0.0000e+00 - val_loss: 0.5497 - val_precision: 0.0000e+00\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5499 - precision: 0.0000e+00 - val_loss: 0.5443 - val_precision: 0.0000e+00\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5458 - precision: 0.0000e+00 - val_loss: 0.5392 - val_precision: 0.0000e+00\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5418 - precision: 0.0000e+00 - val_loss: 0.5355 - val_precision: 0.0000e+00\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5391 - precision: 0.0000e+00 - val_loss: 0.5319 - val_precision: 0.0000e+00\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5363 - precision: 0.0000e+00 - val_loss: 0.5285 - val_precision: 0.0000e+00\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5338 - precision: 0.0000e+00 - val_loss: 0.5248 - val_precision: 0.0000e+00\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5312 - precision: 0.0000e+00 - val_loss: 0.5215 - val_precision: 0.0000e+00\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5291 - precision: 0.0000e+00 - val_loss: 0.5187 - val_precision: 0.0000e+00\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5277 - precision: 0.0000e+00 - val_loss: 0.5165 - val_precision: 0.0000e+00\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5264 - precision: 0.0000e+00 - val_loss: 0.5156 - val_precision: 0.0000e+00\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5257 - precision: 0.0000e+00 - val_loss: 0.5144 - val_precision: 0.0000e+00\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5251 - precision: 0.0000e+00 - val_loss: 0.5123 - val_precision: 0.0000e+00\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5237 - precision: 0.0000e+00 - val_loss: 0.5105 - val_precision: 0.0000e+00\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5226 - precision: 0.0000e+00 - val_loss: 0.5096 - val_precision: 0.0000e+00\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5219 - precision: 0.0000e+00 - val_loss: 0.5079 - val_precision: 0.0000e+00\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5208 - precision: 0.0000e+00 - val_loss: 0.5068 - val_precision: 0.0000e+00\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5203 - precision: 0.0000e+00 - val_loss: 0.5058 - val_precision: 0.0000e+00\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5196 - precision: 0.0000e+00 - val_loss: 0.5046 - val_precision: 0.0000e+00\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5190 - precision: 0.0000e+00 - val_loss: 0.5033 - val_precision: 0.0000e+00\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5184 - precision: 0.0000e+00 - val_loss: 0.5026 - val_precision: 0.0000e+00\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5181 - precision: 0.0000e+00 - val_loss: 0.5015 - val_precision: 0.0000e+00\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5174 - precision: 0.0000e+00 - val_loss: 0.5007 - val_precision: 0.0000e+00\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5170 - precision: 0.0000e+00 - val_loss: 0.4997 - val_precision: 0.0000e+00\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5166 - precision: 0.0000e+00 - val_loss: 0.4990 - val_precision: 0.0000e+00\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5162 - precision: 0.0000e+00 - val_loss: 0.4980 - val_precision: 0.0000e+00\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5159 - precision: 0.0000e+00 - val_loss: 0.4972 - val_precision: 0.0000e+00\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5154 - precision: 0.0000e+00 - val_loss: 0.4969 - val_precision: 0.0000e+00\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5151 - precision: 0.0000e+00 - val_loss: 0.4964 - val_precision: 0.0000e+00\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5148 - precision: 0.0000e+00 - val_loss: 0.4958 - val_precision: 0.0000e+00\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5144 - precision: 0.0000e+00 - val_loss: 0.4950 - val_precision: 0.0000e+00\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5140 - precision: 0.0000e+00 - val_loss: 0.4942 - val_precision: 0.0000e+00\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5136 - precision: 0.0000e+00 - val_loss: 0.4937 - val_precision: 0.0000e+00\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5132 - precision: 0.0000e+00 - val_loss: 0.4933 - val_precision: 0.0000e+00\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5129 - precision: 0.0000e+00 - val_loss: 0.4929 - val_precision: 0.0000e+00\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5126 - precision: 0.0000e+00 - val_loss: 0.4922 - val_precision: 0.0000e+00\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5122 - precision: 0.0000e+00 - val_loss: 0.4916 - val_precision: 0.0000e+00\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5120 - precision: 0.0000e+00 - val_loss: 0.4909 - val_precision: 0.0000e+00\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5118 - precision: 0.0000e+00 - val_loss: 0.4910 - val_precision: 0.0000e+00\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5116 - precision: 0.0000e+00 - val_loss: 0.4908 - val_precision: 0.0000e+00\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5115 - precision: 0.0000e+00 - val_loss: 0.4901 - val_precision: 0.0000e+00\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5111 - precision: 0.0000e+00 - val_loss: 0.4898 - val_precision: 0.0000e+00\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5110 - precision: 0.0000e+00 - val_loss: 0.4892 - val_precision: 0.0000e+00\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5107 - precision: 0.0000e+00 - val_loss: 0.4890 - val_precision: 0.0000e+00\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5105 - precision: 0.0000e+00 - val_loss: 0.4892 - val_precision: 0.0000e+00\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5103 - precision: 0.0000e+00 - val_loss: 0.4889 - val_precision: 0.0000e+00\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5101 - precision: 0.0000e+00 - val_loss: 0.4887 - val_precision: 0.0000e+00\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5098 - precision: 0.0000e+00 - val_loss: 0.4881 - val_precision: 0.0000e+00\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5097 - precision: 0.0000e+00 - val_loss: 0.4881 - val_precision: 0.0000e+00\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5095 - precision: 0.0000e+00 - val_loss: 0.4878 - val_precision: 0.0000e+00\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5093 - precision: 0.0000e+00 - val_loss: 0.4876 - val_precision: 0.0000e+00\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5091 - precision: 0.0000e+00 - val_loss: 0.4874 - val_precision: 0.0000e+00\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5090 - precision: 0.0000e+00 - val_loss: 0.4872 - val_precision: 0.0000e+00\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5089 - precision: 0.0000e+00 - val_loss: 0.4867 - val_precision: 0.0000e+00\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5087 - precision: 0.0000e+00 - val_loss: 0.4867 - val_precision: 0.0000e+00\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5084 - precision: 0.0000e+00 - val_loss: 0.4863 - val_precision: 0.0000e+00\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5083 - precision: 0.0000e+00 - val_loss: 0.4864 - val_precision: 0.0000e+00\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5080 - precision: 0.0000e+00 - val_loss: 0.4860 - val_precision: 0.0000e+00\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5078 - precision: 0.0000e+00 - val_loss: 0.4855 - val_precision: 0.0000e+00\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5076 - precision: 0.0000e+00 - val_loss: 0.4849 - val_precision: 0.0000e+00\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5074 - precision: 0.0000e+00 - val_loss: 0.4848 - val_precision: 0.0000e+00\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5072 - precision: 0.0000e+00 - val_loss: 0.4851 - val_precision: 0.0000e+00\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5071 - precision: 0.0000e+00 - val_loss: 0.4849 - val_precision: 0.0000e+00\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5070 - precision: 0.0000e+00 - val_loss: 0.4844 - val_precision: 0.0000e+00\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5070 - precision: 0.0000e+00 - val_loss: 0.4840 - val_precision: 0.0000e+00\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5066 - precision: 0.0000e+00 - val_loss: 0.4838 - val_precision: 0.0000e+00\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5066 - precision: 0.0000e+00 - val_loss: 0.4837 - val_precision: 0.0000e+00\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5065 - precision: 0.0000e+00 - val_loss: 0.4837 - val_precision: 0.0000e+00\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5064 - precision: 0.0000e+00 - val_loss: 0.4840 - val_precision: 0.0000e+00\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5062 - precision: 0.0000e+00 - val_loss: 0.4841 - val_precision: 0.0000e+00\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5061 - precision: 0.0000e+00 - val_loss: 0.4839 - val_precision: 0.0000e+00\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5061 - precision: 0.0000e+00 - val_loss: 0.4839 - val_precision: 0.0000e+00\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5059 - precision: 0.0000e+00 - val_loss: 0.4841 - val_precision: 0.0000e+00\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5058 - precision: 0.0000e+00 - val_loss: 0.4840 - val_precision: 0.0000e+00\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5057 - precision: 0.0000e+00 - val_loss: 0.4840 - val_precision: 0.0000e+00\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5056 - precision: 0.0000e+00 - val_loss: 0.4839 - val_precision: 0.0000e+00\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5055 - precision: 0.0000e+00 - val_loss: 0.4837 - val_precision: 0.0000e+00\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5055 - precision: 0.0000e+00 - val_loss: 0.4836 - val_precision: 0.0000e+00\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5053 - precision: 0.0000e+00 - val_loss: 0.4833 - val_precision: 0.0000e+00\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5051 - precision: 0.0000e+00 - val_loss: 0.4830 - val_precision: 0.0000e+00\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5050 - precision: 0.0000e+00 - val_loss: 0.4833 - val_precision: 0.0000e+00\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5048 - precision: 0.0000e+00 - val_loss: 0.4833 - val_precision: 0.0000e+00\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5047 - precision: 0.0000e+00 - val_loss: 0.4832 - val_precision: 0.0000e+00\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5046 - precision: 0.0000e+00 - val_loss: 0.4828 - val_precision: 0.0000e+00\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5044 - precision: 0.0000e+00 - val_loss: 0.4823 - val_precision: 0.0000e+00\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5041 - precision: 0.0000e+00 - val_loss: 0.4818 - val_precision: 0.0000e+00\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5040 - precision: 0.0000e+00 - val_loss: 0.4814 - val_precision: 0.0000e+00\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5040 - precision: 0.0000e+00 - val_loss: 0.4808 - val_precision: 0.0000e+00\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5039 - precision: 0.0000e+00 - val_loss: 0.4804 - val_precision: 0.0000e+00\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5037 - precision: 0.0000e+00 - val_loss: 0.4802 - val_precision: 0.0000e+00\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5036 - precision: 0.0000e+00 - val_loss: 0.4799 - val_precision: 0.0000e+00\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5035 - precision: 0.0000e+00 - val_loss: 0.4798 - val_precision: 0.0000e+00\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5034 - precision: 0.0000e+00 - val_loss: 0.4795 - val_precision: 0.0000e+00\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5033 - precision: 0.0000e+00 - val_loss: 0.4791 - val_precision: 0.0000e+00\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5034 - precision: 0.0000e+00 - val_loss: 0.4787 - val_precision: 0.0000e+00\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5035 - precision: 0.0000e+00 - val_loss: 0.4790 - val_precision: 0.0000e+00\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5029 - precision: 0.0000e+00 - val_loss: 0.4788 - val_precision: 0.0000e+00\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5027 - precision: 0.0000e+00 - val_loss: 0.4789 - val_precision: 0.0000e+00\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5027 - precision: 0.0000e+00 - val_loss: 0.4791 - val_precision: 0.0000e+00\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5025 - precision: 0.0000e+00 - val_loss: 0.4790 - val_precision: 0.0000e+00\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5024 - precision: 0.0000e+00 - val_loss: 0.4790 - val_precision: 0.0000e+00\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5021 - precision: 0.0000e+00 - val_loss: 0.4792 - val_precision: 0.0000e+00\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5022 - precision: 0.0000e+00 - val_loss: 0.4790 - val_precision: 0.0000e+00\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5019 - precision: 0.0000e+00 - val_loss: 0.4790 - val_precision: 0.0000e+00\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5018 - precision: 0.0000e+00 - val_loss: 0.4791 - val_precision: 0.0000e+00\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5017 - precision: 0.0000e+00 - val_loss: 0.4790 - val_precision: 0.0000e+00\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5017 - precision: 0.0000e+00 - val_loss: 0.4792 - val_precision: 0.0000e+00\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5015 - precision: 0.0000e+00 - val_loss: 0.4790 - val_precision: 0.0000e+00\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5014 - precision: 0.0000e+00 - val_loss: 0.4786 - val_precision: 0.0000e+00\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5015 - precision: 0.0000e+00 - val_loss: 0.4782 - val_precision: 0.0000e+00\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5013 - precision: 0.0000e+00 - val_loss: 0.4785 - val_precision: 0.0000e+00\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5011 - precision: 0.0000e+00 - val_loss: 0.4785 - val_precision: 0.0000e+00\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5011 - precision: 0.0000e+00 - val_loss: 0.4789 - val_precision: 0.0000e+00\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5010 - precision: 0.0000e+00 - val_loss: 0.4791 - val_precision: 0.0000e+00\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5009 - precision: 0.0000e+00 - val_loss: 0.4789 - val_precision: 0.0000e+00\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5007 - precision: 0.0000e+00 - val_loss: 0.4785 - val_precision: 0.0000e+00\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5006 - precision: 0.0000e+00 - val_loss: 0.4779 - val_precision: 0.0000e+00\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5005 - precision: 0.0000e+00 - val_loss: 0.4780 - val_precision: 0.0000e+00\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5004 - precision: 0.0000e+00 - val_loss: 0.4780 - val_precision: 0.0000e+00\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5004 - precision: 0.0000e+00 - val_loss: 0.4776 - val_precision: 0.0000e+00\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5002 - precision: 0.0000e+00 - val_loss: 0.4774 - val_precision: 0.0000e+00\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5001 - precision: 0.0000e+00 - val_loss: 0.4771 - val_precision: 0.0000e+00\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5000 - precision: 0.0000e+00 - val_loss: 0.4773 - val_precision: 0.0000e+00\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4998 - precision: 0.0000e+00 - val_loss: 0.4770 - val_precision: 0.0000e+00\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4997 - precision: 0.0000e+00 - val_loss: 0.4766 - val_precision: 0.0000e+00\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4997 - precision: 0.0000e+00 - val_loss: 0.4766 - val_precision: 0.0000e+00\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4996 - precision: 0.0000e+00 - val_loss: 0.4765 - val_precision: 0.0000e+00\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4996 - precision: 0.0000e+00 - val_loss: 0.4766 - val_precision: 0.0000e+00\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4994 - precision: 0.0000e+00 - val_loss: 0.4762 - val_precision: 0.0000e+00\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4993 - precision: 0.0000e+00 - val_loss: 0.4760 - val_precision: 0.0000e+00\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4993 - precision: 0.0000e+00 - val_loss: 0.4756 - val_precision: 0.0000e+00\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4992 - precision: 0.0000e+00 - val_loss: 0.4757 - val_precision: 0.0000e+00\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.4991 - precision: 0.0000e+00 - val_loss: 0.4757 - val_precision: 0.0000e+00\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.4990 - precision: 0.0000e+00 - val_loss: 0.4757 - val_precision: 0.0000e+00\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.4989 - precision: 0.0000e+00 - val_loss: 0.4755 - val_precision: 0.0000e+00\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4987 - precision: 0.0000e+00 - val_loss: 0.4756 - val_precision: 0.0000e+00\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4987 - precision: 0.0000e+00 - val_loss: 0.4757 - val_precision: 0.0000e+00\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4986 - precision: 0.0000e+00 - val_loss: 0.4760 - val_precision: 0.0000e+00\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4986 - precision: 0.0000e+00 - val_loss: 0.4758 - val_precision: 0.0000e+00\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4985 - precision: 0.0000e+00 - val_loss: 0.4762 - val_precision: 0.0000e+00\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4984 - precision: 0.0000e+00 - val_loss: 0.4760 - val_precision: 0.0000e+00\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4983 - precision: 0.0000e+00 - val_loss: 0.4758 - val_precision: 0.0000e+00\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4982 - precision: 0.0000e+00 - val_loss: 0.4759 - val_precision: 0.0000e+00\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4982 - precision: 0.0000e+00 - val_loss: 0.4757 - val_precision: 0.0000e+00\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4980 - precision: 0.0000e+00 - val_loss: 0.4750 - val_precision: 0.0000e+00\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4980 - precision: 0.0000e+00 - val_loss: 0.4745 - val_precision: 0.0000e+00\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4980 - precision: 0.0000e+00 - val_loss: 0.4742 - val_precision: 0.0000e+00\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4979 - precision: 0.0000e+00 - val_loss: 0.4738 - val_precision: 0.0000e+00\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4978 - precision: 0.0000e+00 - val_loss: 0.4738 - val_precision: 0.0000e+00\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4978 - precision: 0.0000e+00 - val_loss: 0.4736 - val_precision: 0.0000e+00\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4977 - precision: 0.0000e+00 - val_loss: 0.4733 - val_precision: 0.0000e+00\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4977 - precision: 0.0000e+00 - val_loss: 0.4735 - val_precision: 0.0000e+00\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4976 - precision: 0.0000e+00 - val_loss: 0.4733 - val_precision: 0.0000e+00\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4975 - precision: 0.0000e+00 - val_loss: 0.4732 - val_precision: 0.0000e+00\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4975 - precision: 0.0000e+00 - val_loss: 0.4729 - val_precision: 0.0000e+00\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4974 - precision: 0.0000e+00 - val_loss: 0.4729 - val_precision: 0.0000e+00\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4973 - precision: 0.0000e+00 - val_loss: 0.4727 - val_precision: 0.0000e+00\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4972 - precision: 0.0000e+00 - val_loss: 0.4727 - val_precision: 0.0000e+00\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4973 - precision: 0.0000e+00 - val_loss: 0.4724 - val_precision: 0.0000e+00\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4973 - precision: 0.0000e+00 - val_loss: 0.4724 - val_precision: 0.0000e+00\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4972 - precision: 0.0000e+00 - val_loss: 0.4722 - val_precision: 0.0000e+00\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4972 - precision: 0.0000e+00 - val_loss: 0.4722 - val_precision: 0.0000e+00\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4971 - precision: 0.0000e+00 - val_loss: 0.4721 - val_precision: 0.0000e+00\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4971 - precision: 0.0000e+00 - val_loss: 0.4721 - val_precision: 0.0000e+00\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4970 - precision: 0.0000e+00 - val_loss: 0.4720 - val_precision: 0.0000e+00\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4970 - precision: 0.0000e+00 - val_loss: 0.4718 - val_precision: 0.0000e+00\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4972 - precision: 0.0000e+00 - val_loss: 0.4716 - val_precision: 0.0000e+00\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4970 - precision: 0.0000e+00 - val_loss: 0.4715 - val_precision: 0.0000e+00\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4969 - precision: 0.0000e+00 - val_loss: 0.4714 - val_precision: 0.0000e+00\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4968 - precision: 0.0000e+00 - val_loss: 0.4714 - val_precision: 0.0000e+00\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4966 - precision: 0.0000e+00 - val_loss: 0.4716 - val_precision: 0.0000e+00\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4972 - precision: 0.0000e+00 - val_loss: 0.4726 - val_precision: 0.0000e+00\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4960 - precision: 0.0000e+00 - val_loss: 0.4727 - val_precision: 0.0000e+00\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4959 - precision: 0.0000e+00 - val_loss: 0.4727 - val_precision: 0.0000e+00\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4960 - precision: 0.0000e+00 - val_loss: 0.4724 - val_precision: 0.0000e+00\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4958 - precision: 0.0000e+00 - val_loss: 0.4725 - val_precision: 0.0000e+00\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4956 - precision: 0.0000e+00 - val_loss: 0.4727 - val_precision: 0.0000e+00\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4955 - precision: 0.0000e+00 - val_loss: 0.4729 - val_precision: 0.0000e+00\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4955 - precision: 0.0000e+00 - val_loss: 0.4727 - val_precision: 0.0000e+00\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4954 - precision: 0.0000e+00 - val_loss: 0.4725 - val_precision: 0.0000e+00\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4954 - precision: 0.0000e+00 - val_loss: 0.4727 - val_precision: 0.0000e+00\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4955 - precision: 0.0000e+00 - val_loss: 0.4732 - val_precision: 0.0000e+00\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4952 - precision: 0.0000e+00 - val_loss: 0.4729 - val_precision: 0.0000e+00\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4951 - precision: 0.0000e+00 - val_loss: 0.4725 - val_precision: 0.0000e+00\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4950 - precision: 0.0000e+00 - val_loss: 0.4724 - val_precision: 0.0000e+00\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4952 - precision: 0.0000e+00 - val_loss: 0.4727 - val_precision: 0.0000e+00\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4949 - precision: 0.0000e+00 - val_loss: 0.4726 - val_precision: 0.0000e+00\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4949 - precision: 0.0000e+00 - val_loss: 0.4727 - val_precision: 0.0000e+00\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4948 - precision: 0.0000e+00 - val_loss: 0.4730 - val_precision: 0.0000e+00\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4946 - precision: 0.0000e+00 - val_loss: 0.4733 - val_precision: 0.0000e+00\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4947 - precision: 0.0000e+00 - val_loss: 0.4732 - val_precision: 0.0000e+00\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4949 - precision: 0.0000e+00 - val_loss: 0.4725 - val_precision: 0.0000e+00\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4944 - precision: 0.0000e+00 - val_loss: 0.4725 - val_precision: 0.0000e+00\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4945 - precision: 0.0000e+00 - val_loss: 0.4728 - val_precision: 0.0000e+00\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4946 - precision: 0.0000e+00 - val_loss: 0.4723 - val_precision: 0.0000e+00\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4942 - precision: 0.0000e+00 - val_loss: 0.4721 - val_precision: 0.0000e+00\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4942 - precision: 0.0000e+00 - val_loss: 0.4718 - val_precision: 0.0000e+00\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4944 - precision: 0.0000e+00 - val_loss: 0.4725 - val_precision: 0.0000e+00\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4940 - precision: 0.0000e+00 - val_loss: 0.4727 - val_precision: 0.0000e+00\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4940 - precision: 0.0000e+00 - val_loss: 0.4724 - val_precision: 0.0000e+00\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4938 - precision: 0.0000e+00 - val_loss: 0.4719 - val_precision: 0.0000e+00\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4937 - precision: 0.0000e+00 - val_loss: 0.4716 - val_precision: 0.0000e+00\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4937 - precision: 0.0000e+00 - val_loss: 0.4712 - val_precision: 0.0000e+00\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4939 - precision: 0.0000e+00 - val_loss: 0.4718 - val_precision: 0.0000e+00\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4935 - precision: 0.0000e+00 - val_loss: 0.4716 - val_precision: 0.0000e+00\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4934 - precision: 0.0000e+00 - val_loss: 0.4714 - val_precision: 0.0000e+00\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4935 - precision: 0.0000e+00 - val_loss: 0.4710 - val_precision: 0.0000e+00\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4932 - precision: 0.0000e+00 - val_loss: 0.4713 - val_precision: 0.0000e+00\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4934 - precision: 0.0000e+00 - val_loss: 0.4714 - val_precision: 0.0000e+00\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4932 - precision: 0.0000e+00 - val_loss: 0.4711 - val_precision: 0.0000e+00\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.4931 - precision: 0.0000e+00 - val_loss: 0.4707 - val_precision: 0.0000e+00\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4931 - precision: 0.0000e+00 - val_loss: 0.4702 - val_precision: 0.0000e+00\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.4930 - precision: 0.0000e+00 - val_loss: 0.4699 - val_precision: 0.0000e+00\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4930 - precision: 0.0000e+00 - val_loss: 0.4699 - val_precision: 0.0000e+00\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4930 - precision: 0.0000e+00 - val_loss: 0.4697 - val_precision: 0.0000e+00\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4929 - precision: 0.0000e+00 - val_loss: 0.4698 - val_precision: 0.0000e+00\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4927 - precision: 0.0000e+00 - val_loss: 0.4696 - val_precision: 0.0000e+00\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4927 - precision: 0.0000e+00 - val_loss: 0.4695 - val_precision: 0.0000e+00\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4927 - precision: 0.0000e+00 - val_loss: 0.4693 - val_precision: 0.0000e+00\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4926 - precision: 0.0000e+00 - val_loss: 0.4694 - val_precision: 0.0000e+00\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4926 - precision: 0.0000e+00 - val_loss: 0.4691 - val_precision: 0.0000e+00\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4925 - precision: 0.0000e+00 - val_loss: 0.4691 - val_precision: 0.0000e+00\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4923 - precision: 0.0000e+00 - val_loss: 0.4693 - val_precision: 0.0000e+00\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4923 - precision: 0.0000e+00 - val_loss: 0.4691 - val_precision: 0.0000e+00\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4925 - precision: 0.0000e+00 - val_loss: 0.4688 - val_precision: 0.0000e+00\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4922 - precision: 0.0000e+00 - val_loss: 0.4691 - val_precision: 0.0000e+00\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4921 - precision: 0.0000e+00 - val_loss: 0.4692 - val_precision: 0.0000e+00\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4918 - precision: 0.0000e+00 - val_loss: 0.4696 - val_precision: 0.0000e+00\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4919 - precision: 0.0000e+00 - val_loss: 0.4700 - val_precision: 0.0000e+00\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4918 - precision: 0.0000e+00 - val_loss: 0.4702 - val_precision: 0.0000e+00\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4917 - precision: 0.0000e+00 - val_loss: 0.4703 - val_precision: 0.0000e+00\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4916 - precision: 0.0000e+00 - val_loss: 0.4703 - val_precision: 0.0000e+00\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4916 - precision: 0.0000e+00 - val_loss: 0.4698 - val_precision: 0.0000e+00\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4915 - precision: 0.0000e+00 - val_loss: 0.4698 - val_precision: 0.0000e+00\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4913 - precision: 0.0000e+00 - val_loss: 0.4693 - val_precision: 0.0000e+00\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4914 - precision: 0.0000e+00 - val_loss: 0.4687 - val_precision: 0.0000e+00\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4916 - precision: 0.0000e+00 - val_loss: 0.4683 - val_precision: 0.0000e+00\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4913 - precision: 0.0000e+00 - val_loss: 0.4683 - val_precision: 0.0000e+00\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4913 - precision: 0.0000e+00 - val_loss: 0.4682 - val_precision: 0.0000e+00\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4912 - precision: 0.0000e+00 - val_loss: 0.4684 - val_precision: 0.0000e+00\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4911 - precision: 0.0000e+00 - val_loss: 0.4685 - val_precision: 0.0000e+00\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4909 - precision: 0.0000e+00 - val_loss: 0.4686 - val_precision: 0.0000e+00\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4908 - precision: 0.0000e+00 - val_loss: 0.4689 - val_precision: 0.0000e+00\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4907 - precision: 0.0000e+00 - val_loss: 0.4690 - val_precision: 0.0000e+00\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4906 - precision: 0.0000e+00 - val_loss: 0.4696 - val_precision: 0.0000e+00\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4906 - precision: 0.0000e+00 - val_loss: 0.4695 - val_precision: 0.0000e+00\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4905 - precision: 0.0000e+00 - val_loss: 0.4693 - val_precision: 0.0000e+00\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4905 - precision: 0.0000e+00 - val_loss: 0.4694 - val_precision: 0.0000e+00\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4904 - precision: 0.0000e+00 - val_loss: 0.4691 - val_precision: 0.0000e+00\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4903 - precision: 0.0000e+00 - val_loss: 0.4691 - val_precision: 0.0000e+00\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4903 - precision: 0.0000e+00 - val_loss: 0.4686 - val_precision: 0.0000e+00\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4901 - precision: 0.0000e+00 - val_loss: 0.4683 - val_precision: 0.0000e+00\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4902 - precision: 0.0000e+00 - val_loss: 0.4680 - val_precision: 0.0000e+00\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4902 - precision: 0.0000e+00 - val_loss: 0.4677 - val_precision: 0.0000e+00\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4900 - precision: 0.0000e+00 - val_loss: 0.4674 - val_precision: 0.0000e+00\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4900 - precision: 0.0000e+00 - val_loss: 0.4673 - val_precision: 0.0000e+00\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4899 - precision: 0.0000e+00 - val_loss: 0.4674 - val_precision: 0.0000e+00\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4899 - precision: 0.0000e+00 - val_loss: 0.4672 - val_precision: 0.0000e+00\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4899 - precision: 0.0000e+00 - val_loss: 0.4671 - val_precision: 0.0000e+00\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4897 - precision: 0.0000e+00 - val_loss: 0.4676 - val_precision: 0.0000e+00\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4895 - precision: 0.0000e+00 - val_loss: 0.4683 - val_precision: 0.0000e+00\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4892 - precision: 0.0000e+00 - val_loss: 0.4686 - val_precision: 0.0000e+00\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4896 - precision: 0.0000e+00 - val_loss: 0.4692 - val_precision: 0.0000e+00\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4892 - precision: 0.0000e+00 - val_loss: 0.4693 - val_precision: 0.0000e+00\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4892 - precision: 0.0000e+00 - val_loss: 0.4698 - val_precision: 0.0000e+00\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4893 - precision: 0.0000e+00 - val_loss: 0.4697 - val_precision: 0.0000e+00\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4892 - precision: 0.0000e+00 - val_loss: 0.4697 - val_precision: 0.0000e+00\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4891 - precision: 0.0000e+00 - val_loss: 0.4695 - val_precision: 0.0000e+00\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4890 - precision: 0.0000e+00 - val_loss: 0.4686 - val_precision: 0.0000e+00\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4887 - precision: 0.0000e+00 - val_loss: 0.4681 - val_precision: 0.0000e+00\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4885 - precision: 0.0000e+00 - val_loss: 0.4678 - val_precision: 0.0000e+00\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4885 - precision: 0.0000e+00 - val_loss: 0.4677 - val_precision: 0.0000e+00\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4884 - precision: 0.0000e+00 - val_loss: 0.4676 - val_precision: 0.0000e+00\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4884 - precision: 0.0000e+00 - val_loss: 0.4674 - val_precision: 0.0000e+00\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4882 - precision: 0.0000e+00 - val_loss: 0.4674 - val_precision: 0.0000e+00\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4881 - precision: 0.0000e+00 - val_loss: 0.4672 - val_precision: 0.0000e+00\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4882 - precision: 0.0000e+00 - val_loss: 0.4677 - val_precision: 0.0000e+00\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4879 - precision: 0.0000e+00 - val_loss: 0.4680 - val_precision: 0.0000e+00\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4879 - precision: 0.0000e+00 - val_loss: 0.4680 - val_precision: 0.0000e+00\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4879 - precision: 0.0000e+00 - val_loss: 0.4679 - val_precision: 0.0000e+00\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4878 - precision: 0.0000e+00 - val_loss: 0.4678 - val_precision: 0.0000e+00\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.4877 - precision: 0.0000e+00 - val_loss: 0.4673 - val_precision: 0.0000e+00\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.4876 - precision: 0.0000e+00 - val_loss: 0.4672 - val_precision: 0.0000e+00\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4877 - precision: 0.0000e+00 - val_loss: 0.4669 - val_precision: 0.0000e+00\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4874 - precision: 0.0000e+00 - val_loss: 0.4666 - val_precision: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300\n",
    "history = modela_glove.fit(padded, training_labels_final, \n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(val_padded, val_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "-_ctJiO4ND2t",
    "outputId": "357ac8d3-9a35-4db6-d584-578399043c71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "precision = history.history['precision']\n",
    "val_precision = history.history['val_precision']\n",
    "epochs=range(len(precision))\n",
    "plt.plot(epochs, precision, 'r')\n",
    "plt.plot(epochs, val_precision, 'b')\n",
    "plt.title('Training and validation Precision')\n",
    "plt.ylim((0,1.5))\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "f8srp5_wND2t",
    "outputId": "df4be3fb-168e-46a3-a552-4613bf0d63d6",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5370 - precision: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5369735956192017, 0.0]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modela_glove.evaluate(test_padded, test_labels_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model B with GloVe 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelb_glove50 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], input_length = max_length, trainable=False),  \n",
    "    tf.keras.layers.Conv1D(128, 5, activation=\"relu\"),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "modelb_glove50.compile(loss='binary_crossentropy', \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1200, 50)          250100    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 1196, 128)         32128     \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 774       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 283,009\n",
      "Trainable params: 32,909\n",
      "Non-trainable params: 250,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelb_glove50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.6398 - precision: 0.0000e+00 - val_loss: 0.5893 - val_precision: 0.0000e+00\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.5619 - precision: 0.0000e+00 - val_loss: 0.5412 - val_precision: 0.0000e+00\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.5480 - precision: 0.0000e+00 - val_loss: 0.5275 - val_precision: 0.0000e+00\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.5464 - precision: 0.0000e+00 - val_loss: 0.5212 - val_precision: 0.0000e+00\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.5398 - precision: 0.0000e+00 - val_loss: 0.5176 - val_precision: 0.0000e+00\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.5312 - precision: 0.0000e+00 - val_loss: 0.5163 - val_precision: 0.0000e+00\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.5281 - precision: 0.0000e+00 - val_loss: 0.5168 - val_precision: 0.0000e+00\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.5250 - precision: 0.0000e+00 - val_loss: 0.5119 - val_precision: 0.0000e+00\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.5212 - precision: 0.0000e+00 - val_loss: 0.5079 - val_precision: 0.0000e+00\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.5181 - precision: 0.0000e+00 - val_loss: 0.5037 - val_precision: 0.0000e+00\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 55ms/step - loss: 0.5139 - precision: 0.0000e+00 - val_loss: 0.4942 - val_precision: 0.0000e+00\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.5105 - precision: 0.0000e+00 - val_loss: 0.4903 - val_precision: 0.0000e+00\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.5074 - precision: 0.0000e+00 - val_loss: 0.4886 - val_precision: 0.0000e+00\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.5032 - precision: 0.0000e+00 - val_loss: 0.4855 - val_precision: 0.0000e+00\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.5003 - precision: 0.0000e+00 - val_loss: 0.4811 - val_precision: 0.0000e+00\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.4970 - precision: 0.0000e+00 - val_loss: 0.4811 - val_precision: 0.0000e+00\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.4940 - precision: 0.0000e+00 - val_loss: 0.4727 - val_precision: 0.0000e+00\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.4926 - precision: 0.0000e+00 - val_loss: 0.4676 - val_precision: 0.0000e+00\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.4882 - precision: 0.0000e+00 - val_loss: 0.4792 - val_precision: 0.0000e+00\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 0.4878 - precision: 0.0000e+00 - val_loss: 0.4705 - val_precision: 0.0000e+00\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.4797 - precision: 0.0000e+00 - val_loss: 0.4600 - val_precision: 0.0000e+00\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.4790 - precision: 0.0000e+00 - val_loss: 0.4559 - val_precision: 0.0000e+00\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.4779 - precision: 0.0000e+00 - val_loss: 0.4566 - val_precision: 0.0000e+00\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.4717 - precision: 0.0000e+00 - val_loss: 0.4564 - val_precision: 0.0000e+00\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 0.4696 - precision: 0.0000e+00 - val_loss: 0.4577 - val_precision: 0.0000e+00\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.4761 - precision: 0.0000e+00 - val_loss: 0.4828 - val_precision: 0.0000e+00\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.4750 - precision: 0.0000e+00 - val_loss: 0.4539 - val_precision: 0.0000e+00\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.4713 - precision: 0.0000e+00 - val_loss: 0.4461 - val_precision: 0.0000e+00\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.4689 - precision: 0.0000e+00 - val_loss: 0.4453 - val_precision: 0.0000e+00\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.4617 - precision: 0.0000e+00 - val_loss: 0.4619 - val_precision: 0.0000e+00\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.4631 - precision: 0.0000e+00 - val_loss: 0.4484 - val_precision: 0.0000e+00\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.4532 - precision: 0.0000e+00 - val_loss: 0.4418 - val_precision: 0.0000e+00\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.4522 - precision: 0.0000e+00 - val_loss: 0.4445 - val_precision: 0.0000e+00\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.4494 - precision: 0.0000e+00 - val_loss: 0.4398 - val_precision: 0.0000e+00\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.4470 - precision: 0.0000e+00 - val_loss: 0.4354 - val_precision: 0.0000e+00\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.4459 - precision: 0.0000e+00 - val_loss: 0.4446 - val_precision: 0.0000e+00\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.4429 - precision: 0.0000e+00 - val_loss: 0.4349 - val_precision: 0.0000e+00\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.4402 - precision: 0.0000e+00 - val_loss: 0.4305 - val_precision: 0.0000e+00\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.4387 - precision: 0.0000e+00 - val_loss: 0.4291 - val_precision: 0.0000e+00\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.4403 - precision: 0.0000e+00 - val_loss: 0.4342 - val_precision: 0.0000e+00\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.4339 - precision: 0.0000e+00 - val_loss: 0.4248 - val_precision: 0.0000e+00\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.4289 - precision: 0.0000e+00 - val_loss: 0.4327 - val_precision: 0.0000e+00\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.4410 - precision: 0.0000e+00 - val_loss: 0.4356 - val_precision: 0.0000e+00\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.4268 - precision: 0.0000e+00 - val_loss: 0.4230 - val_precision: 0.0000e+00\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.4298 - precision: 0.0000e+00 - val_loss: 0.4259 - val_precision: 0.0000e+00\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.4274 - precision: 0.0000e+00 - val_loss: 0.4226 - val_precision: 0.0000e+00\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.4247 - precision: 0.0000e+00 - val_loss: 0.4214 - val_precision: 0.0000e+00\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.4242 - precision: 0.0000e+00 - val_loss: 0.4214 - val_precision: 0.0000e+00\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.4220 - precision: 0.0000e+00 - val_loss: 0.4253 - val_precision: 0.0000e+00\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.4229 - precision: 0.0000e+00 - val_loss: 0.4220 - val_precision: 0.0000e+00\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 0.4210 - precision: 0.0000e+00 - val_loss: 0.4194 - val_precision: 0.0000e+00\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 0.4199 - precision: 0.0000e+00 - val_loss: 0.4212 - val_precision: 0.0000e+00\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 1s 99ms/step - loss: 0.4179 - precision: 0.0000e+00 - val_loss: 0.4197 - val_precision: 0.0000e+00\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.4203 - precision: 0.0000e+00 - val_loss: 0.4284 - val_precision: 0.0000e+00\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 0.4104 - precision: 0.0000e+00 - val_loss: 0.4170 - val_precision: 0.0000e+00\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 0.4209 - precision: 0.0000e+00 - val_loss: 0.4190 - val_precision: 0.0000e+00\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 0.4143 - precision: 0.0000e+00 - val_loss: 0.4241 - val_precision: 0.0000e+00\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 0.4169 - precision: 0.0000e+00 - val_loss: 0.4167 - val_precision: 0.0000e+00\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 0.4104 - precision: 0.0000e+00 - val_loss: 0.4234 - val_precision: 0.0000e+00\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 0.4214 - precision: 0.0000e+00 - val_loss: 0.4310 - val_precision: 0.0000e+00\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.4085 - precision: 0.0000e+00 - val_loss: 0.4144 - val_precision: 0.0000e+00\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 0.4134 - precision: 0.0000e+00 - val_loss: 0.4182 - val_precision: 0.0000e+00\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.4119 - precision: 0.0000e+00 - val_loss: 0.4161 - val_precision: 0.0000e+00\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.4169 - precision: 0.0000e+00 - val_loss: 0.4243 - val_precision: 0.0000e+00\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 0.4156 - precision: 0.0000e+00 - val_loss: 0.4136 - val_precision: 0.0000e+00\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 0.4068 - precision: 0.0000e+00 - val_loss: 0.4299 - val_precision: 0.0000e+00\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 0.4066 - precision: 0.0000e+00 - val_loss: 0.4171 - val_precision: 0.0000e+00\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.4042 - precision: 0.0000e+00 - val_loss: 0.4177 - val_precision: 0.0000e+00\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.4047 - precision: 0.0000e+00 - val_loss: 0.4171 - val_precision: 0.0000e+00\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.4118 - precision: 0.0000e+00 - val_loss: 0.4192 - val_precision: 0.0000e+00\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 0.4057 - precision: 0.0000e+00 - val_loss: 0.4125 - val_precision: 1.0000\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.4093 - precision: 0.9474 - val_loss: 0.4315 - val_precision: 0.8000\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 0.4064 - precision: 1.0000 - val_loss: 0.4119 - val_precision: 1.0000\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.4019 - precision: 0.9231 - val_loss: 0.4162 - val_precision: 0.7500\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.3978 - precision: 0.9286 - val_loss: 0.4165 - val_precision: 0.7500\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 0.3980 - precision: 0.9333 - val_loss: 0.4201 - val_precision: 0.8000\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.4017 - precision: 0.9500 - val_loss: 0.4185 - val_precision: 0.7500\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 0.3967 - precision: 1.0000 - val_loss: 0.4123 - val_precision: 1.0000\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 0.4033 - precision: 1.0000 - val_loss: 0.4121 - val_precision: 1.0000\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 0.3925 - precision: 0.9333 - val_loss: 0.4258 - val_precision: 0.8000\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.3982 - precision: 0.9091 - val_loss: 0.4117 - val_precision: 1.0000\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 0.4040 - precision: 1.0000 - val_loss: 0.4132 - val_precision: 0.7500\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 0.3985 - precision: 0.9375 - val_loss: 0.4280 - val_precision: 0.5714\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 0.3939 - precision: 0.9048 - val_loss: 0.4129 - val_precision: 0.7500\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 0.3972 - precision: 0.9333 - val_loss: 0.4193 - val_precision: 0.8000\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 0.3941 - precision: 0.9375 - val_loss: 0.4180 - val_precision: 0.8000\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 0.3974 - precision: 0.9474 - val_loss: 0.4164 - val_precision: 0.8000\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 0.3950 - precision: 0.9000 - val_loss: 0.4192 - val_precision: 0.8000\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 0.3956 - precision: 1.0000 - val_loss: 0.4117 - val_precision: 0.6667\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3908 - precision: 0.9375 - val_loss: 0.4239 - val_precision: 0.6667\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.3928 - precision: 0.9000 - val_loss: 0.4165 - val_precision: 0.8000\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.3915 - precision: 0.9375 - val_loss: 0.4130 - val_precision: 0.6667\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 0.3958 - precision: 0.9000 - val_loss: 0.4168 - val_precision: 0.8000\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 0.3927 - precision: 1.0000 - val_loss: 0.4097 - val_precision: 0.6667\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 0.3864 - precision: 0.9375 - val_loss: 0.4212 - val_precision: 0.5714\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 0.3896 - precision: 0.8696 - val_loss: 0.4126 - val_precision: 0.8000\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 0.3865 - precision: 0.9444 - val_loss: 0.4114 - val_precision: 0.8000\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.3903 - precision: 1.0000 - val_loss: 0.4096 - val_precision: 0.6667\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.3845 - precision: 0.9444 - val_loss: 0.4144 - val_precision: 0.8000\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 0.3876 - precision: 0.9091 - val_loss: 0.4120 - val_precision: 0.8000\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 0.3830 - precision: 0.9412 - val_loss: 0.4086 - val_precision: 1.0000\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 0.3881 - precision: 0.9412 - val_loss: 0.4149 - val_precision: 0.6667\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 0.3857 - precision: 1.0000 - val_loss: 0.4110 - val_precision: 0.8000\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 0.3852 - precision: 1.0000 - val_loss: 0.4146 - val_precision: 0.6667\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.3823 - precision: 0.8636 - val_loss: 0.4087 - val_precision: 0.6667\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.3958 - precision: 1.0000 - val_loss: 0.4109 - val_precision: 0.8000\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.3939 - precision: 0.8462 - val_loss: 0.4159 - val_precision: 0.5714\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.3841 - precision: 1.0000 - val_loss: 0.4080 - val_precision: 0.6667\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 0.3843 - precision: 0.9444 - val_loss: 0.4178 - val_precision: 0.6000\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 0.3822 - precision: 0.9048 - val_loss: 0.4085 - val_precision: 0.6667\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.3835 - precision: 0.9412 - val_loss: 0.4099 - val_precision: 0.8000\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.3817 - precision: 1.0000 - val_loss: 0.4081 - val_precision: 0.6667\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.3790 - precision: 0.9500 - val_loss: 0.4141 - val_precision: 0.5714\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 0.3789 - precision: 0.9524 - val_loss: 0.4077 - val_precision: 0.6667\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.3824 - precision: 1.0000 - val_loss: 0.4136 - val_precision: 0.5714\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 0.3811 - precision: 0.8750 - val_loss: 0.4216 - val_precision: 0.6000\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 1s 98ms/step - loss: 0.3806 - precision: 0.8400 - val_loss: 0.4084 - val_precision: 0.6667\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.3891 - precision: 0.9286 - val_loss: 0.4083 - val_precision: 0.6667\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 1s 100ms/step - loss: 0.3821 - precision: 0.8571 - val_loss: 0.4311 - val_precision: 0.5833\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.3842 - precision: 0.8571 - val_loss: 0.4084 - val_precision: 0.6667\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 0.3767 - precision: 0.9474 - val_loss: 0.4073 - val_precision: 0.6667\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 0.3771 - precision: 0.9000 - val_loss: 0.4088 - val_precision: 0.8000\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 0.3774 - precision: 0.8947 - val_loss: 0.4101 - val_precision: 0.7143\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 0.3754 - precision: 0.9048 - val_loss: 0.4070 - val_precision: 0.6667\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 0.3750 - precision: 1.0000 - val_loss: 0.4116 - val_precision: 0.6250\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 0.3760 - precision: 0.8696 - val_loss: 0.4092 - val_precision: 0.6667\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 0.3742 - precision: 0.9091 - val_loss: 0.4097 - val_precision: 0.6667\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 0.3750 - precision: 0.9091 - val_loss: 0.4144 - val_precision: 0.6000\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 0.3718 - precision: 0.9048 - val_loss: 0.4067 - val_precision: 0.6667\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.3733 - precision: 0.9474 - val_loss: 0.4115 - val_precision: 0.6250\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.3703 - precision: 0.9048 - val_loss: 0.4066 - val_precision: 0.6667\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.3772 - precision: 1.0000 - val_loss: 0.4137 - val_precision: 0.6000\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.3726 - precision: 0.8462 - val_loss: 0.4239 - val_precision: 0.5455\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.3792 - precision: 0.8065 - val_loss: 0.4120 - val_precision: 0.6667\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 0.3928 - precision: 1.0000 - val_loss: 0.4079 - val_precision: 0.6667\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.3812 - precision: 0.8800 - val_loss: 0.4235 - val_precision: 0.5455\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 0.3692 - precision: 1.0000 - val_loss: 0.4066 - val_precision: 0.6667\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 0.3744 - precision: 0.9091 - val_loss: 0.4187 - val_precision: 0.5455\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 0.3756 - precision: 0.8500 - val_loss: 0.4051 - val_precision: 0.6667\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.3737 - precision: 0.9048 - val_loss: 0.4133 - val_precision: 0.6000\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.3708 - precision: 0.8400 - val_loss: 0.4116 - val_precision: 0.6667\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 0.3743 - precision: 1.0000 - val_loss: 0.4049 - val_precision: 0.6667\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 0.3697 - precision: 0.9048 - val_loss: 0.4232 - val_precision: 0.5833\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 0.3711 - precision: 0.8750 - val_loss: 0.4057 - val_precision: 0.5000\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 0.3668 - precision: 0.9524 - val_loss: 0.4089 - val_precision: 0.6250\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.3678 - precision: 0.9500 - val_loss: 0.4166 - val_precision: 0.5455\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.3823 - precision: 0.7576 - val_loss: 0.4171 - val_precision: 0.5455\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.3638 - precision: 0.9474 - val_loss: 0.4056 - val_precision: 0.6667\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 0.3681 - precision: 0.8696 - val_loss: 0.4157 - val_precision: 0.5455\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.3646 - precision: 0.8696 - val_loss: 0.4096 - val_precision: 0.6250\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.3632 - precision: 0.8462 - val_loss: 0.4129 - val_precision: 0.5455\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.3651 - precision: 0.8636 - val_loss: 0.4107 - val_precision: 0.6250\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 0.3708 - precision: 0.8276 - val_loss: 0.4155 - val_precision: 0.5455\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.3732 - precision: 0.9474 - val_loss: 0.4085 - val_precision: 0.5714\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 0.3970 - precision: 0.6842 - val_loss: 0.4570 - val_precision: 0.4375\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.3752 - precision: 0.8333 - val_loss: 0.4054 - val_precision: 0.6667\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 0.3693 - precision: 0.9500 - val_loss: 0.4109 - val_precision: 0.6250\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.3626 - precision: 0.9130 - val_loss: 0.4117 - val_precision: 0.6250\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.3646 - precision: 0.8400 - val_loss: 0.4082 - val_precision: 0.5714\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.3618 - precision: 0.9444 - val_loss: 0.4065 - val_precision: 0.6000\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.3645 - precision: 0.9444 - val_loss: 0.4173 - val_precision: 0.5833\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.3622 - precision: 0.8214 - val_loss: 0.4086 - val_precision: 0.5714\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 0.3684 - precision: 0.9474 - val_loss: 0.4099 - val_precision: 0.5714\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.3613 - precision: 0.8400 - val_loss: 0.4137 - val_precision: 0.5455\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 0.3581 - precision: 0.9545 - val_loss: 0.4073 - val_precision: 0.6000\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.3612 - precision: 0.9524 - val_loss: 0.4089 - val_precision: 0.5714\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 0.3589 - precision: 0.9130 - val_loss: 0.4083 - val_precision: 0.5714\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 0.3587 - precision: 0.9091 - val_loss: 0.4104 - val_precision: 0.6250\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 0.3566 - precision: 0.9545 - val_loss: 0.4076 - val_precision: 0.5000\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 0.3582 - precision: 0.9524 - val_loss: 0.4108 - val_precision: 0.6250\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.3582 - precision: 0.9167 - val_loss: 0.4093 - val_precision: 0.5714\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 0.3619 - precision: 0.9474 - val_loss: 0.4085 - val_precision: 0.5714\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 0.3697 - precision: 0.8276 - val_loss: 0.4132 - val_precision: 0.5000\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.3626 - precision: 0.9474 - val_loss: 0.4065 - val_precision: 0.6000\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 0.3598 - precision: 0.8800 - val_loss: 0.4178 - val_precision: 0.5833\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 0.3568 - precision: 0.9091 - val_loss: 0.4091 - val_precision: 0.5714\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.3549 - precision: 0.9545 - val_loss: 0.4129 - val_precision: 0.5556\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.3535 - precision: 0.9545 - val_loss: 0.4089 - val_precision: 0.5714\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.3650 - precision: 0.8214 - val_loss: 0.4140 - val_precision: 0.5000\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.3538 - precision: 0.9545 - val_loss: 0.4094 - val_precision: 0.5714\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.3537 - precision: 0.9545 - val_loss: 0.4124 - val_precision: 0.5000\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 0.3536 - precision: 0.9130 - val_loss: 0.4117 - val_precision: 0.6250\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 0.3511 - precision: 0.9545 - val_loss: 0.4118 - val_precision: 0.5556\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 0.3524 - precision: 0.8800 - val_loss: 0.4102 - val_precision: 0.5714\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 0.3520 - precision: 0.9545 - val_loss: 0.4120 - val_precision: 0.5000\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.3505 - precision: 0.9130 - val_loss: 0.4094 - val_precision: 0.5714\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 0.3521 - precision: 0.9545 - val_loss: 0.4080 - val_precision: 0.5714\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.3579 - precision: 0.9545 - val_loss: 0.4132 - val_precision: 0.5000\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 0.3518 - precision: 0.9200 - val_loss: 0.4079 - val_precision: 0.5714\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.3528 - precision: 0.9524 - val_loss: 0.4153 - val_precision: 0.5455\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 0.3658 - precision: 0.8065 - val_loss: 0.4211 - val_precision: 0.5833\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 0.3562 - precision: 0.8571 - val_loss: 0.4122 - val_precision: 0.5000\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 0.3514 - precision: 0.9545 - val_loss: 0.4122 - val_precision: 0.5556\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 0.3488 - precision: 0.8889 - val_loss: 0.4125 - val_precision: 0.5000\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.3533 - precision: 0.9524 - val_loss: 0.4190 - val_precision: 0.5833\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.3640 - precision: 0.7812 - val_loss: 0.4144 - val_precision: 0.5455\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.3460 - precision: 0.9200 - val_loss: 0.4071 - val_precision: 0.6000\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 0.3506 - precision: 0.9545 - val_loss: 0.4097 - val_precision: 0.5714\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.3493 - precision: 0.9524 - val_loss: 0.4154 - val_precision: 0.5455\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.3442 - precision: 0.9200 - val_loss: 0.4095 - val_precision: 0.5714\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 0.3463 - precision: 0.9167 - val_loss: 0.4121 - val_precision: 0.5000\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.3437 - precision: 0.9167 - val_loss: 0.4127 - val_precision: 0.5000\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.3433 - precision: 0.9130 - val_loss: 0.4113 - val_precision: 0.5000\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 0.3464 - precision: 0.9583 - val_loss: 0.4156 - val_precision: 0.5000\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.3452 - precision: 0.9583 - val_loss: 0.4109 - val_precision: 0.5000\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.3444 - precision: 0.9200 - val_loss: 0.4118 - val_precision: 0.5000\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 0.3643 - precision: 1.0000 - val_loss: 0.4156 - val_precision: 0.5455\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.3682 - precision: 0.7812 - val_loss: 0.4138 - val_precision: 0.5000\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 0.3469 - precision: 0.9545 - val_loss: 0.4126 - val_precision: 0.5000\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 0.3438 - precision: 0.9545 - val_loss: 0.4125 - val_precision: 0.5000\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 0.3422 - precision: 0.9200 - val_loss: 0.4131 - val_precision: 0.5000\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 0.3460 - precision: 0.9545 - val_loss: 0.4241 - val_precision: 0.5385\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 0.4431 - precision: 0.4912 - val_loss: 0.4821 - val_precision: 0.3500\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 0.3786 - precision: 0.7188 - val_loss: 0.4248 - val_precision: 0.0000e+00\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 0.3605 - precision: 0.8889 - val_loss: 0.4217 - val_precision: 0.5385\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 0.3578 - precision: 0.7879 - val_loss: 0.4128 - val_precision: 0.6000\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.3412 - precision: 0.9565 - val_loss: 0.4093 - val_precision: 0.5556\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.3428 - precision: 0.9130 - val_loss: 0.4138 - val_precision: 0.5455\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 0.3395 - precision: 0.9231 - val_loss: 0.4108 - val_precision: 0.5556\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 0.3402 - precision: 0.9545 - val_loss: 0.4111 - val_precision: 0.5556\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 0.3416 - precision: 0.8462 - val_loss: 0.4137 - val_precision: 0.5455\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.3450 - precision: 0.9524 - val_loss: 0.4159 - val_precision: 0.5455\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 0.3604 - precision: 0.7000 - val_loss: 0.4416 - val_precision: 0.4667\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 0.3323 - precision: 0.8333 - val_loss: 0.4159 - val_precision: 0.5000\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 0.3547 - precision: 0.9333 - val_loss: 0.4239 - val_precision: 0.5000\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 0.3501 - precision: 0.8333 - val_loss: 0.4145 - val_precision: 0.5000\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.3466 - precision: 0.9524 - val_loss: 0.4098 - val_precision: 0.5714\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.3423 - precision: 0.9259 - val_loss: 0.4183 - val_precision: 0.5000\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 0.3371 - precision: 0.9583 - val_loss: 0.4105 - val_precision: 0.5714\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 0.3371 - precision: 0.9565 - val_loss: 0.4179 - val_precision: 0.5000\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.3358 - precision: 0.8889 - val_loss: 0.4143 - val_precision: 0.5000\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.3335 - precision: 0.9583 - val_loss: 0.4117 - val_precision: 0.5714\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 0.3401 - precision: 0.9200 - val_loss: 0.4155 - val_precision: 0.5455\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.3346 - precision: 0.9545 - val_loss: 0.4134 - val_precision: 0.5556\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.3344 - precision: 0.9583 - val_loss: 0.4171 - val_precision: 0.5000\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.3353 - precision: 0.9231 - val_loss: 0.4130 - val_precision: 0.5556\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 1s 111ms/step - loss: 0.3457 - precision: 0.9474 - val_loss: 0.4108 - val_precision: 0.5714\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.3376 - precision: 0.8000 - val_loss: 0.4237 - val_precision: 0.5000\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.3375 - precision: 0.9545 - val_loss: 0.4111 - val_precision: 0.5714\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 0.3348 - precision: 0.9565 - val_loss: 0.4234 - val_precision: 0.5000\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.3495 - precision: 0.7647 - val_loss: 0.4223 - val_precision: 0.5000\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.3392 - precision: 0.9167 - val_loss: 0.4131 - val_precision: 0.5000\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 0.3328 - precision: 0.8929 - val_loss: 0.4226 - val_precision: 0.5385\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.3294 - precision: 0.8846 - val_loss: 0.4108 - val_precision: 0.5714\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.3334 - precision: 0.9565 - val_loss: 0.4162 - val_precision: 0.5455\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 0.3323 - precision: 0.8889 - val_loss: 0.4153 - val_precision: 0.5455\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 0.3301 - precision: 0.9565 - val_loss: 0.4121 - val_precision: 0.5556\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 0.3323 - precision: 0.8846 - val_loss: 0.4147 - val_precision: 0.5455\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 0.3309 - precision: 0.9583 - val_loss: 0.4108 - val_precision: 0.5714\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 0.3350 - precision: 0.9600 - val_loss: 0.4174 - val_precision: 0.5455\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 0.3278 - precision: 0.9231 - val_loss: 0.4140 - val_precision: 0.6000\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.3351 - precision: 0.9167 - val_loss: 0.4295 - val_precision: 0.4667\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.3355 - precision: 0.8065 - val_loss: 0.4164 - val_precision: 0.5455\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.3289 - precision: 0.9583 - val_loss: 0.4145 - val_precision: 0.5000\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.3256 - precision: 0.9231 - val_loss: 0.4267 - val_precision: 0.4615\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.3273 - precision: 0.8571 - val_loss: 0.4171 - val_precision: 0.5455\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.3408 - precision: 0.9474 - val_loss: 0.4165 - val_precision: 0.5455\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.3260 - precision: 0.8929 - val_loss: 0.4233 - val_precision: 0.5000\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.3276 - precision: 0.8846 - val_loss: 0.4238 - val_precision: 0.5000\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 0.3505 - precision: 0.7073 - val_loss: 0.4272 - val_precision: 0.4615\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 0.3314 - precision: 0.8947 - val_loss: 0.4137 - val_precision: 0.5714\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 0.3311 - precision: 0.8621 - val_loss: 0.4238 - val_precision: 0.4615\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 0.3248 - precision: 0.8519 - val_loss: 0.4146 - val_precision: 0.5556\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 0.3257 - precision: 0.9565 - val_loss: 0.4185 - val_precision: 0.5455\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 0.3223 - precision: 0.9231 - val_loss: 0.4157 - val_precision: 0.6000\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.3260 - precision: 0.9565 - val_loss: 0.4150 - val_precision: 0.6000\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 0.3200 - precision: 0.9600 - val_loss: 0.4259 - val_precision: 0.4615\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 0.3267 - precision: 0.8276 - val_loss: 0.4170 - val_precision: 0.5455\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 0.3232 - precision: 0.9583 - val_loss: 0.4168 - val_precision: 0.5455\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 0.3209 - precision: 0.8889 - val_loss: 0.4162 - val_precision: 0.5455\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.3204 - precision: 0.9231 - val_loss: 0.4155 - val_precision: 0.5455\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.3197 - precision: 0.9600 - val_loss: 0.4162 - val_precision: 0.5455\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 0.3221 - precision: 0.9565 - val_loss: 0.4152 - val_precision: 0.5455\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 0.3237 - precision: 0.8929 - val_loss: 0.4187 - val_precision: 0.4615\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 0.3189 - precision: 0.9583 - val_loss: 0.4114 - val_precision: 0.5714\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 0.3212 - precision: 0.9600 - val_loss: 0.4213 - val_precision: 0.4615\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 0.3190 - precision: 0.8889 - val_loss: 0.4167 - val_precision: 0.5455\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.3275 - precision: 0.8000 - val_loss: 0.4152 - val_precision: 0.5455\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.3305 - precision: 0.9524 - val_loss: 0.4162 - val_precision: 0.5000\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.3386 - precision: 0.7568 - val_loss: 0.4171 - val_precision: 0.5000\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 0.3160 - precision: 0.9565 - val_loss: 0.4098 - val_precision: 0.5714\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 0.3217 - precision: 0.9565 - val_loss: 0.4183 - val_precision: 0.5000\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 0.3156 - precision: 0.8889 - val_loss: 0.4117 - val_precision: 0.5556\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.3202 - precision: 0.9565 - val_loss: 0.4176 - val_precision: 0.5000\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 0.3174 - precision: 0.8929 - val_loss: 0.4174 - val_precision: 0.5000\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 0.3283 - precision: 0.9545 - val_loss: 0.4100 - val_precision: 0.5714\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.3268 - precision: 0.8276 - val_loss: 0.4167 - val_precision: 0.5000\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 0.3133 - precision: 0.9583 - val_loss: 0.4175 - val_precision: 0.5000\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 0.3146 - precision: 0.8276 - val_loss: 0.4210 - val_precision: 0.5000\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 0.3139 - precision: 0.9231 - val_loss: 0.4182 - val_precision: 0.5000\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 0.3133 - precision: 0.9231 - val_loss: 0.4196 - val_precision: 0.5000\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 0.3197 - precision: 0.8065 - val_loss: 0.4163 - val_precision: 0.5455\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.3178 - precision: 0.9545 - val_loss: 0.4203 - val_precision: 0.5000\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.3125 - precision: 0.8929 - val_loss: 0.4210 - val_precision: 0.4615\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.3130 - precision: 0.9231 - val_loss: 0.4164 - val_precision: 0.5455\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 0.3139 - precision: 0.9565 - val_loss: 0.4132 - val_precision: 0.5000\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.3124 - precision: 0.9565 - val_loss: 0.4286 - val_precision: 0.4667\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 0.3493 - precision: 0.6977 - val_loss: 0.4305 - val_precision: 0.5000\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.3183 - precision: 0.9167 - val_loss: 0.4167 - val_precision: 0.6000\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 0.3173 - precision: 0.8621 - val_loss: 0.4209 - val_precision: 0.5000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300\n",
    "history = modelb_glove50.fit(padded, training_labels_final, \n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(val_padded, val_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "precision = history.history['precision']\n",
    "val_precision = history.history['val_precision']\n",
    "epochs=range(len(precision))\n",
    "plt.plot(epochs, precision, 'r')\n",
    "plt.plot(epochs, val_precision, 'b')\n",
    "plt.title('Training and validation Precision')\n",
    "plt.ylim((0,1.5))\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5147 - precision: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5146810412406921, 0.6666666865348816]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelb_glove50.evaluate(test_padded, test_labels_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRKZWN0GND20"
   },
   "source": [
    "### Model A with bigger GloVe set predicting next interest rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "KIRtRDhbND22",
    "outputId": "d8e6d641-9a20-42a4-b214-600d97c5ab4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('glove.6B.200d.txt', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "qBqmIavPND23"
   },
   "outputs": [],
   "source": [
    "num_tokens = len(range(vocab_size)) + 2\n",
    "embedding_dim = 200\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "        #print(word, end =\"\")\n",
    "        #print(word)\n",
    "#print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "oJsiueUCND24"
   },
   "outputs": [],
   "source": [
    "modela_glove_next_rate = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(embedding_matrix.shape[0], embedding_dim, weights=[embedding_matrix], input_length = max_length, trainable=False),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "BEJaEHrQND24"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "modela_glove_next_rate.compile(loss='binary_crossentropy', \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "dq_i5ChnND25",
    "outputId": "a2b6b88b-3899-46a0-a9e4-b77049f1d57b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1200, 200)         1000400   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 200)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 1206      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,001,613\n",
      "Trainable params: 1,213\n",
      "Non-trainable params: 1,000,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modela_glove_next_rate.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "v0CnyfiOND25",
    "outputId": "e57d71eb-b0a6-47dc-91af-e196ce945fb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 1s 52ms/step - loss: 0.6628 - precision: 0.5000 - val_loss: 0.6474 - val_precision: 0.0000e+00\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.6314 - precision: 0.0000e+00 - val_loss: 0.6234 - val_precision: 0.0000e+00\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.6106 - precision: 0.0000e+00 - val_loss: 0.6054 - val_precision: 0.0000e+00\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.5941 - precision: 0.0000e+00 - val_loss: 0.5903 - val_precision: 0.0000e+00\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.5819 - precision: 0.0000e+00 - val_loss: 0.5781 - val_precision: 0.0000e+00\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.5718 - precision: 0.0000e+00 - val_loss: 0.5678 - val_precision: 0.0000e+00\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5629 - precision: 0.0000e+00 - val_loss: 0.5599 - val_precision: 0.0000e+00\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5565 - precision: 0.0000e+00 - val_loss: 0.5532 - val_precision: 0.0000e+00\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.5522 - precision: 0.0000e+00 - val_loss: 0.5483 - val_precision: 0.0000e+00\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5490 - precision: 0.0000e+00 - val_loss: 0.5441 - val_precision: 0.0000e+00\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5459 - precision: 0.0000e+00 - val_loss: 0.5392 - val_precision: 0.0000e+00\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5431 - precision: 0.0000e+00 - val_loss: 0.5353 - val_precision: 0.0000e+00\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5404 - precision: 0.0000e+00 - val_loss: 0.5322 - val_precision: 0.0000e+00\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5387 - precision: 0.0000e+00 - val_loss: 0.5293 - val_precision: 0.0000e+00\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5371 - precision: 0.0000e+00 - val_loss: 0.5266 - val_precision: 0.0000e+00\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5357 - precision: 0.0000e+00 - val_loss: 0.5248 - val_precision: 0.0000e+00\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.5345 - precision: 0.0000e+00 - val_loss: 0.5222 - val_precision: 0.0000e+00\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.5333 - precision: 0.0000e+00 - val_loss: 0.5195 - val_precision: 0.0000e+00\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.5317 - precision: 0.0000e+00 - val_loss: 0.5186 - val_precision: 0.0000e+00\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5306 - precision: 0.0000e+00 - val_loss: 0.5172 - val_precision: 0.0000e+00\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.5294 - precision: 0.0000e+00 - val_loss: 0.5158 - val_precision: 0.0000e+00\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5283 - precision: 0.0000e+00 - val_loss: 0.5136 - val_precision: 0.0000e+00\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5272 - precision: 0.0000e+00 - val_loss: 0.5116 - val_precision: 0.0000e+00\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5261 - precision: 0.0000e+00 - val_loss: 0.5101 - val_precision: 0.0000e+00\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5252 - precision: 0.0000e+00 - val_loss: 0.5091 - val_precision: 0.0000e+00\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.5239 - precision: 0.0000e+00 - val_loss: 0.5098 - val_precision: 0.0000e+00\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.5234 - precision: 0.0000e+00 - val_loss: 0.5097 - val_precision: 0.0000e+00\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5229 - precision: 0.0000e+00 - val_loss: 0.5081 - val_precision: 0.0000e+00\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.5219 - precision: 0.0000e+00 - val_loss: 0.5064 - val_precision: 0.0000e+00\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.5208 - precision: 0.0000e+00 - val_loss: 0.5061 - val_precision: 0.0000e+00\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.5199 - precision: 0.0000e+00 - val_loss: 0.5045 - val_precision: 0.0000e+00\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5189 - precision: 0.0000e+00 - val_loss: 0.5034 - val_precision: 0.0000e+00\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.5181 - precision: 0.0000e+00 - val_loss: 0.5027 - val_precision: 0.0000e+00\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5174 - precision: 0.0000e+00 - val_loss: 0.5015 - val_precision: 0.0000e+00\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5166 - precision: 0.0000e+00 - val_loss: 0.4998 - val_precision: 0.0000e+00\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.5158 - precision: 0.0000e+00 - val_loss: 0.4993 - val_precision: 0.0000e+00\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.5152 - precision: 0.0000e+00 - val_loss: 0.4980 - val_precision: 0.0000e+00\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5145 - precision: 0.0000e+00 - val_loss: 0.4970 - val_precision: 0.0000e+00\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.5136 - precision: 0.0000e+00 - val_loss: 0.4957 - val_precision: 0.0000e+00\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5130 - precision: 0.0000e+00 - val_loss: 0.4951 - val_precision: 0.0000e+00\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5121 - precision: 0.0000e+00 - val_loss: 0.4936 - val_precision: 0.0000e+00\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5114 - precision: 0.0000e+00 - val_loss: 0.4927 - val_precision: 0.0000e+00\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5106 - precision: 0.0000e+00 - val_loss: 0.4925 - val_precision: 0.0000e+00\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5100 - precision: 0.0000e+00 - val_loss: 0.4918 - val_precision: 0.0000e+00\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.5092 - precision: 0.0000e+00 - val_loss: 0.4911 - val_precision: 0.0000e+00\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5084 - precision: 0.0000e+00 - val_loss: 0.4898 - val_precision: 0.0000e+00\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5076 - precision: 0.0000e+00 - val_loss: 0.4886 - val_precision: 0.0000e+00\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.5067 - precision: 0.0000e+00 - val_loss: 0.4878 - val_precision: 0.0000e+00\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.5059 - precision: 0.0000e+00 - val_loss: 0.4872 - val_precision: 0.0000e+00\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.5052 - precision: 0.0000e+00 - val_loss: 0.4868 - val_precision: 0.0000e+00\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.5045 - precision: 0.0000e+00 - val_loss: 0.4856 - val_precision: 0.0000e+00\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.5037 - precision: 0.0000e+00 - val_loss: 0.4844 - val_precision: 0.0000e+00\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.5032 - precision: 0.0000e+00 - val_loss: 0.4831 - val_precision: 0.0000e+00\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.5027 - precision: 0.0000e+00 - val_loss: 0.4833 - val_precision: 0.0000e+00\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.5022 - precision: 0.0000e+00 - val_loss: 0.4830 - val_precision: 0.0000e+00\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.5018 - precision: 0.0000e+00 - val_loss: 0.4817 - val_precision: 0.0000e+00\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.5012 - precision: 0.0000e+00 - val_loss: 0.4810 - val_precision: 0.0000e+00\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.5009 - precision: 0.0000e+00 - val_loss: 0.4800 - val_precision: 0.0000e+00\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.5003 - precision: 0.0000e+00 - val_loss: 0.4797 - val_precision: 0.0000e+00\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4995 - precision: 0.0000e+00 - val_loss: 0.4804 - val_precision: 0.0000e+00\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4991 - precision: 0.0000e+00 - val_loss: 0.4800 - val_precision: 0.0000e+00\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4988 - precision: 0.0000e+00 - val_loss: 0.4796 - val_precision: 0.0000e+00\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4980 - precision: 0.0000e+00 - val_loss: 0.4783 - val_precision: 0.0000e+00\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4977 - precision: 0.0000e+00 - val_loss: 0.4782 - val_precision: 0.0000e+00\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4971 - precision: 0.0000e+00 - val_loss: 0.4775 - val_precision: 0.0000e+00\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4966 - precision: 0.0000e+00 - val_loss: 0.4772 - val_precision: 0.0000e+00\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4963 - precision: 0.0000e+00 - val_loss: 0.4766 - val_precision: 0.0000e+00\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4958 - precision: 0.0000e+00 - val_loss: 0.4761 - val_precision: 0.0000e+00\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4956 - precision: 0.0000e+00 - val_loss: 0.4751 - val_precision: 0.0000e+00\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4951 - precision: 0.0000e+00 - val_loss: 0.4751 - val_precision: 0.0000e+00\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.4945 - precision: 0.0000e+00 - val_loss: 0.4744 - val_precision: 0.0000e+00\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4942 - precision: 0.0000e+00 - val_loss: 0.4747 - val_precision: 0.0000e+00\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4936 - precision: 0.0000e+00 - val_loss: 0.4738 - val_precision: 0.0000e+00\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4930 - precision: 0.0000e+00 - val_loss: 0.4728 - val_precision: 0.0000e+00\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4926 - precision: 0.0000e+00 - val_loss: 0.4719 - val_precision: 0.0000e+00\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4921 - precision: 0.0000e+00 - val_loss: 0.4717 - val_precision: 0.0000e+00\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4915 - precision: 0.0000e+00 - val_loss: 0.4725 - val_precision: 0.0000e+00\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4911 - precision: 0.0000e+00 - val_loss: 0.4721 - val_precision: 0.0000e+00\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4909 - precision: 0.0000e+00 - val_loss: 0.4707 - val_precision: 0.0000e+00\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.4909 - precision: 0.0000e+00 - val_loss: 0.4697 - val_precision: 0.0000e+00\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4901 - precision: 0.0000e+00 - val_loss: 0.4694 - val_precision: 0.0000e+00\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.4900 - precision: 0.0000e+00 - val_loss: 0.4692 - val_precision: 0.0000e+00\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4898 - precision: 0.0000e+00 - val_loss: 0.4695 - val_precision: 0.0000e+00\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4894 - precision: 0.0000e+00 - val_loss: 0.4699 - val_precision: 0.0000e+00\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4889 - precision: 0.0000e+00 - val_loss: 0.4699 - val_precision: 0.0000e+00\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4887 - precision: 0.0000e+00 - val_loss: 0.4694 - val_precision: 0.0000e+00\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4885 - precision: 0.0000e+00 - val_loss: 0.4693 - val_precision: 0.0000e+00\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4882 - precision: 0.0000e+00 - val_loss: 0.4698 - val_precision: 0.0000e+00\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.4881 - precision: 0.0000e+00 - val_loss: 0.4697 - val_precision: 0.0000e+00\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4877 - precision: 0.0000e+00 - val_loss: 0.4694 - val_precision: 0.0000e+00\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4874 - precision: 0.0000e+00 - val_loss: 0.4690 - val_precision: 0.0000e+00\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4871 - precision: 0.0000e+00 - val_loss: 0.4684 - val_precision: 0.0000e+00\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4870 - precision: 0.0000e+00 - val_loss: 0.4682 - val_precision: 0.0000e+00\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4864 - precision: 0.0000e+00 - val_loss: 0.4675 - val_precision: 0.0000e+00\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4862 - precision: 0.0000e+00 - val_loss: 0.4670 - val_precision: 0.0000e+00\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4858 - precision: 0.0000e+00 - val_loss: 0.4680 - val_precision: 0.0000e+00\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4854 - precision: 0.0000e+00 - val_loss: 0.4681 - val_precision: 0.0000e+00\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4850 - precision: 0.0000e+00 - val_loss: 0.4677 - val_precision: 0.0000e+00\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4847 - precision: 0.0000e+00 - val_loss: 0.4664 - val_precision: 0.0000e+00\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4841 - precision: 0.0000e+00 - val_loss: 0.4652 - val_precision: 0.0000e+00\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4835 - precision: 0.0000e+00 - val_loss: 0.4642 - val_precision: 0.0000e+00\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4833 - precision: 0.0000e+00 - val_loss: 0.4636 - val_precision: 0.0000e+00\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4832 - precision: 0.0000e+00 - val_loss: 0.4628 - val_precision: 0.0000e+00\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4831 - precision: 0.0000e+00 - val_loss: 0.4624 - val_precision: 0.0000e+00\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4826 - precision: 0.0000e+00 - val_loss: 0.4623 - val_precision: 0.0000e+00\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.4823 - precision: 0.0000e+00 - val_loss: 0.4619 - val_precision: 0.0000e+00\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4819 - precision: 0.0000e+00 - val_loss: 0.4618 - val_precision: 0.0000e+00\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4816 - precision: 0.0000e+00 - val_loss: 0.4612 - val_precision: 0.0000e+00\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4814 - precision: 0.0000e+00 - val_loss: 0.4605 - val_precision: 0.0000e+00\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4815 - precision: 0.0000e+00 - val_loss: 0.4601 - val_precision: 0.0000e+00\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.4817 - precision: 0.0000e+00 - val_loss: 0.4610 - val_precision: 0.0000e+00\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.4802 - precision: 0.0000e+00 - val_loss: 0.4608 - val_precision: 0.0000e+00\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4797 - precision: 0.0000e+00 - val_loss: 0.4614 - val_precision: 0.0000e+00\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4797 - precision: 0.0000e+00 - val_loss: 0.4617 - val_precision: 0.0000e+00\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4792 - precision: 0.0000e+00 - val_loss: 0.4613 - val_precision: 0.0000e+00\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4788 - precision: 0.0000e+00 - val_loss: 0.4611 - val_precision: 0.0000e+00\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4783 - precision: 0.0000e+00 - val_loss: 0.4614 - val_precision: 0.0000e+00\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4784 - precision: 0.0000e+00 - val_loss: 0.4604 - val_precision: 0.0000e+00\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4777 - precision: 0.0000e+00 - val_loss: 0.4601 - val_precision: 0.0000e+00\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4772 - precision: 0.0000e+00 - val_loss: 0.4604 - val_precision: 0.0000e+00\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4770 - precision: 0.0000e+00 - val_loss: 0.4602 - val_precision: 0.0000e+00\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4768 - precision: 0.0000e+00 - val_loss: 0.4604 - val_precision: 0.0000e+00\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4764 - precision: 0.0000e+00 - val_loss: 0.4596 - val_precision: 0.0000e+00\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4759 - precision: 0.0000e+00 - val_loss: 0.4586 - val_precision: 0.0000e+00\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4763 - precision: 0.0000e+00 - val_loss: 0.4578 - val_precision: 0.0000e+00\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4756 - precision: 0.0000e+00 - val_loss: 0.4587 - val_precision: 0.0000e+00\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4752 - precision: 0.0000e+00 - val_loss: 0.4588 - val_precision: 0.0000e+00\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4750 - precision: 0.0000e+00 - val_loss: 0.4597 - val_precision: 0.0000e+00\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4748 - precision: 0.0000e+00 - val_loss: 0.4600 - val_precision: 0.0000e+00\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4744 - precision: 0.0000e+00 - val_loss: 0.4593 - val_precision: 0.0000e+00\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4738 - precision: 0.0000e+00 - val_loss: 0.4578 - val_precision: 0.0000e+00\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4735 - precision: 0.0000e+00 - val_loss: 0.4565 - val_precision: 0.0000e+00\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4732 - precision: 0.0000e+00 - val_loss: 0.4569 - val_precision: 0.0000e+00\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4728 - precision: 0.0000e+00 - val_loss: 0.4574 - val_precision: 0.0000e+00\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4728 - precision: 0.0000e+00 - val_loss: 0.4564 - val_precision: 0.0000e+00\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4722 - precision: 0.0000e+00 - val_loss: 0.4561 - val_precision: 0.0000e+00\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4721 - precision: 0.0000e+00 - val_loss: 0.4557 - val_precision: 0.0000e+00\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.4718 - precision: 0.0000e+00 - val_loss: 0.4562 - val_precision: 0.0000e+00\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4714 - precision: 0.0000e+00 - val_loss: 0.4557 - val_precision: 0.0000e+00\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4710 - precision: 0.0000e+00 - val_loss: 0.4551 - val_precision: 0.0000e+00\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4709 - precision: 0.0000e+00 - val_loss: 0.4552 - val_precision: 0.0000e+00\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4706 - precision: 0.0000e+00 - val_loss: 0.4548 - val_precision: 0.0000e+00\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4704 - precision: 0.0000e+00 - val_loss: 0.4548 - val_precision: 0.0000e+00\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4700 - precision: 0.0000e+00 - val_loss: 0.4539 - val_precision: 0.0000e+00\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4697 - precision: 0.0000e+00 - val_loss: 0.4535 - val_precision: 0.0000e+00\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4696 - precision: 0.0000e+00 - val_loss: 0.4533 - val_precision: 0.0000e+00\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4692 - precision: 0.0000e+00 - val_loss: 0.4538 - val_precision: 0.0000e+00\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4690 - precision: 0.0000e+00 - val_loss: 0.4540 - val_precision: 0.0000e+00\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4687 - precision: 0.0000e+00 - val_loss: 0.4538 - val_precision: 0.0000e+00\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4682 - precision: 0.0000e+00 - val_loss: 0.4532 - val_precision: 0.0000e+00\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4679 - precision: 0.0000e+00 - val_loss: 0.4534 - val_precision: 0.0000e+00\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4677 - precision: 0.0000e+00 - val_loss: 0.4537 - val_precision: 0.0000e+00\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4673 - precision: 0.0000e+00 - val_loss: 0.4543 - val_precision: 0.0000e+00\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4672 - precision: 0.0000e+00 - val_loss: 0.4534 - val_precision: 0.0000e+00\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4667 - precision: 0.0000e+00 - val_loss: 0.4543 - val_precision: 0.0000e+00\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4667 - precision: 0.0000e+00 - val_loss: 0.4537 - val_precision: 0.0000e+00\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.4662 - precision: 0.0000e+00 - val_loss: 0.4532 - val_precision: 0.0000e+00\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4659 - precision: 0.0000e+00 - val_loss: 0.4532 - val_precision: 0.0000e+00\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4656 - precision: 0.0000e+00 - val_loss: 0.4526 - val_precision: 0.0000e+00\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4653 - precision: 0.0000e+00 - val_loss: 0.4509 - val_precision: 0.0000e+00\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4654 - precision: 0.0000e+00 - val_loss: 0.4499 - val_precision: 0.0000e+00\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4652 - precision: 0.0000e+00 - val_loss: 0.4496 - val_precision: 0.0000e+00\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4650 - precision: 0.0000e+00 - val_loss: 0.4494 - val_precision: 0.0000e+00\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4647 - precision: 0.0000e+00 - val_loss: 0.4495 - val_precision: 0.0000e+00\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4645 - precision: 0.0000e+00 - val_loss: 0.4495 - val_precision: 0.0000e+00\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4641 - precision: 0.0000e+00 - val_loss: 0.4490 - val_precision: 0.0000e+00\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4636 - precision: 0.0000e+00 - val_loss: 0.4495 - val_precision: 0.0000e+00\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4633 - precision: 0.0000e+00 - val_loss: 0.4492 - val_precision: 0.0000e+00\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4630 - precision: 0.0000e+00 - val_loss: 0.4491 - val_precision: 0.0000e+00\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4627 - precision: 0.0000e+00 - val_loss: 0.4484 - val_precision: 0.0000e+00\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4626 - precision: 0.0000e+00 - val_loss: 0.4488 - val_precision: 0.0000e+00\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4620 - precision: 0.0000e+00 - val_loss: 0.4482 - val_precision: 0.0000e+00\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4618 - precision: 0.0000e+00 - val_loss: 0.4480 - val_precision: 0.0000e+00\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4617 - precision: 0.0000e+00 - val_loss: 0.4473 - val_precision: 0.0000e+00\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4618 - precision: 0.0000e+00 - val_loss: 0.4472 - val_precision: 0.0000e+00\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4612 - precision: 0.0000e+00 - val_loss: 0.4472 - val_precision: 0.0000e+00\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4609 - precision: 0.0000e+00 - val_loss: 0.4474 - val_precision: 0.0000e+00\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4607 - precision: 0.0000e+00 - val_loss: 0.4471 - val_precision: 0.0000e+00\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4605 - precision: 0.0000e+00 - val_loss: 0.4470 - val_precision: 0.0000e+00\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4601 - precision: 0.0000e+00 - val_loss: 0.4467 - val_precision: 0.0000e+00\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4599 - precision: 0.0000e+00 - val_loss: 0.4460 - val_precision: 0.0000e+00\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4603 - precision: 0.0000e+00 - val_loss: 0.4456 - val_precision: 0.0000e+00\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4596 - precision: 0.0000e+00 - val_loss: 0.4456 - val_precision: 0.0000e+00\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4592 - precision: 0.0000e+00 - val_loss: 0.4457 - val_precision: 0.0000e+00\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4587 - precision: 0.0000e+00 - val_loss: 0.4457 - val_precision: 0.0000e+00\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4581 - precision: 0.0000e+00 - val_loss: 0.4463 - val_precision: 0.0000e+00\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.4600 - precision: 0.0000e+00 - val_loss: 0.4501 - val_precision: 0.0000e+00\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4577 - precision: 0.0000e+00 - val_loss: 0.4497 - val_precision: 0.0000e+00\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4573 - precision: 0.0000e+00 - val_loss: 0.4490 - val_precision: 0.0000e+00\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.4575 - precision: 0.0000e+00 - val_loss: 0.4471 - val_precision: 0.0000e+00\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4563 - precision: 0.0000e+00 - val_loss: 0.4470 - val_precision: 0.0000e+00\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4561 - precision: 0.0000e+00 - val_loss: 0.4476 - val_precision: 0.0000e+00\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4558 - precision: 0.0000e+00 - val_loss: 0.4477 - val_precision: 0.0000e+00\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4556 - precision: 0.0000e+00 - val_loss: 0.4467 - val_precision: 0.0000e+00\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4552 - precision: 0.0000e+00 - val_loss: 0.4459 - val_precision: 0.0000e+00\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4550 - precision: 0.0000e+00 - val_loss: 0.4466 - val_precision: 0.0000e+00\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4552 - precision: 0.0000e+00 - val_loss: 0.4477 - val_precision: 0.0000e+00\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4546 - precision: 0.0000e+00 - val_loss: 0.4464 - val_precision: 0.0000e+00\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4539 - precision: 0.0000e+00 - val_loss: 0.4450 - val_precision: 0.0000e+00\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4537 - precision: 0.0000e+00 - val_loss: 0.4446 - val_precision: 0.0000e+00\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4538 - precision: 0.0000e+00 - val_loss: 0.4450 - val_precision: 0.0000e+00\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4530 - precision: 0.0000e+00 - val_loss: 0.4447 - val_precision: 0.0000e+00\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4528 - precision: 0.0000e+00 - val_loss: 0.4447 - val_precision: 0.0000e+00\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4526 - precision: 0.0000e+00 - val_loss: 0.4457 - val_precision: 0.0000e+00\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4521 - precision: 0.0000e+00 - val_loss: 0.4462 - val_precision: 0.0000e+00\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4521 - precision: 0.0000e+00 - val_loss: 0.4457 - val_precision: 0.0000e+00\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4524 - precision: 0.0000e+00 - val_loss: 0.4436 - val_precision: 0.0000e+00\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4513 - precision: 0.0000e+00 - val_loss: 0.4439 - val_precision: 0.0000e+00\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.4512 - precision: 0.0000e+00 - val_loss: 0.4449 - val_precision: 0.0000e+00\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4513 - precision: 0.0000e+00 - val_loss: 0.4434 - val_precision: 0.0000e+00\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4502 - precision: 0.0000e+00 - val_loss: 0.4430 - val_precision: 0.0000e+00\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4499 - precision: 0.0000e+00 - val_loss: 0.4423 - val_precision: 0.0000e+00\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4507 - precision: 0.0000e+00 - val_loss: 0.4448 - val_precision: 0.0000e+00\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4496 - precision: 0.0000e+00 - val_loss: 0.4455 - val_precision: 0.0000e+00\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4495 - precision: 0.0000e+00 - val_loss: 0.4439 - val_precision: 0.0000e+00\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4485 - precision: 0.0000e+00 - val_loss: 0.4420 - val_precision: 0.0000e+00\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4484 - precision: 0.0000e+00 - val_loss: 0.4412 - val_precision: 0.0000e+00\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4484 - precision: 0.0000e+00 - val_loss: 0.4410 - val_precision: 0.0000e+00\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4494 - precision: 0.0000e+00 - val_loss: 0.4449 - val_precision: 0.0000e+00\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4488 - precision: 0.0000e+00 - val_loss: 0.4446 - val_precision: 0.0000e+00\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4482 - precision: 0.0000e+00 - val_loss: 0.4435 - val_precision: 0.0000e+00\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4482 - precision: 0.0000e+00 - val_loss: 0.4416 - val_precision: 0.0000e+00\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4468 - precision: 0.0000e+00 - val_loss: 0.4428 - val_precision: 0.0000e+00\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4473 - precision: 0.0000e+00 - val_loss: 0.4429 - val_precision: 0.0000e+00\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4466 - precision: 0.0000e+00 - val_loss: 0.4416 - val_precision: 0.0000e+00\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4462 - precision: 0.0000e+00 - val_loss: 0.4402 - val_precision: 0.0000e+00\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4462 - precision: 0.0000e+00 - val_loss: 0.4390 - val_precision: 0.0000e+00\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4460 - precision: 0.0000e+00 - val_loss: 0.4385 - val_precision: 0.0000e+00\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4457 - precision: 0.0000e+00 - val_loss: 0.4386 - val_precision: 0.0000e+00\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4453 - precision: 0.0000e+00 - val_loss: 0.4385 - val_precision: 0.0000e+00\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4452 - precision: 0.0000e+00 - val_loss: 0.4395 - val_precision: 0.0000e+00\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4445 - precision: 0.0000e+00 - val_loss: 0.4391 - val_precision: 0.0000e+00\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4442 - precision: 0.0000e+00 - val_loss: 0.4388 - val_precision: 0.0000e+00\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4442 - precision: 0.0000e+00 - val_loss: 0.4381 - val_precision: 0.0000e+00\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4439 - precision: 0.0000e+00 - val_loss: 0.4384 - val_precision: 0.0000e+00\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4437 - precision: 0.0000e+00 - val_loss: 0.4378 - val_precision: 0.0000e+00\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4432 - precision: 0.0000e+00 - val_loss: 0.4378 - val_precision: 0.0000e+00\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.4428 - precision: 0.0000e+00 - val_loss: 0.4380 - val_precision: 0.0000e+00\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4426 - precision: 0.0000e+00 - val_loss: 0.4377 - val_precision: 0.0000e+00\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4429 - precision: 0.0000e+00 - val_loss: 0.4368 - val_precision: 0.0000e+00\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4421 - precision: 0.0000e+00 - val_loss: 0.4377 - val_precision: 0.0000e+00\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4417 - precision: 0.0000e+00 - val_loss: 0.4380 - val_precision: 0.0000e+00\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4412 - precision: 0.0000e+00 - val_loss: 0.4388 - val_precision: 0.0000e+00\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4414 - precision: 0.0000e+00 - val_loss: 0.4397 - val_precision: 0.0000e+00\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4411 - precision: 0.0000e+00 - val_loss: 0.4395 - val_precision: 0.0000e+00\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4407 - precision: 0.0000e+00 - val_loss: 0.4390 - val_precision: 0.0000e+00\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.4404 - precision: 0.0000e+00 - val_loss: 0.4383 - val_precision: 0.0000e+00\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4401 - precision: 0.0000e+00 - val_loss: 0.4366 - val_precision: 0.0000e+00\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.4396 - precision: 0.0000e+00 - val_loss: 0.4363 - val_precision: 0.0000e+00\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.4393 - precision: 0.0000e+00 - val_loss: 0.4354 - val_precision: 0.0000e+00\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.4396 - precision: 0.0000e+00 - val_loss: 0.4344 - val_precision: 0.0000e+00\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4402 - precision: 0.0000e+00 - val_loss: 0.4340 - val_precision: 0.0000e+00\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.4392 - precision: 0.0000e+00 - val_loss: 0.4345 - val_precision: 0.0000e+00\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4386 - precision: 0.0000e+00 - val_loss: 0.4348 - val_precision: 0.0000e+00\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4383 - precision: 0.0000e+00 - val_loss: 0.4355 - val_precision: 0.0000e+00\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4377 - precision: 0.0000e+00 - val_loss: 0.4359 - val_precision: 0.0000e+00\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4374 - precision: 0.0000e+00 - val_loss: 0.4362 - val_precision: 0.0000e+00\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4372 - precision: 0.0000e+00 - val_loss: 0.4369 - val_precision: 0.0000e+00\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.4371 - precision: 0.0000e+00 - val_loss: 0.4365 - val_precision: 0.0000e+00\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.4369 - precision: 0.0000e+00 - val_loss: 0.4378 - val_precision: 0.0000e+00\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4367 - precision: 0.0000e+00 - val_loss: 0.4365 - val_precision: 0.0000e+00\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.4363 - precision: 0.0000e+00 - val_loss: 0.4354 - val_precision: 0.0000e+00\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4361 - precision: 0.0000e+00 - val_loss: 0.4355 - val_precision: 0.0000e+00\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.4358 - precision: 0.0000e+00 - val_loss: 0.4346 - val_precision: 0.0000e+00\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.4356 - precision: 0.0000e+00 - val_loss: 0.4346 - val_precision: 0.0000e+00\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4355 - precision: 0.0000e+00 - val_loss: 0.4335 - val_precision: 0.0000e+00\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4351 - precision: 0.0000e+00 - val_loss: 0.4331 - val_precision: 0.0000e+00\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.4350 - precision: 0.0000e+00 - val_loss: 0.4330 - val_precision: 0.0000e+00\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4349 - precision: 0.0000e+00 - val_loss: 0.4324 - val_precision: 0.0000e+00\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.4345 - precision: 0.0000e+00 - val_loss: 0.4322 - val_precision: 0.0000e+00\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.4342 - precision: 0.0000e+00 - val_loss: 0.4322 - val_precision: 0.0000e+00\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.4338 - precision: 0.0000e+00 - val_loss: 0.4325 - val_precision: 0.0000e+00\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.4338 - precision: 0.0000e+00 - val_loss: 0.4318 - val_precision: 0.0000e+00\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.4335 - precision: 0.0000e+00 - val_loss: 0.4317 - val_precision: 0.0000e+00\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4333 - precision: 0.0000e+00 - val_loss: 0.4334 - val_precision: 0.0000e+00\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4333 - precision: 0.0000e+00 - val_loss: 0.4348 - val_precision: 0.0000e+00\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4335 - precision: 0.0000e+00 - val_loss: 0.4347 - val_precision: 0.0000e+00\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.4341 - precision: 0.0000e+00 - val_loss: 0.4351 - val_precision: 0.0000e+00\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4335 - precision: 0.0000e+00 - val_loss: 0.4329 - val_precision: 0.0000e+00\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4324 - precision: 0.0000e+00 - val_loss: 0.4332 - val_precision: 0.0000e+00\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.4324 - precision: 0.0000e+00 - val_loss: 0.4327 - val_precision: 0.0000e+00\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4324 - precision: 0.0000e+00 - val_loss: 0.4325 - val_precision: 0.0000e+00\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4316 - precision: 0.0000e+00 - val_loss: 0.4315 - val_precision: 0.0000e+00\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4319 - precision: 0.0000e+00 - val_loss: 0.4296 - val_precision: 0.0000e+00\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4315 - precision: 0.0000e+00 - val_loss: 0.4296 - val_precision: 0.0000e+00\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4313 - precision: 0.0000e+00 - val_loss: 0.4296 - val_precision: 0.0000e+00\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.4313 - precision: 0.0000e+00 - val_loss: 0.4301 - val_precision: 0.0000e+00\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4307 - precision: 0.0000e+00 - val_loss: 0.4300 - val_precision: 0.0000e+00\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.4304 - precision: 0.0000e+00 - val_loss: 0.4300 - val_precision: 0.0000e+00\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.4301 - precision: 0.0000e+00 - val_loss: 0.4304 - val_precision: 0.0000e+00\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.4300 - precision: 0.0000e+00 - val_loss: 0.4297 - val_precision: 0.0000e+00\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.4303 - precision: 0.0000e+00 - val_loss: 0.4311 - val_precision: 0.0000e+00\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4298 - precision: 0.0000e+00 - val_loss: 0.4312 - val_precision: 0.0000e+00\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.4298 - precision: 0.0000e+00 - val_loss: 0.4305 - val_precision: 0.0000e+00\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4294 - precision: 0.0000e+00 - val_loss: 0.4299 - val_precision: 0.0000e+00\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4290 - precision: 0.0000e+00 - val_loss: 0.4295 - val_precision: 0.0000e+00\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4293 - precision: 0.0000e+00 - val_loss: 0.4284 - val_precision: 0.0000e+00\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.4287 - precision: 0.0000e+00 - val_loss: 0.4294 - val_precision: 0.0000e+00\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.4287 - precision: 0.0000e+00 - val_loss: 0.4294 - val_precision: 0.0000e+00\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.4287 - precision: 0.0000e+00 - val_loss: 0.4293 - val_precision: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300\n",
    "history = modela_glove_next_rate.fit(padded, training_labels_final, \n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(val_padded, val_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "J6cOVKfVND25",
    "outputId": "412b54a0-e97a-48b8-f4c5-32097e44328a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "precision = history.history['precision']\n",
    "val_precision = history.history['val_precision']\n",
    "epochs=range(len(precision))\n",
    "plt.plot(epochs, precision, 'r')\n",
    "plt.plot(epochs, val_precision, 'b')\n",
    "plt.title('Training and validation Precision')\n",
    "plt.ylim((0,1.5))\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "pNWiLctvND26",
    "outputId": "49befbd2-e0d0-437e-fc11-4026b5874610",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5145 - precision: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5145053863525391, 0.0]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modela_glove_next_rate.evaluate(test_padded, test_labels_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model B, GloVE 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelb_glove200 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], input_length = max_length, trainable=False),  \n",
    "    tf.keras.layers.Conv1D(128, 5, activation=\"relu\"),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "modelb_glove200.compile(loss='binary_crossentropy', \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1200, 200)         1000400   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 1196, 128)         128128    \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 774       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,129,309\n",
      "Trainable params: 128,909\n",
      "Non-trainable params: 1,000,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelb_glove200.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 2s 199ms/step - loss: 0.6308 - precision: 0.0000e+00 - val_loss: 0.5749 - val_precision: 0.0000e+00\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 2s 172ms/step - loss: 0.5557 - precision: 0.0000e+00 - val_loss: 0.5401 - val_precision: 0.0000e+00\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 2s 171ms/step - loss: 0.5528 - precision: 0.0000e+00 - val_loss: 0.5319 - val_precision: 0.0000e+00\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 2s 176ms/step - loss: 0.5493 - precision: 0.0000e+00 - val_loss: 0.5269 - val_precision: 0.0000e+00\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 160ms/step - loss: 0.5409 - precision: 0.0000e+00 - val_loss: 0.5244 - val_precision: 0.0000e+00\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.5336 - precision: 0.0000e+00 - val_loss: 0.5236 - val_precision: 0.0000e+00\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 132ms/step - loss: 0.5308 - precision: 0.0000e+00 - val_loss: 0.5242 - val_precision: 0.0000e+00\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 0.5270 - precision: 0.0000e+00 - val_loss: 0.5175 - val_precision: 0.0000e+00\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 0.5223 - precision: 0.0000e+00 - val_loss: 0.5125 - val_precision: 0.0000e+00\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.5188 - precision: 0.0000e+00 - val_loss: 0.5088 - val_precision: 0.0000e+00\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 164ms/step - loss: 0.5139 - precision: 0.0000e+00 - val_loss: 0.4990 - val_precision: 0.0000e+00\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.5101 - precision: 0.0000e+00 - val_loss: 0.4953 - val_precision: 0.0000e+00\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 168ms/step - loss: 0.5061 - precision: 0.0000e+00 - val_loss: 0.4931 - val_precision: 0.0000e+00\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 0.5007 - precision: 0.0000e+00 - val_loss: 0.4882 - val_precision: 0.0000e+00\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.4969 - precision: 0.0000e+00 - val_loss: 0.4828 - val_precision: 0.0000e+00\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.4921 - precision: 0.0000e+00 - val_loss: 0.4824 - val_precision: 0.0000e+00\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 0.4878 - precision: 0.0000e+00 - val_loss: 0.4723 - val_precision: 0.0000e+00\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.4850 - precision: 0.0000e+00 - val_loss: 0.4665 - val_precision: 0.0000e+00\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 160ms/step - loss: 0.4802 - precision: 0.0000e+00 - val_loss: 0.4807 - val_precision: 0.0000e+00\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.4769 - precision: 0.0000e+00 - val_loss: 0.4641 - val_precision: 0.0000e+00\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.4680 - precision: 0.0000e+00 - val_loss: 0.4545 - val_precision: 0.0000e+00\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 2s 174ms/step - loss: 0.4655 - precision: 0.0000e+00 - val_loss: 0.4499 - val_precision: 0.0000e+00\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.4624 - precision: 0.0000e+00 - val_loss: 0.4497 - val_precision: 0.0000e+00\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.4545 - precision: 0.0000e+00 - val_loss: 0.4480 - val_precision: 0.0000e+00\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.4522 - precision: 0.0000e+00 - val_loss: 0.4484 - val_precision: 0.0000e+00\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.4665 - precision: 0.0000e+00 - val_loss: 0.4758 - val_precision: 0.0000e+00\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.4539 - precision: 0.0000e+00 - val_loss: 0.4377 - val_precision: 0.0000e+00\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 0.4533 - precision: 0.0000e+00 - val_loss: 0.4354 - val_precision: 0.0000e+00\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 0.4490 - precision: 0.0000e+00 - val_loss: 0.4345 - val_precision: 0.0000e+00\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 0.4441 - precision: 0.0000e+00 - val_loss: 0.4506 - val_precision: 0.0000e+00\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.4449 - precision: 0.0000e+00 - val_loss: 0.4332 - val_precision: 0.0000e+00\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.4353 - precision: 0.0000e+00 - val_loss: 0.4289 - val_precision: 0.0000e+00\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.4355 - precision: 0.0000e+00 - val_loss: 0.4334 - val_precision: 0.0000e+00\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.4346 - precision: 0.0000e+00 - val_loss: 0.4295 - val_precision: 0.0000e+00\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.4324 - precision: 0.0000e+00 - val_loss: 0.4249 - val_precision: 0.0000e+00\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 2s 166ms/step - loss: 0.4322 - precision: 0.0000e+00 - val_loss: 0.4264 - val_precision: 0.0000e+00\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 2s 177ms/step - loss: 0.4302 - precision: 0.0000e+00 - val_loss: 0.4274 - val_precision: 0.0000e+00\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 2s 163ms/step - loss: 0.4325 - precision: 0.0000e+00 - val_loss: 0.4250 - val_precision: 0.0000e+00\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 1s 162ms/step - loss: 0.4274 - precision: 0.0000e+00 - val_loss: 0.4215 - val_precision: 0.0000e+00\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 1s 166ms/step - loss: 0.4287 - precision: 0.0000e+00 - val_loss: 0.4260 - val_precision: 0.0000e+00\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.4242 - precision: 0.0000e+00 - val_loss: 0.4190 - val_precision: 0.0000e+00\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.4253 - precision: 0.0000e+00 - val_loss: 0.4202 - val_precision: 0.0000e+00\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.4270 - precision: 0.0000e+00 - val_loss: 0.4327 - val_precision: 0.0000e+00\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 2s 169ms/step - loss: 0.4215 - precision: 0.0000e+00 - val_loss: 0.4176 - val_precision: 0.0000e+00\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.4201 - precision: 0.0000e+00 - val_loss: 0.4176 - val_precision: 0.0000e+00\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 1s 168ms/step - loss: 0.4190 - precision: 0.0000e+00 - val_loss: 0.4162 - val_precision: 0.0000e+00\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 2s 171ms/step - loss: 0.4172 - precision: 0.0000e+00 - val_loss: 0.4165 - val_precision: 0.0000e+00\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 2s 175ms/step - loss: 0.4156 - precision: 0.0000e+00 - val_loss: 0.4144 - val_precision: 0.0000e+00\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.4142 - precision: 0.0000e+00 - val_loss: 0.4173 - val_precision: 0.0000e+00\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 2s 171ms/step - loss: 0.4138 - precision: 0.0000e+00 - val_loss: 0.4209 - val_precision: 0.0000e+00\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.4139 - precision: 0.0000e+00 - val_loss: 0.4118 - val_precision: 0.0000e+00\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 0.4121 - precision: 0.0000e+00 - val_loss: 0.4163 - val_precision: 0.0000e+00\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.4088 - precision: 0.0000e+00 - val_loss: 0.4138 - val_precision: 0.0000e+00\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 2s 167ms/step - loss: 0.4092 - precision: 0.0000e+00 - val_loss: 0.4215 - val_precision: 0.0000e+00\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.4042 - precision: 0.0000e+00 - val_loss: 0.4088 - val_precision: 0.0000e+00\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 1s 140ms/step - loss: 0.4106 - precision: 0.0000e+00 - val_loss: 0.4083 - val_precision: 0.0000e+00\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 0.4050 - precision: 0.0000e+00 - val_loss: 0.4175 - val_precision: 0.0000e+00\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.4051 - precision: 0.0000e+00 - val_loss: 0.4114 - val_precision: 0.0000e+00\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 1s 156ms/step - loss: 0.4029 - precision: 0.0000e+00 - val_loss: 0.4149 - val_precision: 0.0000e+00\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 1s 162ms/step - loss: 0.4143 - precision: 0.0000e+00 - val_loss: 0.4287 - val_precision: 0.0000e+00\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 1s 156ms/step - loss: 0.4005 - precision: 0.0000e+00 - val_loss: 0.4056 - val_precision: 0.0000e+00\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.4053 - precision: 0.0000e+00 - val_loss: 0.4105 - val_precision: 0.0000e+00\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.4041 - precision: 0.0000e+00 - val_loss: 0.4079 - val_precision: 0.0000e+00\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.4064 - precision: 0.0000e+00 - val_loss: 0.4177 - val_precision: 0.0000e+00\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.4030 - precision: 0.0000e+00 - val_loss: 0.4047 - val_precision: 0.0000e+00\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.3978 - precision: 0.0000e+00 - val_loss: 0.4174 - val_precision: 0.0000e+00\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 1s 143ms/step - loss: 0.3984 - precision: 0.0000e+00 - val_loss: 0.4121 - val_precision: 0.0000e+00\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.3967 - precision: 0.0000e+00 - val_loss: 0.4100 - val_precision: 0.0000e+00\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.3969 - precision: 0.0000e+00 - val_loss: 0.4086 - val_precision: 0.0000e+00\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 2s 174ms/step - loss: 0.4042 - precision: 0.0000e+00 - val_loss: 0.4136 - val_precision: 0.0000e+00\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 2s 169ms/step - loss: 0.3957 - precision: 0.0000e+00 - val_loss: 0.4039 - val_precision: 0.0000e+00\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 1s 162ms/step - loss: 0.3982 - precision: 0.0000e+00 - val_loss: 0.4218 - val_precision: 0.0000e+00\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 0.3975 - precision: 0.0000e+00 - val_loss: 0.4038 - val_precision: 0.0000e+00\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.3934 - precision: 0.0000e+00 - val_loss: 0.4078 - val_precision: 0.0000e+00\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 1s 164ms/step - loss: 0.3916 - precision: 0.0000e+00 - val_loss: 0.4078 - val_precision: 0.0000e+00\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.3907 - precision: 0.0000e+00 - val_loss: 0.4141 - val_precision: 0.0000e+00\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.3984 - precision: 0.7391 - val_loss: 0.4191 - val_precision: 0.7500\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 1s 131ms/step - loss: 0.3887 - precision: 0.9412 - val_loss: 0.4023 - val_precision: 0.8000\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 1s 133ms/step - loss: 0.4015 - precision: 0.9286 - val_loss: 0.4020 - val_precision: 0.8000\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 1s 129ms/step - loss: 0.3855 - precision: 0.9444 - val_loss: 0.4163 - val_precision: 0.8571\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 1s 136ms/step - loss: 0.3916 - precision: 0.8261 - val_loss: 0.4064 - val_precision: 0.8000\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 1s 156ms/step - loss: 0.3917 - precision: 0.9286 - val_loss: 0.4051 - val_precision: 0.8000\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 2s 173ms/step - loss: 0.3886 - precision: 0.9375 - val_loss: 0.4178 - val_precision: 0.7500\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 1s 162ms/step - loss: 0.3889 - precision: 0.8333 - val_loss: 0.4094 - val_precision: 0.8000\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.3857 - precision: 0.9474 - val_loss: 0.4055 - val_precision: 0.8000\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 1s 169ms/step - loss: 0.3878 - precision: 0.9375 - val_loss: 0.4064 - val_precision: 0.8000\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 1s 156ms/step - loss: 0.3909 - precision: 0.8636 - val_loss: 0.4159 - val_precision: 0.6667\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 1s 153ms/step - loss: 0.3930 - precision: 0.8400 - val_loss: 0.4136 - val_precision: 0.7143\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 0.3903 - precision: 0.9375 - val_loss: 0.4007 - val_precision: 0.8000\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 1s 140ms/step - loss: 0.3842 - precision: 0.9412 - val_loss: 0.4152 - val_precision: 0.7500\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 1s 162ms/step - loss: 0.3873 - precision: 0.8333 - val_loss: 0.4136 - val_precision: 0.7143\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 0.3854 - precision: 0.9474 - val_loss: 0.4030 - val_precision: 0.8000\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 1s 153ms/step - loss: 0.3878 - precision: 0.8947 - val_loss: 0.4086 - val_precision: 0.8000\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 1s 156ms/step - loss: 0.3835 - precision: 0.9412 - val_loss: 0.4031 - val_precision: 0.8000\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 2s 177ms/step - loss: 0.3810 - precision: 0.9412 - val_loss: 0.4096 - val_precision: 0.8571\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 2s 162ms/step - loss: 0.3823 - precision: 0.8261 - val_loss: 0.4111 - val_precision: 0.8571\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 1s 165ms/step - loss: 0.3808 - precision: 0.9091 - val_loss: 0.4023 - val_precision: 0.8000\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.3863 - precision: 0.9333 - val_loss: 0.3997 - val_precision: 0.8000\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.3772 - precision: 0.9444 - val_loss: 0.4087 - val_precision: 0.8571\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 1s 164ms/step - loss: 0.3812 - precision: 0.8462 - val_loss: 0.4094 - val_precision: 0.8571\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 1s 165ms/step - loss: 0.3753 - precision: 0.9474 - val_loss: 0.3987 - val_precision: 0.7500\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 1s 163ms/step - loss: 0.3832 - precision: 0.9412 - val_loss: 0.4120 - val_precision: 0.7500\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 2s 170ms/step - loss: 0.3779 - precision: 0.8261 - val_loss: 0.4056 - val_precision: 0.8571\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 2s 183ms/step - loss: 0.3790 - precision: 0.9412 - val_loss: 0.4044 - val_precision: 0.8333\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 1s 166ms/step - loss: 0.3757 - precision: 0.8750 - val_loss: 0.4032 - val_precision: 0.8333\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 1s 160ms/step - loss: 0.3861 - precision: 0.9412 - val_loss: 0.4024 - val_precision: 0.8333\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 2s 184ms/step - loss: 0.3822 - precision: 0.7333 - val_loss: 0.4215 - val_precision: 0.5455\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 2s 172ms/step - loss: 0.3762 - precision: 0.8000 - val_loss: 0.3975 - val_precision: 0.8000\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 2s 172ms/step - loss: 0.3838 - precision: 0.9375 - val_loss: 0.4041 - val_precision: 0.8571\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 2s 172ms/step - loss: 0.3750 - precision: 0.8400 - val_loss: 0.4071 - val_precision: 0.8571\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 2s 172ms/step - loss: 0.3731 - precision: 0.9000 - val_loss: 0.3993 - val_precision: 0.8000\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 1s 141ms/step - loss: 0.3746 - precision: 0.9444 - val_loss: 0.4012 - val_precision: 0.8333\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 1s 129ms/step - loss: 0.3719 - precision: 0.8636 - val_loss: 0.4086 - val_precision: 0.7500\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.3727 - precision: 0.8750 - val_loss: 0.4008 - val_precision: 0.8333\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 2s 195ms/step - loss: 0.3745 - precision: 0.9375 - val_loss: 0.4019 - val_precision: 0.8571\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 2s 182ms/step - loss: 0.3708 - precision: 0.9167 - val_loss: 0.4153 - val_precision: 0.6000\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 2s 195ms/step - loss: 0.3724 - precision: 0.7857 - val_loss: 0.4024 - val_precision: 0.8571\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 1s 164ms/step - loss: 0.3756 - precision: 0.9375 - val_loss: 0.3986 - val_precision: 0.8333\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 1s 143ms/step - loss: 0.3708 - precision: 0.7857 - val_loss: 0.4332 - val_precision: 0.5385\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 1s 137ms/step - loss: 0.3832 - precision: 0.7500 - val_loss: 0.4115 - val_precision: 0.6667\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 1s 131ms/step - loss: 0.3690 - precision: 0.8500 - val_loss: 0.3955 - val_precision: 0.8000\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 1s 135ms/step - loss: 0.3727 - precision: 0.9000 - val_loss: 0.4049 - val_precision: 0.6667\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 1s 129ms/step - loss: 0.3673 - precision: 0.8800 - val_loss: 0.4019 - val_precision: 0.8571\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 1s 142ms/step - loss: 0.3678 - precision: 0.8500 - val_loss: 0.3976 - val_precision: 0.8333\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.3660 - precision: 0.8571 - val_loss: 0.4099 - val_precision: 0.6000\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 2s 171ms/step - loss: 0.3690 - precision: 0.8800 - val_loss: 0.4031 - val_precision: 0.7500\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 2s 172ms/step - loss: 0.3656 - precision: 0.8800 - val_loss: 0.4068 - val_precision: 0.6000\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 1s 166ms/step - loss: 0.3677 - precision: 0.7667 - val_loss: 0.4126 - val_precision: 0.6000\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 2s 171ms/step - loss: 0.3633 - precision: 0.8696 - val_loss: 0.3959 - val_precision: 0.8333\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 2s 251ms/step - loss: 0.3648 - precision: 0.9091 - val_loss: 0.4087 - val_precision: 0.6000\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 2s 189ms/step - loss: 0.3626 - precision: 0.8800 - val_loss: 0.3965 - val_precision: 0.8333\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.3701 - precision: 0.9444 - val_loss: 0.4071 - val_precision: 0.6000\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 1s 138ms/step - loss: 0.3638 - precision: 0.7667 - val_loss: 0.4211 - val_precision: 0.5833\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 1s 141ms/step - loss: 0.3707 - precision: 0.7500 - val_loss: 0.4154 - val_precision: 0.6000\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 1s 160ms/step - loss: 0.3752 - precision: 0.8500 - val_loss: 0.3963 - val_precision: 0.8333\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 0.3683 - precision: 0.8400 - val_loss: 0.4168 - val_precision: 0.6364\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.3604 - precision: 0.8462 - val_loss: 0.3956 - val_precision: 0.8333\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 0.3636 - precision: 0.9048 - val_loss: 0.4024 - val_precision: 0.6667\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 0.3609 - precision: 0.8800 - val_loss: 0.4057 - val_precision: 0.6667\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 2s 245ms/step - loss: 0.3597 - precision: 0.8800 - val_loss: 0.4037 - val_precision: 0.6667\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 2s 225ms/step - loss: 0.3600 - precision: 0.8148 - val_loss: 0.4093 - val_precision: 0.6000\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 2s 196ms/step - loss: 0.3606 - precision: 0.8696 - val_loss: 0.3983 - val_precision: 0.8333\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 2s 226ms/step - loss: 0.3588 - precision: 0.8800 - val_loss: 0.4149 - val_precision: 0.6364\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 2s 217ms/step - loss: 0.3601 - precision: 0.8800 - val_loss: 0.4003 - val_precision: 0.8333\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 2s 217ms/step - loss: 0.3572 - precision: 0.8750 - val_loss: 0.4085 - val_precision: 0.6000\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 2s 216ms/step - loss: 0.3603 - precision: 0.8636 - val_loss: 0.4082 - val_precision: 0.6000\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 2s 193ms/step - loss: 0.3727 - precision: 0.7742 - val_loss: 0.4219 - val_precision: 0.5385\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 2s 223ms/step - loss: 0.3564 - precision: 0.8400 - val_loss: 0.3959 - val_precision: 0.8000\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 2s 176ms/step - loss: 0.3595 - precision: 0.9130 - val_loss: 0.4106 - val_precision: 0.6000\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 2s 180ms/step - loss: 0.3544 - precision: 0.8800 - val_loss: 0.3993 - val_precision: 0.8333\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 0.3547 - precision: 0.9091 - val_loss: 0.4053 - val_precision: 0.6000\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 2s 195ms/step - loss: 0.3542 - precision: 0.8800 - val_loss: 0.4069 - val_precision: 0.6000\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 1s 156ms/step - loss: 0.3561 - precision: 0.8000 - val_loss: 0.4043 - val_precision: 0.6000\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 1s 160ms/step - loss: 0.3578 - precision: 0.8696 - val_loss: 0.4072 - val_precision: 0.6000\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 2s 173ms/step - loss: 0.3852 - precision: 0.7027 - val_loss: 0.4363 - val_precision: 0.5385\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 2s 174ms/step - loss: 0.3575 - precision: 0.8636 - val_loss: 0.3948 - val_precision: 0.8333\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.3576 - precision: 0.8750 - val_loss: 0.4084 - val_precision: 0.6000\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 1s 156ms/step - loss: 0.3527 - precision: 0.8800 - val_loss: 0.4056 - val_precision: 0.6000\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 1s 163ms/step - loss: 0.3527 - precision: 0.7857 - val_loss: 0.3996 - val_precision: 0.8333\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 1s 135ms/step - loss: 0.3507 - precision: 0.9091 - val_loss: 0.3964 - val_precision: 0.8333\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 1s 165ms/step - loss: 0.3529 - precision: 0.9000 - val_loss: 0.4141 - val_precision: 0.6364\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.3512 - precision: 0.8000 - val_loss: 0.4037 - val_precision: 0.6000\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 1s 165ms/step - loss: 0.3587 - precision: 0.8947 - val_loss: 0.4002 - val_precision: 0.7143\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 1s 167ms/step - loss: 0.3513 - precision: 0.8148 - val_loss: 0.4164 - val_precision: 0.6364\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.3472 - precision: 0.8462 - val_loss: 0.3965 - val_precision: 0.8333\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.3512 - precision: 0.9091 - val_loss: 0.4025 - val_precision: 0.6250\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 0.3481 - precision: 0.8800 - val_loss: 0.4004 - val_precision: 0.7143\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.3470 - precision: 0.9130 - val_loss: 0.4043 - val_precision: 0.6000\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.3455 - precision: 0.8800 - val_loss: 0.3985 - val_precision: 0.8333\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.3467 - precision: 0.9091 - val_loss: 0.4009 - val_precision: 0.6250\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.3473 - precision: 0.9167 - val_loss: 0.4050 - val_precision: 0.6667\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 1s 167ms/step - loss: 0.3489 - precision: 0.9091 - val_loss: 0.3995 - val_precision: 0.7143\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 1s 156ms/step - loss: 0.3539 - precision: 0.8065 - val_loss: 0.4068 - val_precision: 0.6000\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 2s 174ms/step - loss: 0.3502 - precision: 0.9130 - val_loss: 0.3960 - val_precision: 0.8333\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 1s 165ms/step - loss: 0.3476 - precision: 0.8800 - val_loss: 0.4138 - val_precision: 0.6364\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 2s 172ms/step - loss: 0.3428 - precision: 0.8800 - val_loss: 0.4004 - val_precision: 0.6250\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 0.3424 - precision: 0.9167 - val_loss: 0.4041 - val_precision: 0.6000\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 2s 178ms/step - loss: 0.3419 - precision: 0.8750 - val_loss: 0.4015 - val_precision: 0.6250\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 2s 178ms/step - loss: 0.3448 - precision: 0.8750 - val_loss: 0.4023 - val_precision: 0.5556\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 2s 170ms/step - loss: 0.3423 - precision: 0.9130 - val_loss: 0.4009 - val_precision: 0.7143\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 2s 183ms/step - loss: 0.3416 - precision: 0.9091 - val_loss: 0.4017 - val_precision: 0.6250\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 2s 174ms/step - loss: 0.3400 - precision: 0.9130 - val_loss: 0.4051 - val_precision: 0.6000\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 1s 156ms/step - loss: 0.3388 - precision: 0.8800 - val_loss: 0.4037 - val_precision: 0.6667\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 1s 143ms/step - loss: 0.3393 - precision: 0.8800 - val_loss: 0.4029 - val_precision: 0.6250\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 1s 165ms/step - loss: 0.3390 - precision: 0.9130 - val_loss: 0.4042 - val_precision: 0.6000\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 1s 163ms/step - loss: 0.3374 - precision: 0.8800 - val_loss: 0.4027 - val_precision: 0.6250\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 1s 160ms/step - loss: 0.3381 - precision: 0.9130 - val_loss: 0.3986 - val_precision: 0.8333\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 1s 142ms/step - loss: 0.3455 - precision: 0.8696 - val_loss: 0.4087 - val_precision: 0.6000\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 0.3387 - precision: 0.8800 - val_loss: 0.4001 - val_precision: 0.8333\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 2s 181ms/step - loss: 0.3400 - precision: 0.9130 - val_loss: 0.4013 - val_precision: 0.7143\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 2s 162ms/step - loss: 0.3478 - precision: 0.8276 - val_loss: 0.4207 - val_precision: 0.5833\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.3459 - precision: 0.8333 - val_loss: 0.4073 - val_precision: 0.6000\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 1s 163ms/step - loss: 0.3343 - precision: 0.8800 - val_loss: 0.4077 - val_precision: 0.6000\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.3336 - precision: 0.8800 - val_loss: 0.4016 - val_precision: 0.7143\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.3399 - precision: 0.9545 - val_loss: 0.4157 - val_precision: 0.6364\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 1s 169ms/step - loss: 0.3560 - precision: 0.7297 - val_loss: 0.4116 - val_precision: 0.6364\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.3320 - precision: 0.8750 - val_loss: 0.3972 - val_precision: 0.8000\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 0.3390 - precision: 0.9130 - val_loss: 0.4022 - val_precision: 0.5556\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 2s 171ms/step - loss: 0.3324 - precision: 0.9130 - val_loss: 0.4019 - val_precision: 0.6250\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 1s 166ms/step - loss: 0.3312 - precision: 0.9130 - val_loss: 0.4058 - val_precision: 0.5556\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 1s 164ms/step - loss: 0.3325 - precision: 0.8889 - val_loss: 0.4084 - val_precision: 0.6000\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 2s 170ms/step - loss: 0.3295 - precision: 0.9130 - val_loss: 0.4040 - val_precision: 0.6250\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 2s 171ms/step - loss: 0.3293 - precision: 0.9130 - val_loss: 0.4042 - val_precision: 0.6250\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 2s 168ms/step - loss: 0.3317 - precision: 0.8800 - val_loss: 0.4111 - val_precision: 0.6000\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 2s 166ms/step - loss: 0.3299 - precision: 0.8800 - val_loss: 0.4037 - val_precision: 0.8333\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 1s 167ms/step - loss: 0.3294 - precision: 0.9167 - val_loss: 0.4055 - val_precision: 0.7143\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.3452 - precision: 0.9474 - val_loss: 0.4086 - val_precision: 0.6250\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.3435 - precision: 0.8276 - val_loss: 0.4065 - val_precision: 0.6250\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 1s 160ms/step - loss: 0.3294 - precision: 0.9545 - val_loss: 0.4044 - val_precision: 0.7143\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 1s 164ms/step - loss: 0.3277 - precision: 0.9545 - val_loss: 0.4074 - val_precision: 0.5556\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 2s 174ms/step - loss: 0.3262 - precision: 0.8846 - val_loss: 0.4086 - val_precision: 0.5556\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 2s 183ms/step - loss: 0.3297 - precision: 0.9545 - val_loss: 0.4171 - val_precision: 0.6364\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 2s 179ms/step - loss: 0.3989 - precision: 0.5490 - val_loss: 0.4232 - val_precision: 0.5833\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 2s 168ms/step - loss: 0.3462 - precision: 0.9545 - val_loss: 0.4126 - val_precision: 0.6667\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 0.3312 - precision: 0.9524 - val_loss: 0.4125 - val_precision: 0.5833\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 1s 141ms/step - loss: 0.3310 - precision: 0.8387 - val_loss: 0.4051 - val_precision: 0.6250\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 1s 134ms/step - loss: 0.3264 - precision: 0.8696 - val_loss: 0.4048 - val_precision: 0.6250\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 0.3254 - precision: 0.9130 - val_loss: 0.4060 - val_precision: 0.6667\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 0.3242 - precision: 0.8800 - val_loss: 0.4078 - val_precision: 0.6000\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 1s 162ms/step - loss: 0.3233 - precision: 0.9545 - val_loss: 0.4047 - val_precision: 0.5714\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 2s 171ms/step - loss: 0.3257 - precision: 0.8750 - val_loss: 0.4103 - val_precision: 0.6000\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 2s 175ms/step - loss: 0.3280 - precision: 0.9524 - val_loss: 0.4063 - val_precision: 0.8000\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 2s 184ms/step - loss: 0.3214 - precision: 0.9130 - val_loss: 0.4143 - val_precision: 0.7000\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 2s 173ms/step - loss: 0.3315 - precision: 0.8438 - val_loss: 0.4066 - val_precision: 0.6667\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 1s 153ms/step - loss: 0.3373 - precision: 0.9444 - val_loss: 0.4118 - val_precision: 0.6000\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 0.3232 - precision: 0.8929 - val_loss: 0.4139 - val_precision: 0.6000\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.3226 - precision: 0.9545 - val_loss: 0.4071 - val_precision: 0.5000\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 1s 136ms/step - loss: 0.3218 - precision: 0.9259 - val_loss: 0.4129 - val_precision: 0.6000\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 1s 128ms/step - loss: 0.3188 - precision: 0.9565 - val_loss: 0.4067 - val_precision: 0.6667\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 0.3192 - precision: 0.9524 - val_loss: 0.4190 - val_precision: 0.5833\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 2s 168ms/step - loss: 0.3169 - precision: 0.8966 - val_loss: 0.4095 - val_precision: 0.5714\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 2s 172ms/step - loss: 0.3151 - precision: 0.9565 - val_loss: 0.4083 - val_precision: 0.6667\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 1s 162ms/step - loss: 0.3205 - precision: 0.9167 - val_loss: 0.4140 - val_precision: 0.6000\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.3156 - precision: 0.9545 - val_loss: 0.4113 - val_precision: 0.5714\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 1s 168ms/step - loss: 0.3155 - precision: 0.9231 - val_loss: 0.4179 - val_precision: 0.6364\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 0.3153 - precision: 0.9583 - val_loss: 0.4104 - val_precision: 0.5000\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 1s 142ms/step - loss: 0.3207 - precision: 0.9524 - val_loss: 0.4095 - val_precision: 0.5000\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.3130 - precision: 0.9231 - val_loss: 0.4138 - val_precision: 0.6000\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.3182 - precision: 0.9545 - val_loss: 0.4120 - val_precision: 0.6250\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.3121 - precision: 0.9583 - val_loss: 0.4211 - val_precision: 0.5833\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.3218 - precision: 0.8710 - val_loss: 0.4113 - val_precision: 0.5714\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.3141 - precision: 0.9545 - val_loss: 0.4168 - val_precision: 0.6000\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.3129 - precision: 0.9231 - val_loss: 0.4154 - val_precision: 0.5556\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 1s 163ms/step - loss: 0.3108 - precision: 0.9259 - val_loss: 0.4102 - val_precision: 0.5000\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.3123 - precision: 0.9565 - val_loss: 0.4139 - val_precision: 0.6250\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 1s 162ms/step - loss: 0.3115 - precision: 0.9259 - val_loss: 0.4130 - val_precision: 0.6250\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 1s 138ms/step - loss: 0.3101 - precision: 0.9565 - val_loss: 0.4107 - val_precision: 0.6250\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.3093 - precision: 0.9600 - val_loss: 0.4125 - val_precision: 0.6250\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 1s 143ms/step - loss: 0.3122 - precision: 0.9583 - val_loss: 0.4115 - val_precision: 0.6667\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.3127 - precision: 0.9583 - val_loss: 0.4184 - val_precision: 0.6667\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 1s 142ms/step - loss: 0.3071 - precision: 0.9231 - val_loss: 0.4130 - val_precision: 0.6250\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.3128 - precision: 0.9565 - val_loss: 0.4330 - val_precision: 0.5385\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.3168 - precision: 0.8485 - val_loss: 0.4129 - val_precision: 0.6667\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 0.3118 - precision: 0.9524 - val_loss: 0.4167 - val_precision: 0.6250\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 1s 140ms/step - loss: 0.3037 - precision: 0.9259 - val_loss: 0.4234 - val_precision: 0.5455\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.3043 - precision: 0.9259 - val_loss: 0.4145 - val_precision: 0.6250\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 0.3211 - precision: 0.9500 - val_loss: 0.4203 - val_precision: 0.6000\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 1s 163ms/step - loss: 0.3055 - precision: 0.9286 - val_loss: 0.4200 - val_precision: 0.6667\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 1s 163ms/step - loss: 0.3026 - precision: 0.9600 - val_loss: 0.4293 - val_precision: 0.5385\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 1s 166ms/step - loss: 0.3250 - precision: 0.7561 - val_loss: 0.4152 - val_precision: 0.6250\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.3195 - precision: 0.9412 - val_loss: 0.4176 - val_precision: 0.6250\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 0.3155 - precision: 0.8710 - val_loss: 0.4197 - val_precision: 0.6000\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 0.3043 - precision: 0.9583 - val_loss: 0.4137 - val_precision: 0.5714\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 1s 137ms/step - loss: 0.3032 - precision: 0.9200 - val_loss: 0.4213 - val_precision: 0.5455\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 1s 140ms/step - loss: 0.2986 - precision: 0.9615 - val_loss: 0.4150 - val_precision: 0.6250\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.3087 - precision: 0.9524 - val_loss: 0.4153 - val_precision: 0.6250\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 2s 185ms/step - loss: 0.2965 - precision: 0.9615 - val_loss: 0.4272 - val_precision: 0.5455\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 2s 175ms/step - loss: 0.3037 - precision: 0.9259 - val_loss: 0.4194 - val_precision: 0.6667\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 1s 165ms/step - loss: 0.2985 - precision: 0.9600 - val_loss: 0.4219 - val_precision: 0.5455\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.2985 - precision: 0.9286 - val_loss: 0.4158 - val_precision: 0.6250\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 2s 177ms/step - loss: 0.2982 - precision: 0.9600 - val_loss: 0.4183 - val_precision: 0.6250\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 2s 191ms/step - loss: 0.2953 - precision: 0.9615 - val_loss: 0.4185 - val_precision: 0.5556\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 2s 185ms/step - loss: 0.3030 - precision: 0.9565 - val_loss: 0.4159 - val_precision: 0.5556\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 2s 171ms/step - loss: 0.3012 - precision: 0.9286 - val_loss: 0.4204 - val_precision: 0.6000\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 2s 181ms/step - loss: 0.2948 - precision: 0.9583 - val_loss: 0.4156 - val_precision: 0.5556\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 2s 178ms/step - loss: 0.2946 - precision: 0.9259 - val_loss: 0.4214 - val_precision: 0.5455\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.2951 - precision: 0.9583 - val_loss: 0.4197 - val_precision: 0.6000\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.3068 - precision: 0.8182 - val_loss: 0.4139 - val_precision: 0.6250\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 0.3235 - precision: 0.9500 - val_loss: 0.4136 - val_precision: 0.6250\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 1s 164ms/step - loss: 0.3193 - precision: 0.7692 - val_loss: 0.4129 - val_precision: 0.6250\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 1s 163ms/step - loss: 0.3017 - precision: 0.9565 - val_loss: 0.4129 - val_precision: 0.5556\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 2s 177ms/step - loss: 0.2948 - precision: 0.9259 - val_loss: 0.4181 - val_precision: 0.6667\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 2s 173ms/step - loss: 0.2912 - precision: 0.9615 - val_loss: 0.4147 - val_precision: 0.6250\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 1s 167ms/step - loss: 0.2945 - precision: 0.9583 - val_loss: 0.4193 - val_precision: 0.6667\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 2s 179ms/step - loss: 0.2919 - precision: 0.9615 - val_loss: 0.4198 - val_precision: 0.6000\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 2s 171ms/step - loss: 0.2933 - precision: 0.9583 - val_loss: 0.4168 - val_precision: 0.6250\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 2s 218ms/step - loss: 0.2981 - precision: 0.9286 - val_loss: 0.4141 - val_precision: 0.7143\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 2s 200ms/step - loss: 0.2928 - precision: 0.9583 - val_loss: 0.4234 - val_precision: 0.5455\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 2s 208ms/step - loss: 0.2913 - precision: 0.9333 - val_loss: 0.4202 - val_precision: 0.6667\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 2s 235ms/step - loss: 0.2909 - precision: 0.9259 - val_loss: 0.4232 - val_precision: 0.6000\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 2s 185ms/step - loss: 0.2874 - precision: 0.9615 - val_loss: 0.4212 - val_precision: 0.6667\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 2s 176ms/step - loss: 0.2933 - precision: 0.8667 - val_loss: 0.4187 - val_precision: 0.6250\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 2s 212ms/step - loss: 0.2919 - precision: 0.9583 - val_loss: 0.4238 - val_precision: 0.6000\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 2s 177ms/step - loss: 0.2869 - precision: 0.8966 - val_loss: 0.4241 - val_precision: 0.5455\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 2s 168ms/step - loss: 0.2866 - precision: 0.8929 - val_loss: 0.4178 - val_precision: 0.6250\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 2s 179ms/step - loss: 0.2931 - precision: 0.9583 - val_loss: 0.4174 - val_precision: 0.7143\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 2s 177ms/step - loss: 0.2858 - precision: 0.9259 - val_loss: 0.4311 - val_precision: 0.5000\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 2s 180ms/step - loss: 0.3054 - precision: 0.8235 - val_loss: 0.4179 - val_precision: 0.6250\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 2s 185ms/step - loss: 0.2902 - precision: 0.9583 - val_loss: 0.4264 - val_precision: 0.6000\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 2s 187ms/step - loss: 0.2846 - precision: 0.9310 - val_loss: 0.4194 - val_precision: 0.6250\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300\n",
    "history = modelb_glove200.fit(padded, training_labels_final, \n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(val_padded, val_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABKvElEQVR4nO2dd5gW1fXHv2c7S9kCS68CFrACohhUbAEM9hKjUTExRo1Ro0nE/GI3iVGjxoqoxJKoUaOGqFGjBrHRNICioiBtpS1tF5Yt7L7n98eZu/fOvH33XZZ93/N5nveZeWfuzNxp33vm3HPvJWaGoiiK0v7JausMKIqiKKlBBV1RFCVNUEFXFEVJE1TQFUVR0gQVdEVRlDRBBV1RFCVNUEFPY4jo30R0fqrTtiVEtIKIjm2F/TIRDfHmpxLRdYmkbcZxziGiN5ubz7Ym0eeEiLYT0R67Ik+KhTQOffeCiLY7fwsB1AFo9P7/lJn/tutztftARCsAXMjMb6V4vwxgKDMvTVVaIhoIYDmAXGZuSElGox9rHIB3AOwAwADWALiNmf/SmsdVdi9y2joDih9m7mTmY4kXEeW0tkgo7Y41zNyXiAjASQBeIKI5zPy5m0ifnfRFXS7tBCIaR0TlRHQNEa0D8BciKiGiV4iogoi2ePN9nW1mEtGF3vxkInqfiO700i4noonNTDuIiGYR0TYieouIHiCiv0bJdyJ5vIWIPvD29yYRdXPWn0tEK4loExH9X4zrcygRrSOibGfZKUS0yJsfTUQfEdFWIlpLRPcTUV6UfT1ORLc6/3/lbbOGiH4USPs9IvofEVUR0WoiutFZPcubbvVcEGPMtXW2P4yI5hFRpTc9LNFrEw0WXgawBcAw75gfENHdRLQZwI1ElO/d31VEtN5zM3Vwjn0SES3wzmsZEU1w8mSekyFE9K6X941E9Hdne9eFVURET3rPwEoi+i0RZXnrYj5rSnKooLcvegIoBTAAwEWQ+/cX739/ADUA7o+x/SEAlgDoBuB2AI8RETUj7dMA5gLoCuBGAOfGOGYieTwbwAUAugPIA/BLACCiYQAe8vbf2zteX0SAmWcDqAZwdGC/T3vzjQB+4Z3PGADHALg0Rr7h5WGCl5/jAAwFEPTfVwM4D0AxgO8BuISITvbWHeFNi5m5EzN/FNh3KYBXAdzrndtdAF4loq6Bcwi7NnHynEVEp3h5+tRbfAiAb7z9/A7AHwHsCeBAAEMA9AFwvbf9aABPAviVt48jAKyIcKhbALwJoARyX+6LkqX7ABQB2APAkZDrdYGzPpnnUokFM+tvN/1BXqJjvflxAOoBFMRIfyCALc7/mRCXDQBMBrDUWVcI8bX2TCYtRJQbABQ66/8K4K8JnlOkPP7W+X8pgNe9+esBPOus6+hdg2Oj7PtWANO9+c4QsR0QJe2VAF5y/jOAId784wBu9eanQ3zRJt2ebtoI+70HwN3e/EAvbY6zfjKA9735cwHMDWz/EYDJ8a5NhOOOAxACsBXAZgALAJzlHHOVk5a8azPYWTYGwHJv/mFzDhGO4z4nTwKYBqBvhHQMKSiyIfVAw5x1PwUwM5HnUn/J/dRCb19UMHOt+UNEhUT0sPcZWwX5xC923Q4B1pkZZt7hzXZKMm1vAJudZQCwOlqGE8zjOmd+h5On3u6+mbkawKZox4JY46cSUT6AUwF8wswrvXzs6bl71nn5+D3EIoyHLw8AVgbO7xAi+q/nTqgEcHGC+zX7XhlYthJiLRuiXZtIrGHmYmYuZeYDmflZZ517DmUQ4fzYc0FtBfC6txwA+gFYlkD+fw0pHOYS0eKgO8qjG+TLwj3PqOeYwHOpxEAFvX0RDEm6GsBeAA5h5i6wn/it+bm6FkApERU6y/rFSN+SPK519+0ds2u0xCyVfysBTITf3QKI6+ZLSHRKFwC/aU4eIF8oLk8DmAGgHzMXAZjq7DdeCNkaiCvKpT+AbxPIV7K4edkIcX0N9wqAYmYuYlshvxrA4Lg7ZF7HzD9h5t4Qq/tBCg/n3AhgJ/zn2VrnmPGooLdvOkNezK2eP/aG1j6gZ/HOh1Ss5RHRGAAntFIeXwAwiYjGehWYNyP+M/s0gMshBcfzgXxUAdhORHsDuCTBPDwHYDIRDfMKlGD+O0O+WGo93/PZzroKiBskWjz2awD2JKKziSiHiL4PYBiAVxLMW7Ng5hCARwDcTUTdAYCI+hDReC/JYwAuIKJjPH98H++a+SCiM8hWcG+BFBqNbhpmboRcw98RUWciGgDgKoibTkkxKujtm3sAdIBYQbMhn827gnMgPtdNEL/13yF+0kjcg2bmkZkXA/gZRKTXQkSjPM5mz0D8ye8w80Zn+S8hYrsNImZ/D980Yh7+7Z3DOwCWelOXSwHcTETbID7/55xtd0AqID/wXBuHBva9CcAkyFfMJogLY1Ig363FNZDzme25oN6CfEmBmedCKi3vBlAJ4F2Ef0kAwMEA5pC0nZgB4ApmXh4h3c8hPvtvALwPuZ/TU3o2CgBtWKSkAC9c7UtmbvUvBEVRoqMWupI0RHQwEQ32PscnQBqxvNzG2VKUjEdbiirNoSeAFyEVlOUALmHm/7VtlhRFUZeLoihKmqAuF0VRlDShzVwu3bp144EDB7bV4RVFUdolH3/88UZmLou0rs0EfeDAgZg/f35bHV5RFKVdQkTB1sVNqMtFURQlTVBBVxRFSRNU0BVFUdIEFXRFUZQ0QQVdURQlTVBBVxRFSRNU0BVFUdIEFXRFUZQ0QQVdURQlTVBBVxRFSRPiCjoRTSeiDUT0WZx0BxNRIxGdnrrsKYqiKImSiIX+OIAJsRJ4I7j/EcAbKciToiiK0gziCjozzwKwOU6ynwP4B4ANqciUoiiKkjwt9qETUR8ApwCYmkDai4hoPhHNr6ioaOmhFUVRFIdUVIreA+AaZm6Ml5CZpzHzKGYeVVYWsTtfRVEUpZmkoj/0UQCeJSIA6AbgeCJqYOaXU7BvRVEUJUFaLOjMPMjME9HjAF5RMVcURdn1xBV0InoGwDgA3YioHMANAHIBgJnj+s0VRVGUXUNcQWfmHyS6M2ae3KLcKIqiKM1GW4oqiqKkCSroiqIoaYIKuqIoSpqggq4oipImqKAriqKkCSroiqIoaYIKuqIoSpqggq4oipImqKAriqKkCSroiqIoaYIKuqIoSpqggq4oipImqKAriqKkCSroiqIoaYIKuqIoSpqggq4oipImqKAriqKkCSroiqIoaYIKuqIoSpqggq4oipImxBV0IppORBuI6LMo688hokXe70MiOiD12VQURVHikYiF/jiACTHWLwdwJDPvD+AWANNSkC9FURQlSXLiJWDmWUQ0MMb6D52/swH0TUG+FEVRlCRJtQ/9xwD+HW0lEV1ERPOJaH5FRUWKD60oipLZpEzQiegoiKBfEy0NM09j5lHMPKqsrCxVh1YURVGQgMslEYhofwCPApjIzJtSsU9FURQlOVpsoRNRfwAvAjiXmb9qeZYURVGU5hDXQieiZwCMA9CNiMoB3AAgFwCYeSqA6wF0BfAgEQFAAzOPaq0MK4qiKJFJJMrlB3HWXwjgwpTlSFEURWkW2lJUURQlTVBBVxRFSRNU0BVFUdIEFXRFUZQ0QQVdURQlTVBBVxRFSRNU0BVFUdIEFXRFUZQ0QQVdURQlTVBBVxRFSRNU0BVFUdIEFXRFUZQ0QQVdURQlTVBBVxRFSRNU0BVFUdIEFXRFUZQ0QQVdURQlTVBBVxRFSRNU0BVFUdIEFXRFUZQ0Ia6gE9F0ItpARJ9FWU9EdC8RLSWiRUQ0IvXZVBRFUeKRiIX+OIAJMdZPBDDU+10E4KGWZ0tRFEVJlriCzsyzAGyOkeQkAE+yMBtAMRH1SlUGFUVRlMRIhQ+9D4DVzv9yb1kYRHQREc0novkVFRUpOLSiKIpiSIWgU4RlHCkhM09j5lHMPKqsrCwFh1YURVEMqRD0cgD9nP99AaxJwX4VRVGUJEiFoM8AcJ4X7XIogEpmXpuC/SqKoihJkEjY4jMAPgKwFxGVE9GPiehiIrrYS/IagG8ALAXwCIBLWy23iqJkFjU1wM6diaVtaABCofDlGzcCixcDW7YAixZJmvp6gBlYuBCYPTux/TMD770n+5k5E9ixIzzN/PmJ57c1YOY2+Y0cOZIVRUkRy5czV1Qkv93Gjcwvvsj86afMlZXMS5YwV1Uxv/8+c12dP21dHfOCBZH3Ewoxz53LXF3NfMMNzIsXM9fXM998M/PWrczz5sl+J05kfuIJ2WbGDOYjj2SeNUuOX10tyx9+mHnhQua77mLu2JG5QwfmgQOZH3yQ+YUXmN97L3Ie9tlH0hkee4z5wguZTzmFWeRYfrffzty3L/Of/mSX/fjHzB98wPzd7zLPnCn5qqmR/VRWMt9yC/PLL/v3U1Ym53z44cyffy7zAPN11zFPmCDn3NDAfMIJzO+8I/s6/XTm559P/j45AJjPUXRVBV0RVq9m3rQp8rqNG5nXrYu9/bZtIgZK2wAwd+2aePotW5jLy5l/9jPZtmdP5v32k/nf/16mAweKUBumT2fOzmZ+6SVZ5z4vb70l21x8sRW8adNkevXVMr3ggvB1APM118j0mGNknwDzSSfJscaNY77ySuY+fZjHjLHbTJrEfPLJcuznnmN++mm7zr0mgGzrCnH//jIdMIB58GDmSy+V/+PG+dO98w7zlCki5gBzly4yveQSuRYA88iRMv3Nb5jvv1/mv/Mdmd56K/OqVbbAqKsLz2MzUEFXhNmzxYo7+2zmZ5/1r+vaVR6HHTvssgULmJcuFSsJECvwsceYP/7YpnnkEebJk+WBBpgffVQssjlzmLdvZ/7ww/B8fPkl83HHicWWKiZNYv7Xv1K3v/ZEKJS8UJSWSvozzvCLmCuwgP8eXXedLDv3XJm+/jrzsmUixKYQyM212x57LDdZsgBzXp5d17OnnT/xRDv/6qsyzcqy/5mZr7jCLnN/DQ3MvXszFxTYZatWMX/xhT/d8ccz33Zb+PY/+pE848HlAPPll8v0ssvssuHD7fUYPNguHzFC8ggwjx0r04suYv7oI7vdxo02/c6dzb7dKuiK4D6spaXyUJ17roi0WT5liqS9+Wb571pFJ58s0732kjTui3DmmTItKJCXOzfXWjyVlVI4TJrEXFvLfOedsnz2bOaVK5mPPpp5zRopbI47jnnt2uTOq7IyeUFLJ6qqkjt/twAYPz5cyK66yi+Ohp/8RJYdcIBMb7+d+amn2GepAuKCIGIuLAzfd//+8hwAzPn5zHvswTxkiF3/61/702/eLMd+8snIous+u7F+06aJ+Hfo4F/+yCNyPfr2Dd/mtNOs6Jtl555rr8fkyf70e+0l0169ZDpxorhXALkeCxfatHPmNPt2xxJ07ZwrU2D2/x89Grj+euCpp4Df/Q7o2FGWf/ihTF9+Wabl5XabDz6Q6YYNMv3d7+y6LVtkWlsLLFsmFUMzZ8qymhrg3XeBV14BVqwAvvzS7ufvfwfeeUfysnAh8J//AB9/nNy5mTyWlia3Xbqwbl1y6VetsvOVleHr6+vt/Nat4cf5/HOZLloEbPYakf/vfzbduHFAnz6RKw1HjgQOP9zO9+kDfPONXT91KtC5s8wPHw6UlMj8qFE2Tffudv7aa2VaUCDToiK7rksXO7/vvkB2NnDggfJ/0CCZjhkDEAFHHSX/+zkR2N9+K9NNm/z5N4wdK9PTT5fpkiUyXesF+a1ebffBLM+5wZ1PISromYL7kgJAXR3wl7/IfK9eQHW1zJuX1ryobo29ad1bVSWRAq++atctW2bnV670H6umBti2ze73iy9kfsMGiUwApCDZvl3mzTRRVNCTS28KZrPt0KH+9bW1dt4VdCNU5plwBT0UsqJ65JFWMA177CHTUaOsoI8ZA3Tr5o9MqaoCfvQjEeMjj7TL99zTGh0bN9rlGzaIcfLzn8v/ujr/vgzDhtljduoE3HwzcMQRwD77yPJzzpG8XXGF3WaN15zGFfRDDrHzEybIfm+8EfjlLxHG6tXybObkyH9j4Oy9t81PilFBzxRqamR6113A8ceLZWZexhUrZEpkxcE8xMbyNgwfDjQ2SvjWhg3AKaf49wGEC3ptrV/QXQt9tddrxOefA595HXq2laBXVNj8tJRQCFiwQObnzAHGj7fnt2CBWGyVlcD3vmcLw08/lYL1k0+saH7+udy7JUtsobtsmV+szD3LzZXpihXAjBnyKy+X34wZ9h6ZrzBALMi99vLn3TwrgAh6XZ2E/QULji++ANavt/9POQX46CPg6KOBgQNlWXGxTC+9FPjxj4GzzgIOPhj46U+BCy4A3BbjkyfLl9ott8g1c78As7OBm24CDjrIFgC/+Q3w/PPylXf77bKtWxiZ7YYNs5b79dcDc+cCP/yhfDVmeRI4fjwwb54UDDNmyDJTgG3aJO/G7NnAoYfafffpI9dl+HA5/gcfyLtlqKyUZ33AAKBDB3ufp08HTjwRrYEKeqZgXtIOHeQlW7vWWu3GEtl7bxGKykoR4A4d/BYPYC2Up5+Wh/zss+V/KAT07Svz7ie9ObYR9CVLbGGxfr1fQBculGmigs4MXHWVdQ8Z8XBpbJRfIuy7L9C/v+zvjjtip50/X0QqeH2WLxexeuopEZ/XXgMmTgTefBP47neB556T5Y88AsyaJetfeUW2239/sR5HjgSmTZPC9KCDRNgOOgi48075ohkyBDj1VHtMIzzm/E89FTjpJPmdeaaI6Ekn2W3mz7fb7twp1rQpDIBwQX/4YeCAA/zut8JC2dbdV79+InhEVtDPPBO4+mrg3HOBRx8VSz0nR1wrw4eLhQ7IsunTRbQ7d5ZnMXg/r75arHfDqFHi7jDHMl8ILtOnSyFjKCqyVnkk8vLsl4EpVDdulPN1rfMgRMBhhwE9e/qXz54twl9SYg0d1xWUYlTQMwVX0IuKrAh06mT963vvLVPjIx0yJHw/o0fL9MMPgcGD/dad+awOilxNjbUo3c99Y6GbgsAULMYSZRaxC7qLDKtWAXffDfzrX/LfuG9cunUDTj458vZBTN3AlCnAddeFW3sujz4KPPSQ/xMdEOtu2jTgttvk/9VXizDffbdc8zfekOUvvyyWOCBWnhHGPfeU6XvvicVYXy+CWlMjlr2x8t9+2x7TWM6FhZLnTz8FfvIT4PLLRVA+/FDu+8KFUlgvWmTvNSDC2cvpILWmxopOZaX4x4OF4gEH2LwbXP+zEdmhQ6Ugcv3eLsZCLysTUYyH8akH5wE5xyB9+yYvoJ06+f9v3izXNhG6dvX/37hR8lBaao0aU0fQCqigZwpG0AsK/BVHRoSBcEEfPNi/j7Iy6xtdulReUtfN4e7LxXW5mFZ5PXtaQTf+RFPIGAv9k0+AE06w/tEgn37q/x+shAuFxMJ85ZXwSuFYLFkihdK8edHT5OfL9OGHRdRuvVWOYaxY41b68ku5LscdJ/+N+H71la1IXLxYxDY7W6anny5ugTlzZL3xGX/+uSwH/D5qs8/6eknT0AAceyxw3nk2BuOaa+R6PP20PAvjxtntu3QJF3QjTFu32ucBsKJ70EE2rcEVdJO//v2jXUHBFfRESFbQm9MJYFaW9dcDUphF2nckzHVz74+x0A0q6EqLCVroBle0jaAbq8tdN2GCuBLMtrW14YIerAhzj20Efc0aEYURI8Snu3mzfHqbdYAVdBP98MQTkfcbT9BNAREpbZBIgj9rVvT0bnTIQw+JRV9eHtkHf8QR9oU257Rsmd9CX7hQrn9BgXwFLV/ur3Q227z/vsy7omAEvbbWuq0OOEBEt2dPuU+XXCLLp06VaVDQe/e2/2tq5DkpLJSvC1OJDdivNiPogBRYubnAfvvZZWPHylfK974Xfj1cjMslmgUfxHXDJCLoZv/JEhTdZC30ESOAX/xC5g880P+eqKArLSYRQTe+xUiCPmWKVFa5L1T37rI/47s0n9mRjm0EHRDx6NvXVhIZQTcuDiPoS5fKtK4O+PprEd377xc/67p14jowEQRAuKC7vvxrr7UCOnMm8NvfAv/+t11vKogBsdAGDRK3R5BFi8TF41ZKfvWVTDds8PuZjVvCFfTly+361avlmlVWii/dhNQZX+2cOXYfHTqIpfi3v8l/Y7X/859WxI2gFxaK8GZlSV3AHXfIvRo0SPJvCg1DUZH/XtfUiEAXF8uz4N47I9pDhlhhGj9e0rhfaLm58lXgWrqRaImFHqwE350EvVs3CUCorQV+8AOb7w4d/M9silFBzxSClaIG90U2ImAE3fWhm23cwsC8hOYh7t3birtxSQB+lwsgn+GuRTZ4sFRGGYKCDojbZP58cb/ceCPwzDNidR93nOwrJydc0E0lVL9+Ipg33SQukAkTpKLx+OMlUgKwVu4++wCnnSYWrBFKw/PPi8CeeKK/APj6a5kaF9I++8g53XGHiOj48bbgM/ULxcXiq738cvkfClnxHjVKIiPy8yV/Bx3kT5ebKxE5zBIZsnatnL8R9P32E/cNINEc550n86edJsu/9z2/r7dLFyngbrjB3q+cHMmjqVA0X2cHHyz/e/SwVn1pqf9+J0OyFroRxpyc8MIiKOhFRf7K3mQI+tGTdbmY88rPly9SU/i0onUOqKBnDsb6jWahE8nyHj1sYwhX7I2gBy10wD6spaV23xddJJENQLiF3r+/3yI76CB/xZUr6IcfLqL4wQdijRof7oYN4us+8ECJlrn00uiCvnixRJqUl0tUTMeOYr1Pngz84Q9SaWjcM1OnSiRKr14imldfLQXCxo3AxRfbfa9YYX3G5ktg7VpxG51yiuT9uOPExeIKHyBivWWLXJNLLpEY6JNPFsEFxBpcsULu2ZlnypfF9dfbY990k0RgLF0qPu577pFlzLLdgAGIyB13iH/9hRdEsMy17NLFH/3hWujmS+TGG+VYZ50lFcFDh4afV3MwX3nRvu6CmOevpCS8EjUY5ZLoPiPRUgs9WDlqCqJWjHABVNAzB8dC30KlqEOeWGtGlIqKxDo3L2lOjr+Sy3uRargA83PHoALdgO7dUVcHfJx7KNahB1BSgp1F3bARXcWHetddTccOVW3HIuyHbzDIL+h33IH1tUVA585YD6+AcAV9yBCsG3E8+L33RdCPOELysmyZiJOJkCkstNExhlWr5EXq3FnSlZeLOJ56qpzbffdJhdXNN1tBN2FnPXqIi+Ouu2S7++8XQTMW/erVts7AxEUvWiR5cq+bi3mpXbdBQQHw178CL70UvVLZnN8LL0gB0ccb4dH40/fay4rZxo2JWYFZWVZczNS4AmpqrIUOyPF69JD5gQOlAMnJsc9K0JedDAUF8lXhFpbx0hcURD6ma0X/7nfyVddcgtcwUQt90CAJXzStSA1qoSspxRH0g396EG7EjfJSGEvCvLymFV9+vlhpxpLzHsTLLwcO3vkhxmEmUFaGG24ARn0yDaMwHygtxTWVv0EZNmJ7Xql9CWpq8Mz2E3AAFmEovsbaor0lkuPdd/Fo0dXo2RN4sP5C9MR6PIczRJirq4E1a7C620Ho9Y/78YcNP5KQvVNOkbwaX7R5sU1c9M6d4pNubBQL3VirffuKVb9+vRXiTp3k5Vu50rpcTLRH0AWwbp18Rh9xhPwPhcItQNNlgSlkgpiXurkCeNppkndTGJoQ0D33tIK+fXviomG+poygG/dEUNAPOyxySGEqLHRArP1IMeTRKCmJfExXdPv0iX4fEqG5FnphodwX45oymHuugq6kBE/Qq7kQy1bnYxH2l5ci6BufNEmmxtotKZEX3mtRZ9zrS7AXGkq7N/3/Fn3R2LEL/lM9BgDw1lf97Uu6eTMWs3zOh5CNr2gvEY8jjsDv/yBCsTgk6+/CVSJKXqvGTaXSLP063CIuAePLNYJuXmzzwtXUiIgfcIBY+EbQjVUL+KNxunUTq3btWnHFmBfOWKSGzZulAHA/pXv08IuIEfRkLPTmYAT9/fel4O3f3y+IQf9vNMw9N1PXQs/NtV9Khx0WeftUCXqylJbGF/REBTgazRX0aKiFrqQUT9BXVsiDuRID5CEzVnjQQjcUF/v85sYt3YgcrAn19LXy31pJGF4irotX53cXl05uLrBhgxzP7KNRLCdmq8tZeSImc3AoeNv2piiO2s4iXiFko37O/0S4iotta1MjjqaCbPt2sdAXLxYf+zHHyHLXWnMt627dRKy//dbfyi9ooa9fL8dwBb2oyC8sNTViyUYL3zRpI7VoTQYj6EuWSMV1dnbLBN2IjLHQQyERdxN/Hk3Q995bCvpoBVhrcc894tMPkkpBb26laDTUh66kFE/QV6yTF38FBoKLvYfMtdTz8qRV47Rp8r+kpGldXZ3U+R1WJGb5iqoSrFhhN926FagmEdZnX+uCceOACzAdoQ0bsRIDMKavVB7O+qYvJk+27WYAoIpsRe1XVT2bokh25Nrl78/zIimKi8EArsKfsHB9T1xzDTBvnScqa9fiFvwW/8U4/PHED/D6kMtkuWehT8VP8dyn+2D6dHFdN3UOtXgx0Ls3Xn4ZuPdehFnos1b0x42bLwe6dsWHGINj8BZ+8urJ4BIr6MuwBy4ufhYNhfLSrlsnLdWbGpyWlGAbOmHynIt9QTKJMGWKtCm67jrgva+cvJmWuq6gx7ACX3xRqg4AiKB37GgjYtxwutxcaSzVrZsNpwwyfrz49FtS+dgcjj023KUB+EW3pQJsrqG5NmqhK7sVNTVAVhZWfisvbTU6YXMnrxXfL34BnH++TXvlldJ0HBAXx6UyTKxpM3NkL4m7XvhZDrZts+/7li3AlsYuyEMdRh/MKC8HHt/5Q1StrcYKDMSeQ8VF/djj2XjiCeCxx+whq2Af9BU7ujdZ4DW51qJp6mW1uBjb0Bl34yq8/H433H478M9PvQrF8nLcgV/huaOm4k8fHYZnnvV8v56F/iD9DH95qQhTp0rr/abwsi+/BPr0wZNPeoJXWmpfZgD/2DAWf1x7LtC5M16jSXgHx+DRj4ajptjzuefm4g2Mx8NbzmwKRZ81Szq0bGpoWVqKTzACTyw+OOFhLAGpZ/3jH6VO+LbbgBdeccTb9KWToIX+xBPAn/9sr6Mv4skV9Jwc4Pvfl0gfN6TUhSh6RE1b4F6DVLlczJdaS/enPnQlpXit/1auspVbK8ecJTNXXml7TQxy9tkSggjrbjn8VPnkf/dd+e8T9NzumDToc7z932xcdZUs375hB9agNwb2a/QZc267n20hK0L1nNPUanRHjn0BmrqIKS5GHcRar6yTl9j8R3k56pCPGipETY0TyVhUBBQWoi63E2pqCDU13v6MoDc2An37oq7OW56V5QutrK8NoS6UCwahrkNx0/KaLp61HAqhBmIVmvpnk9+m1vElJU35dFvMx8Ok3bFDxL2yElIazpxpQx0TtNDr6pxGrldf7Zjr8MdsNzd+uy1pDR+6+VJrqcVfXCzPU7A7jRSTkKAT0QQiWkJES4loSoT1RUT0LyJaSESLieiC1GdVaRE1NUBBAVassAELKwaOS2oXpvfVvS8cix49rKCbVuBbtgBb6jqi5GhZYAy7bzZ2ASMLAwb4DTq3X6eqRvsC1iNPPgdyc1ETskLV5LooLkYtZPnWKnmEa1kOFlpVjnrkowYdUFPjRDJ6PQDWZndETY1cjtpa+FsS9umD2lrnOI4fvR55YGRh506gNt9atU2CPmxYmKCb/TSJd2lpU76bI+hGiKuqIL4ct7/wBC302lrZDzPkxrm9NgYt9PZGbq7tDrelgn7wwXJ9TD9DLd1fdraE2nrGUWsRV9CJKBvAAwAmAhgG4AdEFOyd/WcAPmfmAwCMA/AnIorynaa0CcZCX2kt6mC35fFYuVLel759RZhN63Ofhb7Ffl2axoNf1YlrZ+DgbJ+gm/ZLAFC101pA9cgT8720FDW19osioqBv9daF5HGrWynhh9t2FqCxMRCa/re/obawNHFBd/zo9chrykNtvnUD1XTyrPjp01Hz/cm+fAanzRV0s70510iDDCUj6Dt3RulI0rXK26OgE1lLuqUW9YgR0mYhVRY6IFa/48ZrDRKx0EcDWMrM3zBzPYBnAZwUSMMAOhMRAegEYDOACH2ZKm1GTQ3Gb34ac+eK4dG5s7T2vu8+aTBZViY/M6bAddfZxom33CLrbr9d6hZzc209WMeOtoeAdetEKIygGwv9a0jo4YCheWH1ZyaasKrOClI98rBl+VaMrnyzaYwIwO9yMcJoxK0uJGJUu1pGVdq0XUoTn6AfeCBqd+Y0CbrrcrkTV+OXL33HulyAiIJeVwfUOm6gmo5egTBgAGp6DzGXWvIStNAPPxy13zvdvywBIlroQTxBvwp/wl0vDoy6L5OniIVCsFI0CgsWSOBLsB3XboER3pZa1Aazn1Ttr5VJRND7AHC7kCv3lrncD2AfAGsAfArgCmYOBdKAiC4iovlENL/CDGem7BKqthHe3HE4xo6VxkH33Sdu5VdekciHfv3kfTZulH/9S1rAAzLMZ0GBDDhz552y7Je/lLrS++6Tdygvz7pkgoJeAbFiiweV4MwzZR8mhNlEE1bV2g+6euRhyaoOmFe7f1OHh1lZfgu9yYfuCVNtowhQ3bfy2bCpyqv8DYhOXZ34onfs8PZXWAh06IC3cCxe/7gbamulF9pQCOJj/sMfmvIEyDZ1ubYPkZpjJklvi2VlTcIb1YdeWIi6k870L0uAoAjHEvRXMAnvfFIUIYE/T+7Ick0kaKHPmyddvLhDge42qKDHJUITMQT7Gh0PYAGA3gAOBHA/EYUFXDLzNGYexcyjyprTT7HSbJZtFpW94gppc3P++dLocc4c6VJk8mQZMMeIRUWFvLCNjTJ/6KHAAw9I1yKAuBgfeEBGESMSETcveFDQt3kRLPld8lFaKjppQr5NCHN1nRWQeuShqk42Xr/etlJvEvSiojALvbZBtq9dK0Pmbd4sj63bvQuzFfS6Omd/ZWVSkdqQ27Ssrg7iS/Kif3wul2xH0Dt3b2q2HrTMw1wuznyk8ZOjEbTQY7lcqtERdY3RxTgVFrrJT7Khl7uEggJ5IKNF5iSLEfJUuFx2AYkIejkAt+VAX4gl7nIBgBdZWApgOYC9U5NFJRUs3SquAbcDxSFD7IttekPdtk2Er6JCfK2rV8t8vPK3uNgKuolLNz70KnTx/QdsfWOvXuGtyuuQ37TNpk3hHRVG9KHv9AS9nnzLXQvdbN/kpjH769YN9bkdUVNDTcuaRNhrsORzuXS3gza4why00MNcLlGWxcOkNecUy0KvRsemaxGJmIKeoIW+Wwu66cc9kdGPEt0fkFYW+jwAQ4lokFfReRaAGYE0qwAcAwBE1APAXgB2xw+yjGXpNvEHB3vLdee7dBGxqKqywykuWSIvbjxBLymxXYFHstCzqdGnEUbQe/SwQm8ae9YXljQJOmAFPZLLxYhcXYM8yma5Ga8ikqCbdbW13ny/fqjL72IrSp205kU2+62tBepyOjW1E3GF2Yh7IhZ6SypFa2rs/WnCtdB3RhezYKHmIx0sdCPoqSLdLHRmbgBwGYA3AHwB4DlmXkxEFxOR6SLtFgCHEdGnAN4GcA0zb2ytTCvJs7S6F3oVbPZ1IW0EPStLKjmNhe5Wb8yZI6KXiKAH511Bz8/215G74xoYQTehv/Xd+za5aQB5p3yCXlqKWpIXzQwjWluXBeTnN1nuhtpaOxxmMLIjFPK2nzoVdX0G+wS9KW1ODpCX53e5OBW/rjDH9aFHWRYPk9YdMjXMSs/Px07koAG5qKuLLugJu1zau4WeKoYPF6tjd2pAFYOEYpOY+TUArwWWTXXm1wD4bmqzpqSSpbV9MKTzBgC2qboR9AEDRHy7dBFBN2MlA3Z8gxYLeo6/jtxY6N27W0Hv0EGiuuqLysIs9Px8x2ouKkLttTcBv7f7q60FcPzxqH1pU1jeduyQwiJSqF5tLZDbsyfqQrL/pgLCTduxI+rr/YJu3EqxBD1VLpdI+a6qCnS5nZ2N6pxioCH62NbMGeJySaU1PWKE7YmzHaAtRTOEpfX9MaTE/9HUo4c/7LBzZ7FaTXx6VlbzBD2SDz0/31+PHslCz8+XQqC+U6lP0I2FXlMjoZSrVgG1e/ibQtTVAbjssjALHQh3hYRt50yNNd9UeAAi6K4PPY6FnmqXS6S0kQS5Or80PO8OO3dad1PaulyOPFL6eslQ2mHrAaU5VIS6okfnz3zLiIDLLrNDepqO4Ezl5siRduD7eII+YYL0XTJsmNUC10Lvku93+h51lPTUu//+EQR934NQu2prU7Bshw6yz6VLgTffFMs0qDe1tbLTuqM/Bd7xrzN+9EhCF+YzDywH4BP02lpJm4jLJdWVoi6RKkar80qA6uiC7i5PWwv9mmvaOgdtigp6hhBCFrJzwz/IbrvNzhsfthm7efz4xAV90iTblbrBCHoDcpFf4PehDxwose5ABEHP6oCqsccDz8jywkL5WjA95lZXh4+HUFsLgAi1P70iqqBHc7kAcQS9sDDMh56IyyVVPvRoLpcg1XklUdMHl6ethZ7hqKBnCI3IQVZ27FAuI+jffCMi6o6iFRwiMRHcUOD8jtEftTBBr/cLVocO8jVhRMiMu+ASFm7oEEvQzXb19f7l0Sx043Ixfv3mulyaE4fuEtHlklvclMdIxBX07Gy50Mzt10LPcNSHngEYv2lWnLttXC7LlolFPmKEXdeczvf8gh59B4kIumuRb98e3aKOJGbNcblE86Ebl0tBgRR6uyIOPWEL/fgzmtJzsOkfEnC5AFbI1UJvl6igZwChRnm74/ULZCz08nLbt0tLcBsSufPR0hlBr6uTaBuDqRQ1bN8eLnJGxCKJX6xKURPWaCpD3eVNOIJuQhvz86WgqamRDsleeMEK3aZNwN/+5hfvhgbg8cdtXiIJ+jPPRP76iGehv/su8NVXQPV46TmR2R/iGOmczPbLlgHvuC4qI+hqoceFGXjyyfCvuyAvv+wPBW5NVNAzgMYGEfRELXTAjpV88snAxInNO67PQk9C0CNZ6O72kQQdiN6LYDyXSyzLHYD0weI1LDIFTUGBFfQnnwTOOMOK6GuvAT/8IfDFF3Zfd9wh3SQY8QyK9MqV0vX8s8+G5yWYNivLf33OP19GZIvUiCrSORUVSSEEAL//veS1CWOZJyDo27fHF7N0Zu5cufZvvhk9TUWFDDVwxhm7Jk/qQ88AQjsbAWQlbKEDMhA7ALz0UvOP6361Jyro+fnhgl5Y6BeOaILu6/rWIV6laCTxc5dxYUfUB1qmuoK+KTz0HYAV+JoaYNEi/7qgSBuL2W0D4ObRkJNjW/QaNm2SMa5dQa+tDe9F1+ynTx87+tT69QH3TRIuF0AKhuB42pnC+vUyjdgVg4cpOFevjp4mlaiFngE07pRGPclY6Hvu2fLjElldSNZC37bN5icRHzoQLs6mAIvnQ49noTeca8drMcLrCnrEngsdamrCP7mDgm5cLRsjtK920+bny3Ux+WhokG3Xr49voZtl/frJ9a2rk+NVV3u9SwIJW+gmyscddSrTMPcqVgW3KezdFtqtiQp6BhBq8AQ9TpSL28DOWOgtxRXrRNLk5VmxMX2lJ+py8fWgCDt2RbyGRfEEvf6gQ5rmjZC6PvSoFYzOvow15y4LOY1njRhHEnQ3LwUF4jIxVqGZJiLoroUOiNiY4zUVGgla6N/5jszPnx81Wdpjrl2sfuFNmhhjjqQUFfQMQFwuQHZWhNAHB7eDulRY6ID1oycj6MaqMcKTSKUoEO5yKS6Wr5J4LpdIfmBXEN31kVwuiVjoQUEP5sfkMVLlmWuhFxT4XS7m2Js3+/MRK+be9EG/cWMEUUrQQt97b+m2Ye7cqMnSHhV0pU1ocrnEsdBdzAAULaU5gm5eAtdCb47LxfTT1FKXiyvorsulsDBc0F23laGiIr5Qx7LQgy6XoiKbD/fYZoARILbLxQj62rURYvvjRLkwN41miNGjVdCB2C4XFXQl5RiXSzLDGcbztydKcwTdiJQRnqCFXl0d20J3B5np2BF44w3gkktk5KUs6ZSxKU1CLpcogt6hg7zMrsvFdKvr4rpWTL4Av1C7PnRm4N577ZirQZdLJAsd8I8gFOuczHX98ku7zrXQl2Iwpr8zsGldebmMTMUs14LZCvoXX/grBevqpPWxCQe97bbIoZjJ8MQTcv8++ED+v/oq8N57/jQzZ8aONjF8+SXw1FPJ56G6Ws6lqkoGsTL1D4C4CG+/Xe7FHXf4K8lNmlYeSrQJjXLJAJKx0C+9NLWd1TXHh24YMQIYMwYYNcq+zIAIRKTYbLfjrB075DyOPVaE/NFHpQLR+OM7drTD0CUj6EZAXR+6G/NdUuK3lF1r2jTCNPmLZqGvWSMjS23eLOGINTV2P8aHHmn0IlfQE3G5RBT0nBw8jAtw59374pw/yHk+/DBw663Aaaf5uwffYw85nyVLZAQrAPjvf4Frr5VRsUpLZb5/fwnJbA7M0t/Q9u0SKfLKK7aLCbfx1HXXyXX6bpw+X6dOBR58UEI1kxkD4957gd/8RoyDmTNlMCvz1TV7tnypVFTI8Iq5ucCVV8o6I+jRumNINWqhZwBNlaIJ3O0HHrDjhqaC5ljohr59gQ8/BPbZx2+hh0IirGaZmQb7WenQAfjrX8V/PX68Tduhg00TSdB9oyMhOR960OVijgNY0YvUD4wR1O3bbV86ixfbPLo9WEaz0N3GWLEKKeNOcwXddblsgPRtbMTI5OPbb22eO3SwBYP5kgDsICcbNtjt3fXJsmqVzZvJh8EV9PLy2OGDhq1bpb1CMi11AWthz5wp02+/tee3xhu/zbif3HyqoCspp8nlkpOiYbmSoCWC7opjsDOuTZvEUgXs1Ihz585SeLlfGsYfb4S4sFCOFUnQi4qiW+imRanZT3W1X0iCVp8R4p49bR/wkXpqdN0SCxfK1AiDGyZoXC719ZLvYIWs8dXG6remUyfJQzSXixF0Y4FGE3RzTV3BNvMbNljXQ0sE3Rx7/Hj58nGvk6loZhZRTUTQg9FBiRIM+nEF3XSXbiJ+VNCVViXRlqKtgRHooCC7JCLowQJh48ZwQTcuFyO2kQTdCL07TmlQ0H0DUiOytWtcLsanbAhGzBjx3mMPm89Igu5GSixYINOvv5ZjBwXd7Key0gq6cYUYH34sCz0vT0I63XEbqqsl71tQggpInw8bNsg2S5dKmqCgd+8udaeRBL2iIlzQN2yI3MdMLD7zenw2g5O7YmnmN24Mb4wWjZgDbccgWHCuXGmXGZebqRxdvNiepykUk/0iaC4q6BlAU9jiLqqYcWmJD91tuRp0rwBW5Fz3iRH07t2tRQxYQd+82a4zw9q5IpyTIxZsJJeLW0AUFPgjF8w5BAXLnM8ee9h8mpaVRqwAv6AbC72hQfpocQfUMC4XQASsslL+DxzoP89ogp6fL18RJkbfsH27VOjtt+AprIdksKJC/OOmUjco6FlZ0kVEIhb62rXSoOnf/w7PVywWLxYXken5c84c/zr3mBHHWg2QKkEPtvx1qaqyrqddbaFrpWgGYDrnSiZsMVUk63Ix80T+1nVGyHv2tJWOsQT9nXf8oygZoaupkY6zcnJkAA/X5ZKXJ5/WvvFLYQW9c2craAUF4ts3PPEEsN9+wFVXyf/evcUNYNwCgwdbS+7QQ0Wob7hB+vh4/nlJm5Ul4rlwoZ1fvDi6hV5VJUJTXAzMmAF8/rn4tUeMAF5/XUaiGjNGrsWrr0oacx2NoJuK2upqEe9v68tAEAWfOxd48UVJl5UVLujmukaz0E2ab7+Vr436envvmKWietIk22+Qey2NYL79tgzAMniwPBtmBC1Ars2770rfOYY33pCK2bFjpQ8VQPb15JPAQQdZIf/kE7nugwcDF1+MMCoqgLvukjyXlPjDSbOybKEbxL1vvXrZpv+1tZKHI44AHnoIGDeu+X0kxUIFPQNorBcLvT0Iuklv/OCGSIIeyeViurY1FqvBjas3AhJ0uRQXi488Pz+yoHfpYvtaKSjwdy/crZuM1nTNNTJy04QJwPTp0iHX//0fMHmyCAggQnfvvRIpcfLJEiUBSGOupUtF+EeNEgv+mWdE/MwYxcaHDliXS3GxCNPgwfYT/+mnRUhnzpTIpSVLZLnpQfPIIyXM77jjJHKkutrxSXsf7iZUcd995ZpEE3TXDeJa6OYLZs0a20WAqbj99FPgooskiueGG+z2zLKc2X5NTJokX5eDB1t3FCCVx+PGwcevfy2hlNOnAyecIAX3XXdJIdGpk833HXfYqKAf/jA8TnzaNAlTNIV7r15iYPTvL19br74q6QYNApYvt9sdeqjcz48+kgLEUFkpHXkZiotbR9ATcrkQ0QQiWkJES4loSpQ044hoAREtJqJ3U5tNpSU0dZ/bjipFg9EiJk3PnnZZpEpR41YIYiz04D5dC724WJZFs9CDPn3XsjQW9FFHiS910CD5P3KkuDMGDvRHqhxwgAiUEXNA9nfooTI/aJCI1YwZ8v+EE+y2rsvFCLqbL8OaNVL4LVkixwOs4F99tZzjv/4l13z79vCOwZhliMBPP5X8x7PQ3dhs14fe0GCF2Aj666/LNBi5Ulcn1/ummyRtVRVw+eWyrqzMimdeXuSOzIxIb91qo05MXcH27TZPbmjp2rXh+3n9dSmw33/fpjn4YPkKOsTrCaKwEDj8cP92w4dLfP4bb9gCskeP8A7cJkwIP2YqiCvoRJQN4AEAEwEMA/ADIhoWSFMM4EEAJzLzcAC7qLNIJRES7ZyrNWiuD931nwN+C90Qy+USJFKDHyPcrqAXFEQPWwxG3bgRLa6ouv8j+fzNsuBL3bGjDa/Mz7frBw0Sd47Z1q0Uraz0H9s93po1VjjvvhtR6dhRLPRIAmnGm+3dO7qgb9smPxO+V1pqfeim3sb4vk3F5RtvyNStR3DXm3N0KSuz92Xo0MjdKdTVSeGXlWWP4Z6XqQ9wG3uZfBsqK8XCnjDB/2VnrrMpyPfdN9zw6NNHtps713afPGCAv26lRw9bwKaaRF7x0QCWMvM3zFwP4FkAJwXSnA3gRWZeBQDMHOHRUNqK3d1CN+JQUBDdQjdp3BfM+MiLikRct26NPN4oELkRSYcOUkln/N4lJTYC5rPPZNi9rl1tX9auyJgwtr33Dl/n5s2tSA0uCwp6p07WhRAK2fUTJsjxsrNlW3Ntzj9fLF9X0N3wuupq4B//EEEJuiZcOnYMt9CLi0TxjKAb4TbWrDkHE4u+337ilwbElVRTI26WvfaSZcb3vW2brHvvPbnXX38t/486CvjnP62PO1IXCu6AK0OHRi6AzLpDDrGF2fr1kbv43WMPma5ZI/UMY8dKgfDf/4rrbfx4qTw3hpDbvgEQt5Wp5zHPd9++sh2zuL0AcdO4jB/fesZVIj70Pmgafx0AUA7gkECaPQHkEtFMAJ0B/JmZnwzuiIguAnARAPQPnqXSaiTa22JrkIigH3mkNGY69FBbGRZ8ofv2Be6/HzjrLNnX2rXAOeeIwB99tFhj99/v7wkwyGuv+S313/5WPueNf/nGG6VQKCmxY6jOm2ety5/+VMRx771tAfH22+IWCUaNnHiiWMVuxekRR8h5moiN8eOlyfjzz8txOnaUT/h775VCpEcPadU4caIc74kn5Bq51+aUU6xLAggvuN59Fzj1VFn+3nuRm+F36iRRGW6L1+F7NeCDuXnYd1/5byzKRx6RfBoX1sSJ1m88a5a37XARyM2bgdNPl+tr4vdNobBzp/jv//Mf4LnnxNc/ZIgtIOIJ+pAhdv7888UdctllNt1xx0nr1i1bRPjHjQu36A88UFw0a9bI9f/gA8nr55/L+pEjpRDt0UPybArk00+Xr5XLLgP+9CdZdthhcs9PP91+vb3rOZ7d+pxzzpE6lVaDmWP+IO6TR53/5wK4L5DmfgCzAXQE0A3A1wD2jLXfkSNHsrJr+OTZJQwwv/TrD3f5sS+5hBlgfvfdxNI/8oikP/XU5I7zzDOyXe/ezPX1iW939dWyXU5O5PUPPSTrAeZvv00uT4ly3nmy/5//PPFtTJ527Ii+zvxuuCH2vkaOZN5jD0mbn1XHAPNPzqthgPnrryVNVRVzdrakOe44//YLF8ry44+X6QMP2GPfeivz6NH2/3e/yzxvnszffLNMDz5YpmPHMr/9tszPnBmez3vvtft5+GE7//rrcm/M/0cfle0B5r/8RaZXXRV+XaZMYS4slHUTJ8qyv/+d+cILmbt3918fgPmmm8LzdOedsu6UU/zL+/SR5bm5Ng3APH9+7HuRCADmcxRdTcTwLwfQz/nfF8CaCGleZ+ZqZt4IYBaAVvISKcnSli6XRHzoLtFcLvE49VSJKpgyJbkBrft5T3akMTgB/+eyGyOfSowbKZk+dA4/HPjVrxLbxv1KiETHjray8YxBH+M7eB/HHhXCyJG2crdzZxvVc+SR/u3NV49pgDRmjF3Xtav9IgHEQjdjkR52mLgx5s2T/25HX/Es9MGD7XyPHv70ZWXy1VBQYIf0M18aLj162PBS4+/+4gu5Fua8AXt/gvUkgHW5BF1uZvvu3f33KNnnOlkSEfR5AIYS0SAiygNwFoAZgTT/BHA4EeUQUSHEJfNFarOqNBfbOdeuP3YiLpdI6ZN98PPyxIf7858nt108z18/x5RpLUE3QpVMa8JZs8RdkwjGzx+NTp1spd2vDnoL7+NwnPl9wvz5/sZoRsiDgm5cEcuXS5jggQeKewmQSBDjhwdEsI2g9+oF3HyzzJt+8E2USixBLyz0Ry117y7CatxNZWXyvI0dC7z1lizr398/ApbZrndvCX9cuVKWffllagW9Rw+/oEeq7E0lcX3ozNxARJcBeANANoDpzLyYiC721k9l5i+I6HUAiwCEIC6az6LvVdmVWAt914e57CpBby6uYMdb31qC7jYUSiWdOknFaLzBStwGXD06e+3XI/SH/pOfSKFzSKAGzfSLU18vIkkklbHXXisVul26SD8nX38tDaqMoJeWSre4S5eKCF93na2viBblAsj+3ErOsjI5phmaz6Q7+mgr6D16yK+qSsR9yRJroRsrPidHKsNXrQK+/327/1iCbrpciCXobiX97mChg5lfY+Y9mXkwM//OWzaVmac6ae5g5mHMvC8z39NK+VWawe5eKepi0gXDFluLeILuvqitJehuQ6FU0qePVMjFc8sYQScCunb2YjQjCPqee0rFc9ClRWTdLmbarZtUoJouFh58UL4UXJdLaakc5s9/lsY9gBX0SPffVDx36SLimpsr+zD5MdfRpDv6aLut2xWE+SozFrrh6KNF0BsaUutyMYKelxe7T6NUoC1FM4CmzrnaQNB3lQ+9ubh+2Ui4USOtFWpmfMwXXZSa/R1yiIhanz4xR5JrYv/9ZTpiBJCTlyV+lmQ6C4cI67p1keP9DZ07i6Bv2iRfD24B2b+/iN3Klf4uIFxcQScSsXSfky5dRNyNuI4cKcesrhZfvrHqTSHeo4dExxDJtTr3XDtIhivoo0fL+khfOkbQg89rJJfLrnimVdAzgLasFHVHD0qEXS3obdHYKkivXsn3QhgLt/VpIvziF1L3kJ0N4LlRwDHHJH3MoIUeic6dxfpduzY8XVaWhIQuWRLdz5yXJ+vMs9GrV7igd+tmy6KcHPH3f/yxnFvv3pKme3cR/q5dJQz2jDNkGyI7sIhb6br//razrSDm+MHzMdv36mWtchV0JSU0Weht4EM/5xyxiNyOsmJhhD/S563SejRZ8t//vt+BnCCJCjogze4jpRs4UAQ9lvD17GmfpYce8lv5JSXhFct3323F+Fe/kr5z9tlH4tJNha9b8fvVV9IgybXQY7H//tLZmxlFydC3r9QjHHWUbefQ2hWigAp6RtBkobdBlEtJCXBSsF1xDEaOBB5/XBqG7CoWLIjdveny5VKhp0QnGUFfuVI6MgtiGuDEEr7HHrOF/ahR/nV/+EO4oA8ZYhsh9e9v/efRBkHv2lWMkEQhij683qmnylRdLkpKactK0WTJyvL3SrcriNevxsCB4b03Kn6SEfR16/yx6QZjFcdy30drBQzYuoDdDeNy2RUW+m7gQVRaG9Psui1cLkpmkIiguxZqNJcLYPsQTxd2pYWub3gG0JZjiiqZQTIWerR0RtBNWGO6sCsrRVXQM4DGxrarFFUyg1QIunG5pJuFri4XJaWEGtoubFHJDPbdVwTbdJcbid69bXx5pP5lTJuAa69Nff7ako4dpbCK1J9MqtFK0QwgpBa60soMHx6/64LiYrG+d+6M7H4w45umG9nZto+a1kYFPQNoqhRtB1EuSnpjBhBRWgc12TKAUKNXKZqrt1tR0hl9wzOARq+vb3W5KEp6o294BtCWfbkoirLrUEHPAEIhrRRVlExA3/AMQF0uipIZ6BueATS5XLRSVFHSGn3DMwDty0VRMgN9wzMArRRVlMxABT0DCEkYOrJy26BDdEVRdhkJCToRTSCiJUS0lIimxEh3MBE1EtHpqcui0lLackxRRVF2HXEFnYiyATwAYCKAYQB+QERh44146f4I4I1UZ1JpGcZCz85TC11R0plELPTRAJYy8zfMXA/gWQCRBhX7OYB/ANiQwvwpKcB2n6sWuqKkM4kIeh8Aq53/5d6yJoioD4BTAEyNtSMiuoiI5hPR/IqKimTzqjSTkBflkq0+dEVJaxIR9EhmXbCTy3sAXMPMjbF2xMzTmHkUM48qM50fK61OU6Wohi0qSlqTSPe55QD6Of/7AlgTSDMKwLMko7t2A3A8ETUw88upyKTSMpri0NVCV5S0JhFBnwdgKBENAvAtgLMAnO0mYOZBZp6IHgfwior57kNTpai2FFWUtCauoDNzAxFdBoleyQYwnZkXE9HF3vqYfnOl7dGWooqSGSQ0YhEzvwbgtcCyiELOzJNbni0llWjDIkXJDNRkywBCjQxCCJSlYYuKks6ooGcAjSFCFkIyCq+iKGmLCnoGEAoxshEzolRRlDRABT0DaGz0LHRFUdIaFfQMIBSCWuiKkgGooGcAoRDUQleUDEAFPQNoqhRVFCWtUUHPAEIhRjapoCtKuqOCngGoha4omYEKegYglaIq6IqS7qigZwChECFLXS6KkvaooGcA4nIJdmGvKEq6oYKeAYRCQDZpHLqipDsq6BmAWuiKkhmooGcAaqErSmaggp4BhJiQRWqhK0q6o4KeAajLRVEyAxX0DCDE0JaiipIBqKBnAI2hLI1DV5QMQAU9A5BKURV0RUl3EhJ0IppAREuIaCkRTYmw/hwiWuT9PiSiA1KfVaW5aKWoomQGcQWdiLIBPABgIoBhAH5ARMMCyZYDOJKZ9wdwC4Bpqc6o0nwaQ6QWuqJkAIlY6KMBLGXmb5i5HsCzAE5yEzDzh8y8xfs7G0Df1GZTaQlqoStKZpCIoPcBsNr5X+4ti8aPAfw70goiuoiI5hPR/IqKisRzqbSIRhV0RckIEhF0irAsojoQ0VEQQb8m0npmnsbMo5h5VFlZWeK5VFpEiNXloiiZQE4CacoB9HP+9wWwJpiIiPYH8CiAicy8KTXZU1KBdJ+rFrqipDuJWOjzAAwlokFElAfgLAAz3ARE1B/AiwDOZeavUp9NpSU0MiFbBV1R0p64FjozNxDRZQDeAJANYDozLyaii731UwFcD6ArgAeJCAAamHlU62VbSYYQE3Ky1OWiKOlOIi4XMPNrAF4LLJvqzF8I4MLUZk1JFY2chayshrbOhqIorYy2FM0AQupyUZSMQAU9A9A4dEXJDFTQM4BGzkJ2lgq6oqQ7KugZgFroipIZqKBnAFIpqoKuKOmOCnoGoJWiipIZqKBnACHOQpbeaUVJe/Q1zwCkUlQbFilKuqOCngGEQMiK1MWaoihphQp6BqCVooqSGaigZwAhjUNXlIxABT0DCIG0UlRRMgB9zTOARs7WsEVFyQBU0DMAtdAVJTPQ1zwDaORsFXRFyQD0Nc8AQiCtFFWUDEAFPQMIQVuKKkomoK95BqDd5ypKZqCCngGEkIWs7LbOhaIorY0KegbQiGxt+q8oGUBCgk5EE4hoCREtJaIpEdYTEd3rrV9ERCNSn1WluYSQhWy10BUl7Ykr6ESUDeABABMBDAPwAyIaFkg2EcBQ73cRgIdSnE+lBWilqKJkBjkJpBkNYCkzfwMARPQsgJMAfO6kOQnAk8zMAGYTUTER9WLmtanO8EvXzMZ5tw9P9W7Tmp3ojJxE7rSiKO2aRF7zPgBWO//LARySQJo+AHyCTkQXQSx4ANhOREuSyq2lG4CNzdx2d2OXnMst7wG3tL4fXe/L7omey+5Jc89lQLQViQh6JBkIxsAlkgbMPA3AtASOGTtDRPOZeVRL97M7oOeye6Lnsnui5xKbRDyr5QD6Of/7AljTjDSKoihKK5KIoM8DMJSIBhFRHoCzAMwIpJkB4Dwv2uVQAJWt4T9XFEVRohPX5cLMDUR0GYA3AGQDmM7Mi4noYm/9VACvATgewFIAOwBc0HpZBpACt81uhJ7L7omey+6JnksMSAJTFEVRlPaORicriqKkCSroiqIoaUK7E/R43RDs7hDRCiL6lIgWENF8b1kpEf2HiL72piVtnc9IENF0ItpARJ85y6LmnYiu9e7TEiIa3za5jkyUc7mRiL717s0CIjreWbdbngsR9SOi/xLRF0S0mIiu8Ja3u/sS41za430pIKK5RLTQO5ebvOWte1+Yud38IJWyywDsASAPwEIAw9o6X0mewwoA3QLLbgcwxZufAuCPbZ3PKHk/AsAIAJ/Fyzukm4iFAPIBDPLuW3Zbn0Occ7kRwC8jpN1tzwVALwAjvPnOAL7y8tvu7kuMc2mP94UAdPLmcwHMAXBoa9+X9mahN3VDwMz1AEw3BO2dkwA84c0/AeDktstKdJh5FoDNgcXR8n4SgGeZuY6Zl0MioEbvinwmQpRzicZuey7MvJaZP/HmtwH4AtJKu93dlxjnEo3d+VyYmbd7f3O9H6OV70t7E/RoXQy0JxjAm0T0sdcVAgD0YC9u35t2b7PcJU+0vLfXe3WZ12PodOdzuF2cCxENBHAQxBps1/clcC5AO7wvRJRNRAsAbADwH2Zu9fvS3gQ9oS4GdnO+w8wjID1U/oyIjmjrDLUS7fFePQRgMIADIf0Q/clbvtufCxF1AvAPAFcyc1WspBGW7e7n0i7vCzM3MvOBkJbzo4lo3xjJU3Iu7U3Q230XA8y8xptuAPAS5LNqPRH1AgBvuqHtcpg00fLe7u4VM6/3XsIQgEdgP3l363MholyIAP6NmV/0FrfL+xLpXNrrfTEw81YAMwFMQCvfl/Ym6Il0Q7DbQkQdiaizmQfwXQCfQc7hfC/Z+QD+2TY5bBbR8j4DwFlElE9EgyB95c9tg/wljHnRPE6B3BtgNz4XIiIAjwH4gpnvcla1u/sS7Vza6X0pI6Jib74DgGMBfInWvi9tXRvcjNrj4yG138sA/F9b5yfJvO8BqcleCGCxyT+ArgDeBvC1Ny1t67xGyf8zkE/enRCL4sex8g7g/7z7tATAxLbOfwLn8hSATwEs8l6wXrv7uQAYC/k0XwRggfc7vj3elxjn0h7vy/4A/ufl+TMA13vLW/W+aNN/RVGUNKG9uVwURVGUKKigK4qipAkq6IqiKGmCCrqiKEqaoIKuKIqSJqigK4qipAkq6IqiKGnC/wPXwseCjsjzRAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision = history.history['precision']\n",
    "val_precision = history.history['val_precision']\n",
    "epochs=range(len(precision))\n",
    "plt.plot(epochs, precision, 'r')\n",
    "plt.plot(epochs, val_precision, 'b')\n",
    "plt.title('Training and validation Precision')\n",
    "plt.ylim((0,1.5))\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 54ms/step - loss: 0.5530 - precision: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5529599785804749, 0.6666666865348816]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelb_glove200.evaluate(test_padded, test_labels_final)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
