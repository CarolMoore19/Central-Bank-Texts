{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1jV3IklNUb9"
   },
   "source": [
    "# Read data\n",
    "\n",
    "The dataset was compiled from the files for the United States Federal Reserve Bank and the (usa_df.csv) and the European Union Euporean Central Bank (ecb_df.csv) the initial corpus at https://github.com/CarolMoore19/Central-Bank-Texts-Parsed, which contains announcements following all scheduled meetings of monetary policy committees. These data were further cleaned and prepared offline, and combined with macroeconomic variables downloaded from the Fed's public site for economic data, https://fred.stlouisfed.org/.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jKJNCSme3J8U"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmd8a\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import os \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AwvJe8gh3Vth"
   },
   "outputs": [],
   "source": [
    "os.chdir('/Users/dmd8a/OneDrive - University of Virginia/Desktop/MSDS/DS6050/Project')\n",
    "df=pd.read_csv('us_ecb_combined_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVNwmSyvPWGp"
   },
   "source": [
    "The key variables are:\n",
    "\n",
    "* Bank:  The US Federal Reserve or European Central Bnak\n",
    "\n",
    "* rate_curr:  the policy (target) interest rate set at the monetary policy committee meeting.  \n",
    "\n",
    "* rate_next:  the rate set at the subsequent meeting.\n",
    "\n",
    "* rate_change:  a categorical variable indicating if the rate changed between the current and next meeting\n",
    "\n",
    "Macroeconomic variables are only available for the US at this time:\n",
    "\n",
    "* urate:  the unemployment rate on the first day of the month of the meeting\n",
    "\n",
    "* pce_inf:  inflation for personal consumption expenditures, less food and energy, on the first day of the month of the meeting.  This is the inflation concept that the Fed uses for policy.\n",
    "\n",
    "* effective_ffr:  The market federal funds rate on the first day of the month of the meeting.  When setting policy, the fed is trying to influence this interest rate.\n",
    "\n",
    "Other variables - filename, date_dt, and chron_order_in_country - exist to to keep track of the meeting dates and do not enter into the analysis below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TUBETiSa3eiY",
    "outputId": "41a12ec1-9a95-424a-ff3e-8c44657abf34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 434 entries, 0 to 433\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   bank                    434 non-null    object \n",
      " 1   filename                434 non-null    object \n",
      " 2   date_dt                 434 non-null    object \n",
      " 3   chron_order_in_country  434 non-null    int64  \n",
      " 4   rate_curr               434 non-null    float64\n",
      " 5   rate_next               434 non-null    float64\n",
      " 6   rate_change             434 non-null    int64  \n",
      " 7   urate                   171 non-null    float64\n",
      " 8   pce_inf                 171 non-null    float64\n",
      " 9   effective_ffr           171 non-null    float64\n",
      " 10  statement               434 non-null    object \n",
      "dtypes: float64(5), int64(2), object(4)\n",
      "memory usage: 37.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hrx9B4wd4MiX",
    "outputId": "1b1d16de-81d2-4970-8c28-3d89b5e10a59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(434, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-ZC7xHqSV2W"
   },
   "source": [
    "# Standardize continuous variables\n",
    "\n",
    "To predict the interest rate level to be set at the next policy meeting, we scale the target variables: 'rate_next' , 'rate_curr', and the macroeconomic variables.\n",
    "\n",
    "Note that the central bank communications are tailored for their own jurisdictions and economic conditions.  The policy interest rate concept differs for each bank. Further, the ranges of experience are differ:  ECB has had negative nominal interest rates, which the Fed never had. \n",
    "\n",
    "For this reason, we apply a stratified standardization - one for the ECB and one for the US banks. This means that a standardized value of 0 represents the average rate for the ECB and the Fed, respectively, rather than an overall average across both banks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DIXQXcjLUqWJ",
    "outputId": "40584a53-4699-4f9f-bffa-bbd01989b6fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ecb      265\n",
       "usfed    169\n",
       "Name: bank, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.bank.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TDssovfgSHfA"
   },
   "outputs": [],
   "source": [
    "#Target var - next meeting policy rate\n",
    "df['y_std_us'] = np.where(df.bank=='usfed',\n",
    "                          (df.rate_next - np.mean(df.rate_next))/np.std(df.rate_next),np.nan)\n",
    "df['y_std_ecb'] = np.where(df.bank=='ecb',\n",
    "                          (df.rate_next - np.mean(df.rate_next))/np.std(df.rate_next),np.nan)\n",
    "df['y_std'] = np.where(df.bank=='ecb',df.y_std_ecb,df.y_std_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "zg-TiYoVVR-E",
    "outputId": "fd0ec016-a012-4c42-b214-24c1af394aa7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>y_std_us</th>\n",
       "      <th>y_std_ecb</th>\n",
       "      <th>y_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usfed</td>\n",
       "      <td>0.039051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usfed</td>\n",
       "      <td>0.039051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usfed</td>\n",
       "      <td>0.039051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>usfed</td>\n",
       "      <td>-0.271642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.271642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>usfed</td>\n",
       "      <td>-0.271642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.271642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>ecb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.126050</td>\n",
       "      <td>-1.126050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>ecb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.126050</td>\n",
       "      <td>-1.126050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>ecb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.126050</td>\n",
       "      <td>-1.126050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>ecb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.815357</td>\n",
       "      <td>-0.815357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>ecb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.349316</td>\n",
       "      <td>-0.349316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>434 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      bank  y_std_us  y_std_ecb     y_std\n",
       "0    usfed  0.039051        NaN  0.039051\n",
       "1    usfed  0.039051        NaN  0.039051\n",
       "2    usfed  0.039051        NaN  0.039051\n",
       "3    usfed -0.271642        NaN -0.271642\n",
       "4    usfed -0.271642        NaN -0.271642\n",
       "..     ...       ...        ...       ...\n",
       "429    ecb       NaN  -1.126050 -1.126050\n",
       "430    ecb       NaN  -1.126050 -1.126050\n",
       "431    ecb       NaN  -1.126050 -1.126050\n",
       "432    ecb       NaN  -0.815357 -0.815357\n",
       "433    ecb       NaN  -0.349316 -0.349316\n",
       "\n",
       "[434 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['bank','y_std_us','y_std_ecb', 'y_std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "h-Z5wwCSt8PV"
   },
   "outputs": [],
   "source": [
    "#Current var -  policy rate set at current meeting\n",
    "df['y_std_us_curr'] = np.where(df.bank=='usfed',\n",
    "                          (df.rate_curr - np.mean(df.rate_curr))/np.std(df.rate_curr),np.nan)\n",
    "df['y_std_ecb_curr'] = np.where(df.bank=='ecb',\n",
    "                          (df.rate_curr - np.mean(df.rate_curr))/np.std(df.rate_curr),np.nan)\n",
    "df['y_std_curr'] = np.where(df.bank=='ecb',df.y_std_ecb_curr,df.y_std_us_curr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F35N9R2Qr1B6"
   },
   "source": [
    "### Standardize macroeconomic variables - only available for US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "f0T7hS9ZrzsK"
   },
   "outputs": [],
   "source": [
    "#Unemployment rate the first of the month in which the meeting occurred.\n",
    "df['urate_us_std'] = np.where(df.bank=='usfed',\n",
    "                          (df.urate - np.mean(df.urate))/np.std(df.urate),np.nan)\n",
    "\n",
    "#Inflation\n",
    "df['inf_us_std'] = np.where(df.bank=='usfed',(\n",
    "    df.pce_inf - np.mean(df.pce_inf))/np.std(df.pce_inf),np.nan)\n",
    "\n",
    "\n",
    "#Effective (market) Federal Fuinds RATE\n",
    "df['effr_us_std'] = np.where(df.bank=='usfed',\n",
    "    (df.effective_ffr - np.mean(df.effective_ffr))/np.std(df.effective_ffr),np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpPuyVWBjnxj"
   },
   "source": [
    "# Keep the variables we need for the analysis\n",
    "\n",
    "The rate_change variable includes 3 categories - up, down, and same. After some experimentation and following examples in the literature we chose to model a binary outcome, up (1) or not up (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "x40hOkZ3f9iq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>y_std_curr</th>\n",
       "      <th>y_std</th>\n",
       "      <th>urate_us_std</th>\n",
       "      <th>inf_us_std</th>\n",
       "      <th>effr_us_std</th>\n",
       "      <th>rate_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>0.037428</td>\n",
       "      <td>0.039051</td>\n",
       "      <td>-0.104017</td>\n",
       "      <td>-0.273528</td>\n",
       "      <td>0.348743</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>0.037428</td>\n",
       "      <td>0.039051</td>\n",
       "      <td>-0.104017</td>\n",
       "      <td>-0.358325</td>\n",
       "      <td>0.309969</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>0.037428</td>\n",
       "      <td>0.039051</td>\n",
       "      <td>-0.153426</td>\n",
       "      <td>-0.238576</td>\n",
       "      <td>0.361668</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>0.037428</td>\n",
       "      <td>-0.271642</td>\n",
       "      <td>-0.153426</td>\n",
       "      <td>0.706411</td>\n",
       "      <td>0.387517</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.273162</td>\n",
       "      <td>-0.271642</td>\n",
       "      <td>-0.054609</td>\n",
       "      <td>-0.225833</td>\n",
       "      <td>-0.013152</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.273162</td>\n",
       "      <td>-0.271642</td>\n",
       "      <td>-0.005201</td>\n",
       "      <td>-0.136049</td>\n",
       "      <td>-0.058388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.273162</td>\n",
       "      <td>-0.271642</td>\n",
       "      <td>-0.104017</td>\n",
       "      <td>-0.122053</td>\n",
       "      <td>0.051472</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.273162</td>\n",
       "      <td>-0.271642</td>\n",
       "      <td>-0.054609</td>\n",
       "      <td>-0.136619</td>\n",
       "      <td>0.083784</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the federal open market committee decided to k...</td>\n",
       "      <td>-0.273162</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>0.044207</td>\n",
       "      <td>-0.310871</td>\n",
       "      <td>0.019160</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>0.143024</td>\n",
       "      <td>-0.441503</td>\n",
       "      <td>0.129021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           statement  y_std_curr     y_std  \\\n",
       "0  the federal open market committee decided toda...    0.037428  0.039051   \n",
       "1  the federal open market committee decided toda...    0.037428  0.039051   \n",
       "2  the federal open market committee decided toda...    0.037428  0.039051   \n",
       "3  the federal open market committee decided toda...    0.037428 -0.271642   \n",
       "4  the federal open market committee decided toda...   -0.273162 -0.271642   \n",
       "5  the federal open market committee decided toda...   -0.273162 -0.271642   \n",
       "6  the federal open market committee decided toda...   -0.273162 -0.271642   \n",
       "7  the federal open market committee decided toda...   -0.273162 -0.271642   \n",
       "8  the federal open market committee decided to k...   -0.273162 -0.426989   \n",
       "9  the federal open market committee decided toda...   -0.428457 -0.426989   \n",
       "\n",
       "   urate_us_std  inf_us_std  effr_us_std  rate_change  \n",
       "0     -0.104017   -0.273528     0.348743            0  \n",
       "1     -0.104017   -0.358325     0.309969            0  \n",
       "2     -0.153426   -0.238576     0.361668            0  \n",
       "3     -0.153426    0.706411     0.387517           -1  \n",
       "4     -0.054609   -0.225833    -0.013152            0  \n",
       "5     -0.005201   -0.136049    -0.058388            0  \n",
       "6     -0.104017   -0.122053     0.051472            0  \n",
       "7     -0.054609   -0.136619     0.083784            0  \n",
       "8      0.044207   -0.310871     0.019160           -1  \n",
       "9      0.143024   -0.441503     0.129021            0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[['statement', 'y_std_curr','y_std','urate_us_std', 'inf_us_std', 'effr_us_std', 'rate_change']]\n",
    "#df=df[['statement', 'rate_change', 'rate_next']]\n",
    "#df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "SE4yn2PjND1R",
    "outputId": "84ce4271-7aaa-4a78-c1a4-9aabcdc34cc8",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>y_std_curr</th>\n",
       "      <th>y_std</th>\n",
       "      <th>urate_us_std</th>\n",
       "      <th>inf_us_std</th>\n",
       "      <th>effr_us_std</th>\n",
       "      <th>rate_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>0.037428</td>\n",
       "      <td>0.039051</td>\n",
       "      <td>-0.104017</td>\n",
       "      <td>-0.273528</td>\n",
       "      <td>0.348743</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>0.037428</td>\n",
       "      <td>0.039051</td>\n",
       "      <td>-0.104017</td>\n",
       "      <td>-0.358325</td>\n",
       "      <td>0.309969</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>0.037428</td>\n",
       "      <td>0.039051</td>\n",
       "      <td>-0.153426</td>\n",
       "      <td>-0.238576</td>\n",
       "      <td>0.361668</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>0.037428</td>\n",
       "      <td>-0.271642</td>\n",
       "      <td>-0.153426</td>\n",
       "      <td>0.706411</td>\n",
       "      <td>0.387517</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.273162</td>\n",
       "      <td>-0.271642</td>\n",
       "      <td>-0.054609</td>\n",
       "      <td>-0.225833</td>\n",
       "      <td>-0.013152</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.273162</td>\n",
       "      <td>-0.271642</td>\n",
       "      <td>-0.005201</td>\n",
       "      <td>-0.136049</td>\n",
       "      <td>-0.058388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.273162</td>\n",
       "      <td>-0.271642</td>\n",
       "      <td>-0.104017</td>\n",
       "      <td>-0.122053</td>\n",
       "      <td>0.051472</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.273162</td>\n",
       "      <td>-0.271642</td>\n",
       "      <td>-0.054609</td>\n",
       "      <td>-0.136619</td>\n",
       "      <td>0.083784</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the federal open market committee decided to k...</td>\n",
       "      <td>-0.273162</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>0.044207</td>\n",
       "      <td>-0.310871</td>\n",
       "      <td>0.019160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>0.143024</td>\n",
       "      <td>-0.441503</td>\n",
       "      <td>0.129021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the committee continues to believe that an acc...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>0.044207</td>\n",
       "      <td>-0.489983</td>\n",
       "      <td>-0.155324</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>0.044207</td>\n",
       "      <td>-0.520189</td>\n",
       "      <td>-0.051926</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>-0.005201</td>\n",
       "      <td>-0.393720</td>\n",
       "      <td>-0.181174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>-0.153426</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-0.200561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>-0.153426</td>\n",
       "      <td>-0.060780</td>\n",
       "      <td>-0.142400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>-0.104017</td>\n",
       "      <td>-0.019717</td>\n",
       "      <td>-0.129475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.271642</td>\n",
       "      <td>-0.202834</td>\n",
       "      <td>0.162546</td>\n",
       "      <td>-0.148862</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.273162</td>\n",
       "      <td>-0.116295</td>\n",
       "      <td>-0.202834</td>\n",
       "      <td>0.294014</td>\n",
       "      <td>0.083784</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>-0.117867</td>\n",
       "      <td>0.039051</td>\n",
       "      <td>-0.301651</td>\n",
       "      <td>0.029940</td>\n",
       "      <td>0.193645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>the federal open market committee decided toda...</td>\n",
       "      <td>0.037428</td>\n",
       "      <td>0.194398</td>\n",
       "      <td>-0.301651</td>\n",
       "      <td>0.090479</td>\n",
       "      <td>0.445679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            statement  y_std_curr     y_std  \\\n",
       "0   the federal open market committee decided toda...    0.037428  0.039051   \n",
       "1   the federal open market committee decided toda...    0.037428  0.039051   \n",
       "2   the federal open market committee decided toda...    0.037428  0.039051   \n",
       "3   the federal open market committee decided toda...    0.037428 -0.271642   \n",
       "4   the federal open market committee decided toda...   -0.273162 -0.271642   \n",
       "5   the federal open market committee decided toda...   -0.273162 -0.271642   \n",
       "6   the federal open market committee decided toda...   -0.273162 -0.271642   \n",
       "7   the federal open market committee decided toda...   -0.273162 -0.271642   \n",
       "8   the federal open market committee decided to k...   -0.273162 -0.426989   \n",
       "9   the federal open market committee decided toda...   -0.428457 -0.426989   \n",
       "10  the committee continues to believe that an acc...   -0.428457 -0.426989   \n",
       "11  the federal open market committee decided toda...   -0.428457 -0.426989   \n",
       "12  the federal open market committee decided toda...   -0.428457 -0.426989   \n",
       "13  the federal open market committee decided toda...   -0.428457 -0.426989   \n",
       "14  the federal open market committee decided toda...   -0.428457 -0.426989   \n",
       "15  the federal open market committee decided toda...   -0.428457 -0.426989   \n",
       "16  the federal open market committee decided toda...   -0.428457 -0.271642   \n",
       "17  the federal open market committee decided toda...   -0.273162 -0.116295   \n",
       "18  the federal open market committee decided toda...   -0.117867  0.039051   \n",
       "19  the federal open market committee decided toda...    0.037428  0.194398   \n",
       "\n",
       "    urate_us_std  inf_us_std  effr_us_std  rate_change  \n",
       "0      -0.104017   -0.273528     0.348743            0  \n",
       "1      -0.104017   -0.358325     0.309969            0  \n",
       "2      -0.153426   -0.238576     0.361668            0  \n",
       "3      -0.153426    0.706411     0.387517            1  \n",
       "4      -0.054609   -0.225833    -0.013152            0  \n",
       "5      -0.005201   -0.136049    -0.058388            0  \n",
       "6      -0.104017   -0.122053     0.051472            0  \n",
       "7      -0.054609   -0.136619     0.083784            0  \n",
       "8       0.044207   -0.310871     0.019160            1  \n",
       "9       0.143024   -0.441503     0.129021            0  \n",
       "10      0.044207   -0.489983    -0.155324            0  \n",
       "11      0.044207   -0.520189    -0.051926            0  \n",
       "12     -0.005201   -0.393720    -0.181174            0  \n",
       "13     -0.153426   -0.301254    -0.200561            0  \n",
       "14     -0.153426   -0.060780    -0.142400            0  \n",
       "15     -0.104017   -0.019717    -0.129475            0  \n",
       "16     -0.202834    0.162546    -0.148862            0  \n",
       "17     -0.202834    0.294014     0.083784            0  \n",
       "18     -0.301651    0.029940     0.193645            0  \n",
       "19     -0.301651    0.090479     0.445679            0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rate_change'] = np.where(df['rate_change'] == 1, 0, df['rate_change'])\n",
    "df['rate_change'] = np.where(df['rate_change'] == -1, 1, df['rate_change']) # now down is 1 and not down is 0\n",
    "#df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIDI1AWhmQ3O"
   },
   "source": [
    "# Get some rough stats on the text. Knowng the length of each statement will guide our choice of dimensions later.  \n",
    "\n",
    "The max approximate length of the statements is 1,011."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqWTRpVMND1S",
    "outputId": "b7010a96-e02c-4840-ac01-92e1a8a5a05e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     434.000000\n",
       "mean      229.396313\n",
       "std       213.255292\n",
       "min        36.000000\n",
       "25%        63.000000\n",
       "50%       148.000000\n",
       "75%       380.500000\n",
       "max      1011.000000\n",
       "Name: statement, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx_length = df['statement'].str.split().str.len()\n",
    "approx_length.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NR76ZNv_ZU5z"
   },
   "source": [
    "# Shuffle the data and split it into test, train and validation sets.\n",
    "\n",
    "Although the original data are time-series, the file is not organized as such.  The future values are on the same row as the current values. Therefore we shuffle the data.\n",
    "\n",
    "We first divide the file into test and train.  Then we split the test file into test and validate (60%, 20%, 20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "D9SuoyxbqF7G"
   },
   "outputs": [],
   "source": [
    "df_shuffled=df.sample(frac=1, random_state=42).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "iHl-2doiq3Gq",
    "outputId": "759369fb-d1b2-43f0-c6bb-661982835faa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>statement</th>\n",
       "      <th>y_std_curr</th>\n",
       "      <th>y_std</th>\n",
       "      <th>urate_us_std</th>\n",
       "      <th>inf_us_std</th>\n",
       "      <th>effr_us_std</th>\n",
       "      <th>rate_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>280</td>\n",
       "      <td>at today's meeting, the governing council of t...</td>\n",
       "      <td>1.279790</td>\n",
       "      <td>1.281827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78</td>\n",
       "      <td>information received since the federal open ma...</td>\n",
       "      <td>-0.894343</td>\n",
       "      <td>-0.893030</td>\n",
       "      <td>1.477048</td>\n",
       "      <td>-0.047189</td>\n",
       "      <td>-0.756328</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113</td>\n",
       "      <td>information received since the federal open ma...</td>\n",
       "      <td>-0.739048</td>\n",
       "      <td>-0.737683</td>\n",
       "      <td>-0.499284</td>\n",
       "      <td>-0.946329</td>\n",
       "      <td>-0.678779</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>0.192724</td>\n",
       "      <td>0.194398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>324</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                          statement  y_std_curr  \\\n",
       "0    280  at today's meeting, the governing council of t...    1.279790   \n",
       "1     78  information received since the federal open ma...   -0.894343   \n",
       "2    113  information received since the federal open ma...   -0.739048   \n",
       "3    253  at today's meeting the governing council of th...    0.192724   \n",
       "4    324  at today's meeting the governing council of th...   -0.428457   \n",
       "\n",
       "      y_std  urate_us_std  inf_us_std  effr_us_std  rate_change  \n",
       "0  1.281827           NaN         NaN          NaN            0  \n",
       "1 -0.893030      1.477048   -0.047189    -0.756328            0  \n",
       "2 -0.737683     -0.499284   -0.946329    -0.678779            0  \n",
       "3  0.194398           NaN         NaN          NaN            0  \n",
       "4 -0.426989           NaN         NaN          NaN            0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M68nu7j92XiP",
    "outputId": "3b3c7adc-e85c-4e17-9614-64b19fb6cbb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(434, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x8rul3Kx5eE6",
    "outputId": "53525de3-754e-4adb-b8a8-f5366b4b608d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260 347\n"
     ]
    }
   ],
   "source": [
    "train_cut=int(.6*df_shuffled.shape[0])\n",
    "val_cut=int(.8*df_shuffled.shape[0])\n",
    "print(train_cut, val_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "188yG1l0iShI",
    "outputId": "68c5925b-2639-4760-9cb8-49fb225b586b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>statement</th>\n",
       "      <th>y_std_curr</th>\n",
       "      <th>y_std</th>\n",
       "      <th>urate_us_std</th>\n",
       "      <th>inf_us_std</th>\n",
       "      <th>effr_us_std</th>\n",
       "      <th>rate_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>280</td>\n",
       "      <td>at today's meeting, the governing council of t...</td>\n",
       "      <td>1.279790</td>\n",
       "      <td>1.281827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78</td>\n",
       "      <td>information received since the federal open ma...</td>\n",
       "      <td>-0.894343</td>\n",
       "      <td>-0.893030</td>\n",
       "      <td>1.477048</td>\n",
       "      <td>-0.047189</td>\n",
       "      <td>-0.756328</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113</td>\n",
       "      <td>information received since the federal open ma...</td>\n",
       "      <td>-0.739048</td>\n",
       "      <td>-0.737683</td>\n",
       "      <td>-0.499284</td>\n",
       "      <td>-0.946329</td>\n",
       "      <td>-0.678779</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>0.192724</td>\n",
       "      <td>0.194398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>324</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>179</td>\n",
       "      <td>at today's meeting (which was held in the form...</td>\n",
       "      <td>1.279790</td>\n",
       "      <td>1.592521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>320</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>294</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>1.435086</td>\n",
       "      <td>1.592521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>285</td>\n",
       "      <td>at today's meeting, the governing council of t...</td>\n",
       "      <td>1.435086</td>\n",
       "      <td>1.437174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>418</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>-1.127286</td>\n",
       "      <td>-1.126050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                          statement  y_std_curr  \\\n",
       "0      280  at today's meeting, the governing council of t...    1.279790   \n",
       "1       78  information received since the federal open ma...   -0.894343   \n",
       "2      113  information received since the federal open ma...   -0.739048   \n",
       "3      253  at today's meeting the governing council of th...    0.192724   \n",
       "4      324  at today's meeting the governing council of th...   -0.428457   \n",
       "..     ...                                                ...         ...   \n",
       "255    179  at today's meeting (which was held in the form...    1.279790   \n",
       "256    320  at today's meeting the governing council of th...   -0.428457   \n",
       "257    294  at today's meeting the governing council of th...    1.435086   \n",
       "258    285  at today's meeting, the governing council of t...    1.435086   \n",
       "259    418  at today's meeting the governing council of th...   -1.127286   \n",
       "\n",
       "        y_std  urate_us_std  inf_us_std  effr_us_std  rate_change  \n",
       "0    1.281827           NaN         NaN          NaN            0  \n",
       "1   -0.893030      1.477048   -0.047189    -0.756328            0  \n",
       "2   -0.737683     -0.499284   -0.946329    -0.678779            0  \n",
       "3    0.194398           NaN         NaN          NaN            0  \n",
       "4   -0.426989           NaN         NaN          NaN            0  \n",
       "..        ...           ...         ...          ...          ...  \n",
       "255  1.592521           NaN         NaN          NaN            0  \n",
       "256 -0.426989           NaN         NaN          NaN            0  \n",
       "257  1.592521           NaN         NaN          NaN            0  \n",
       "258  1.437174           NaN         NaN          NaN            0  \n",
       "259 -1.126050           NaN         NaN          NaN            0  \n",
       "\n",
       "[260 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=df_shuffled.iloc[0:train_cut,:]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "7G_YT2bAtFMe",
    "outputId": "819525e2-218e-4fca-f3a7-4a84eb1eb7d9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>statement</th>\n",
       "      <th>y_std_curr</th>\n",
       "      <th>y_std</th>\n",
       "      <th>urate_us_std</th>\n",
       "      <th>inf_us_std</th>\n",
       "      <th>effr_us_std</th>\n",
       "      <th>rate_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>407</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>-1.096227</td>\n",
       "      <td>-1.094981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>233</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>0.503314</td>\n",
       "      <td>0.194398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>354</td>\n",
       "      <td>at today's meeting, which was held in bratisla...</td>\n",
       "      <td>-0.739048</td>\n",
       "      <td>-0.737683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>164</td>\n",
       "      <td>the federal reserve is committed to using its ...</td>\n",
       "      <td>-0.894343</td>\n",
       "      <td>-0.893030</td>\n",
       "      <td>-1.042775</td>\n",
       "      <td>4.007804</td>\n",
       "      <td>-0.762790</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>136</td>\n",
       "      <td>information received since the federal open ma...</td>\n",
       "      <td>0.348019</td>\n",
       "      <td>0.349745</td>\n",
       "      <td>-1.141592</td>\n",
       "      <td>0.269350</td>\n",
       "      <td>0.600777</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>352</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>-0.583753</td>\n",
       "      <td>-0.582336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>216</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>0.969200</td>\n",
       "      <td>0.971133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>279</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>1.279790</td>\n",
       "      <td>1.281827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>377</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>-1.018579</td>\n",
       "      <td>-1.017308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>337</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>-0.428457</td>\n",
       "      <td>-0.426989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                          statement  y_std_curr  \\\n",
       "260    407  at today's meeting the governing council of th...   -1.096227   \n",
       "261    233  at today's meeting the governing council of th...    0.503314   \n",
       "262    354  at today's meeting, which was held in bratisla...   -0.739048   \n",
       "263    164  the federal reserve is committed to using its ...   -0.894343   \n",
       "264    136  information received since the federal open ma...    0.348019   \n",
       "..     ...                                                ...         ...   \n",
       "342    352  at today's meeting the governing council of th...   -0.583753   \n",
       "343    216  at today's meeting the governing council of th...    0.969200   \n",
       "344    279  at today's meeting the governing council of th...    1.279790   \n",
       "345    377  at today's meeting the governing council of th...   -1.018579   \n",
       "346    337  at today's meeting the governing council of th...   -0.428457   \n",
       "\n",
       "        y_std  urate_us_std  inf_us_std  effr_us_std  rate_change  \n",
       "260 -1.094981           NaN         NaN          NaN            0  \n",
       "261  0.194398           NaN         NaN          NaN            1  \n",
       "262 -0.737683           NaN         NaN          NaN            0  \n",
       "263 -0.893030     -1.042775    4.007804    -0.762790            0  \n",
       "264  0.349745     -1.141592    0.269350     0.600777            0  \n",
       "..        ...           ...         ...          ...          ...  \n",
       "342 -0.582336           NaN         NaN          NaN            0  \n",
       "343  0.971133           NaN         NaN          NaN            0  \n",
       "344  1.281827           NaN         NaN          NaN            0  \n",
       "345 -1.017308           NaN         NaN          NaN            0  \n",
       "346 -0.426989           NaN         NaN          NaN            0  \n",
       "\n",
       "[87 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val=df_shuffled.iloc[train_cut:val_cut,:]\n",
    "df_val       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "D_QhAmpdtuhp",
    "outputId": "70bd484b-f749-47e3-eef9-35b73a4c1182"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>statement</th>\n",
       "      <th>y_std_curr</th>\n",
       "      <th>y_std</th>\n",
       "      <th>urate_us_std</th>\n",
       "      <th>inf_us_std</th>\n",
       "      <th>effr_us_std</th>\n",
       "      <th>rate_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>236</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>0.192724</td>\n",
       "      <td>0.194398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>207</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>1.745676</td>\n",
       "      <td>1.747868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>212</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>1.279790</td>\n",
       "      <td>1.281827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>295</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>1.590381</td>\n",
       "      <td>1.592521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>397</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>-1.096227</td>\n",
       "      <td>-1.094981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>71</td>\n",
       "      <td>information received since the federal open ma...</td>\n",
       "      <td>-0.894343</td>\n",
       "      <td>-0.893030</td>\n",
       "      <td>1.724089</td>\n",
       "      <td>-0.732240</td>\n",
       "      <td>-0.711091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>106</td>\n",
       "      <td>information received since the federal open ma...</td>\n",
       "      <td>-0.894343</td>\n",
       "      <td>-0.893030</td>\n",
       "      <td>-0.153426</td>\n",
       "      <td>-0.657313</td>\n",
       "      <td>-0.769253</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>270</td>\n",
       "      <td>at today's meeting, which was held in madrid, ...</td>\n",
       "      <td>0.658609</td>\n",
       "      <td>0.660439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>348</td>\n",
       "      <td>at today's meeting the governing council of th...</td>\n",
       "      <td>-0.583753</td>\n",
       "      <td>-0.582336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>102</td>\n",
       "      <td>information received since the federal open ma...</td>\n",
       "      <td>-0.894343</td>\n",
       "      <td>-0.893030</td>\n",
       "      <td>0.093616</td>\n",
       "      <td>-0.129469</td>\n",
       "      <td>-0.756328</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                          statement  y_std_curr  \\\n",
       "347    236  at today's meeting the governing council of th...    0.192724   \n",
       "348    207  at today's meeting the governing council of th...    1.745676   \n",
       "349    212  at today's meeting the governing council of th...    1.279790   \n",
       "350    295  at today's meeting the governing council of th...    1.590381   \n",
       "351    397  at today's meeting the governing council of th...   -1.096227   \n",
       "..     ...                                                ...         ...   \n",
       "429     71  information received since the federal open ma...   -0.894343   \n",
       "430    106  information received since the federal open ma...   -0.894343   \n",
       "431    270  at today's meeting, which was held in madrid, ...    0.658609   \n",
       "432    348  at today's meeting the governing council of th...   -0.583753   \n",
       "433    102  information received since the federal open ma...   -0.894343   \n",
       "\n",
       "        y_std  urate_us_std  inf_us_std  effr_us_std  rate_change  \n",
       "347  0.194398           NaN         NaN          NaN            0  \n",
       "348  1.747868           NaN         NaN          NaN            0  \n",
       "349  1.281827           NaN         NaN          NaN            0  \n",
       "350  1.592521           NaN         NaN          NaN            0  \n",
       "351 -1.094981           NaN         NaN          NaN            0  \n",
       "..        ...           ...         ...          ...          ...  \n",
       "429 -0.893030      1.724089   -0.732240    -0.711091            0  \n",
       "430 -0.893030     -0.153426   -0.657313    -0.769253            0  \n",
       "431  0.660439           NaN         NaN          NaN            0  \n",
       "432 -0.582336           NaN         NaN          NaN            0  \n",
       "433 -0.893030      0.093616   -0.129469    -0.756328            0  \n",
       "\n",
       "[87 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test=df_shuffled.iloc[val_cut:df_shuffled.shape[0],:]\n",
    "df_test  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtWZGAEhurwC"
   },
   "source": [
    "# Part I.  Model with embeddings derived from our corpus.  \n",
    "\n",
    "In this model, our own corpus is the source of the embedding layer.  By using our own embeddings we may be making training less efficient and generalizable than if we used a pre-trained model.  Given the small size of our data set, however, training is still very fast and because of the highly specialized nature of our corpus, self-created embeddings could be more predictive.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VigM-PBEudv_"
   },
   "source": [
    "The next section of code was demonstrated by Sucky in:\n",
    "https://towardsdatascience.com/a-complete-step-by-step-tutorial-on-sentiment-analysis-in-keras-and-tensorflow-ea420cc8913f. It offers a straightforward way to create embeddings in Keras and incorporate them into a neural network.\n",
    "\n",
    "The first step is to ensure that the data are in the correct format:  the statement should be a string and the target variables, y_std_curr and y_std should be floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6WICo1HGvrSB",
    "outputId": "4df1176d-c34f-41cf-be5c-b2d65a202bed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87 entries, 347 to 433\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   index         87 non-null     int64  \n",
      " 1   statement     87 non-null     object \n",
      " 2   y_std_curr    87 non-null     float64\n",
      " 3   y_std         87 non-null     float64\n",
      " 4   urate_us_std  30 non-null     float64\n",
      " 5   inf_us_std    30 non-null     float64\n",
      " 6   effr_us_std   30 non-null     float64\n",
      " 7   rate_change   87 non-null     int64  \n",
      "dtypes: float64(5), int64(2), object(1)\n",
      "memory usage: 5.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1DrcofC2yKO6",
    "outputId": "40e34167-672b-48e1-e934-c0332b1c4304"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 260 entries, 0 to 259\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   index         260 non-null    int64  \n",
      " 1   statement     260 non-null    object \n",
      " 2   y_std_curr    260 non-null    float64\n",
      " 3   y_std         260 non-null    float64\n",
      " 4   urate_us_std  104 non-null    float64\n",
      " 5   inf_us_std    104 non-null    float64\n",
      " 6   effr_us_std   104 non-null    float64\n",
      " 7   rate_change   260 non-null    int64  \n",
      "dtypes: float64(5), int64(2), object(1)\n",
      "memory usage: 16.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i8GkL-lVx4h6",
    "outputId": "8da8fa95-0cb6-4431-afd1-abdab6f0bcae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87 entries, 260 to 346\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   index         87 non-null     int64  \n",
      " 1   statement     87 non-null     object \n",
      " 2   y_std_curr    87 non-null     float64\n",
      " 3   y_std         87 non-null     float64\n",
      " 4   urate_us_std  35 non-null     float64\n",
      " 5   inf_us_std    35 non-null     float64\n",
      " 6   effr_us_std   35 non-null     float64\n",
      " 7   rate_change   87 non-null     int64  \n",
      "dtypes: float64(5), int64(2), object(1)\n",
      "memory usage: 5.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_val.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_v6l6_9wySCE"
   },
   "source": [
    "# Interest rate level prediction - predicting policy at next meeting\n",
    "\n",
    "In the next section we try to predict the value of the interest rate using various models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "PLYxULkF49_4"
   },
   "outputs": [],
   "source": [
    "train_statement = df_train.statement\n",
    "train_label = df_train.rate_change\n",
    "#train_label=df_train.rate_next\n",
    "\n",
    "test_statement = df_test.statement\n",
    "test_label = df_test.rate_change\n",
    "#test_label = df_test.rate_next\n",
    "\n",
    "val_statement = df_val.statement\n",
    "#val_label = df_val.rate_next\n",
    "val_label = df_val.rate_change\n",
    "\n",
    "training_sentences = []\n",
    "training_labels = []\n",
    "testing_sentences = []\n",
    "testing_labels = []\n",
    "val_sentences = []\n",
    "val_labels = []\n",
    "\n",
    "for row in train_statement:\n",
    "    training_sentences.append(str(row))\n",
    "for row in train_label:\n",
    "    training_labels.append(row)\n",
    "\n",
    "for row in test_statement:\n",
    "    testing_sentences.append(str(row))\n",
    "for row in test_label:\n",
    "    testing_labels.append(row)\n",
    "\n",
    "for row in val_statement:\n",
    "    val_sentences.append(str(row))\n",
    "for row in val_label:\n",
    "    val_labels.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PRq1Ro0Q4C9d",
    "outputId": "967ba85e-8d97-4b05-b06b-0475bc37c2a6"
   },
   "outputs": [],
   "source": [
    "#print(val_sentences[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MqyG6LA0-Rbf",
    "outputId": "b894f67f-be69-4c7f-ba1f-8289d75c90db"
   },
   "outputs": [],
   "source": [
    "#print(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "p3sV3KW7_MRj"
   },
   "outputs": [],
   "source": [
    "#Convert labels from lists to numpy arrays.  We deal with the statements below.\n",
    "training_labels_final = np.array(training_labels)\n",
    "val_labels_final = np.array(val_labels)\n",
    "test_labels_final = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GECt1MoZ5-ek",
    "outputId": "31d27f68-ad63-4eb9-ecf8-825e2d734653"
   },
   "outputs": [],
   "source": [
    "#print(val_labels_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sd7uVBbiWW8j"
   },
   "source": [
    "# Embedding based on the corpus\n",
    "\n",
    "We first examine embeddings based on the corpus.  \n",
    "\n",
    "* The embedding will look at the first 1200 words in each statement. Since the maximum length in our dataset is only about 1,000 words, this is not binding.  However, we choose a larger value to accomodate potentially longer statements in the future.\n",
    "\n",
    "* There is no need to truncate statements in the current file, but to accomodate future data we set the tokenizer to truncate words at the end of each statement.\n",
    "\n",
    "* To ensure the embeddings are all the same length, statements padded with zeros to make them all 1500 in length.\n",
    "\n",
    "* We choose a vocab_size for the corpus\n",
    "\n",
    "* The 'OOV' token represents words that occur with low frequency and are not part of the vocabulary.\n",
    "\n",
    "* An embedding dimension of 16 means that the embedding will be a matrix of 1500 (number of tokens) by 16 (size of the vector for each token).  These vectors can be thought of as the 'features' for each token, and help the model understand the similarity between tokens and statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "1dJsVBZp5wgc"
   },
   "outputs": [],
   "source": [
    "max_length = 1200 #Number of tokens per statement\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "\n",
    "vocab_size = 5000 #choose 5000 words to constitute vocabulary\n",
    "oov_tok = '<OOV>' #indicate out of vocabularly words\n",
    "\n",
    "embedding_dim = 16 #number of features per word in vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXJ2YPOBvh2-"
   },
   "source": [
    "We next tokenize the text and develop the vocabulary, which given by word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "wHFQvZHq4-J0"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lahsZxxJ6jVt",
    "outputId": "b4059bc4-3e10-42aa-81fc-8e083e504d7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 855, 1718, 1155, 329, 247, 179, 182, 828]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the indexes for select words from the word index\n",
    "test_list=['<OOV>','inflationary','war','macroeconomic','euro','debt','current','voting','projections']\n",
    "[word_index[i] for i in test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XTtVODLZ8Y_Z",
    "outputId": "4c7d529d-3fcd-4d1e-82a8-2ba500f31dac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1923"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wK6R12s_-gD5"
   },
   "source": [
    "Assure that the arrays fed into the neural network are all the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "y9PFBhRj6nbQ"
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded = pad_sequences(sequences, maxlen=max_length, truncating=trunc_type)\n",
    "\n",
    "val_sequences = tokenizer.texts_to_sequences(val_sentences)\n",
    "val_padded = pad_sequences(val_sequences, maxlen=max_length)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyORPwqpvBpD"
   },
   "source": [
    "Let's take a look at these sequences arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EK-QzS4buLo8",
    "outputId": "9d2a7aa4-7018-4d8b-cfde-e2e14f373b0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(260, 1200) (87, 1200) (87, 1200)\n"
     ]
    }
   ],
   "source": [
    "print(padded.shape, val_padded.shape, test_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nBUweP3Su-X-",
    "outputId": "12955c5e-2488-4293-9dd9-7c79a7888f95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ..., 134, 829,  77],\n",
       "       [  0,   0,   0, ...,  91, 202, 145],\n",
       "       [  0,   0,   0, ..., 120,  54,  24],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  72, 133, 134],\n",
       "       [  0,   0,   0, ..., 134, 829,  77],\n",
       "       [  0,   0,   0, ...,  72, 217,  77]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzYsgfWyJTYc"
   },
   "source": [
    "# Model A\n",
    "\n",
    "This model was demonstrated by Sucky in a blog post.  The 1D Global Average Pooling layer simply flattens the embedding layer to be a vector.  (We found that the model did much worse without this layer). Each element of the vector is connected to a 6-node dense layer.  The relu was chosen as an activation function due to its ability to mitigate the vanishing gradient problem.  A linear activation was chosen in the final layer because the target is a continuous variable that can take positive or negative values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "lC5t_QqOJSOr"
   },
   "outputs": [],
   "source": [
    "\n",
    "modela = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "qzhigJyKJSZh"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "modela.compile(loss='binary_crossentropy', \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ok5oiBKoJSco",
    "outputId": "61fefbad-020f-40f5-90c5-ef4b730122a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1200, 16)          80000     \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 16)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 102       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,109\n",
      "Trainable params: 80,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modela.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Jr1za8GJSgF",
    "outputId": "8e4aa727-8b23-4308-f579-7a07f755abf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 1s 32ms/step - loss: 0.6873 - precision: 0.0000e+00 - val_loss: 0.6807 - val_precision: 0.0000e+00\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6732 - precision: 0.0000e+00 - val_loss: 0.6616 - val_precision: 0.0000e+00\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6528 - precision: 0.0000e+00 - val_loss: 0.6399 - val_precision: 0.0000e+00\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6300 - precision: 0.0000e+00 - val_loss: 0.6167 - val_precision: 0.0000e+00\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6062 - precision: 0.0000e+00 - val_loss: 0.5924 - val_precision: 0.0000e+00\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5815 - precision: 0.0000e+00 - val_loss: 0.5675 - val_precision: 0.0000e+00\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5551 - precision: 0.0000e+00 - val_loss: 0.5414 - val_precision: 0.0000e+00\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5285 - precision: 0.0000e+00 - val_loss: 0.5151 - val_precision: 0.0000e+00\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5016 - precision: 0.0000e+00 - val_loss: 0.4890 - val_precision: 0.0000e+00\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4754 - precision: 0.0000e+00 - val_loss: 0.4645 - val_precision: 0.0000e+00\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4503 - precision: 0.0000e+00 - val_loss: 0.4388 - val_precision: 0.0000e+00\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4244 - precision: 0.0000e+00 - val_loss: 0.4157 - val_precision: 0.0000e+00\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4009 - precision: 0.0000e+00 - val_loss: 0.3950 - val_precision: 0.0000e+00\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3796 - precision: 0.0000e+00 - val_loss: 0.3756 - val_precision: 0.0000e+00\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3607 - precision: 0.0000e+00 - val_loss: 0.3597 - val_precision: 0.0000e+00\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3440 - precision: 0.0000e+00 - val_loss: 0.3457 - val_precision: 0.0000e+00\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3303 - precision: 0.0000e+00 - val_loss: 0.3342 - val_precision: 0.0000e+00\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3188 - precision: 0.0000e+00 - val_loss: 0.3254 - val_precision: 0.0000e+00\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3101 - precision: 0.0000e+00 - val_loss: 0.3190 - val_precision: 0.0000e+00\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3042 - precision: 0.0000e+00 - val_loss: 0.3150 - val_precision: 0.0000e+00\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2991 - precision: 0.0000e+00 - val_loss: 0.3121 - val_precision: 0.0000e+00\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2960 - precision: 0.0000e+00 - val_loss: 0.3099 - val_precision: 0.0000e+00\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2935 - precision: 0.0000e+00 - val_loss: 0.3085 - val_precision: 0.0000e+00\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2917 - precision: 0.0000e+00 - val_loss: 0.3078 - val_precision: 0.0000e+00\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2907 - precision: 0.0000e+00 - val_loss: 0.3074 - val_precision: 0.0000e+00\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2901 - precision: 0.0000e+00 - val_loss: 0.3071 - val_precision: 0.0000e+00\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2893 - precision: 0.0000e+00 - val_loss: 0.3066 - val_precision: 0.0000e+00\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2891 - precision: 0.0000e+00 - val_loss: 0.3061 - val_precision: 0.0000e+00\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2877 - precision: 0.0000e+00 - val_loss: 0.3059 - val_precision: 0.0000e+00\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2872 - precision: 0.0000e+00 - val_loss: 0.3058 - val_precision: 0.0000e+00\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2866 - precision: 0.0000e+00 - val_loss: 0.3056 - val_precision: 0.0000e+00\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2863 - precision: 0.0000e+00 - val_loss: 0.3053 - val_precision: 0.0000e+00\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2858 - precision: 0.0000e+00 - val_loss: 0.3050 - val_precision: 0.0000e+00\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2853 - precision: 0.0000e+00 - val_loss: 0.3049 - val_precision: 0.0000e+00\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2849 - precision: 0.0000e+00 - val_loss: 0.3048 - val_precision: 0.0000e+00\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2847 - precision: 0.0000e+00 - val_loss: 0.3046 - val_precision: 0.0000e+00\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2842 - precision: 0.0000e+00 - val_loss: 0.3043 - val_precision: 0.0000e+00\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2840 - precision: 0.0000e+00 - val_loss: 0.3040 - val_precision: 0.0000e+00\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2835 - precision: 0.0000e+00 - val_loss: 0.3037 - val_precision: 0.0000e+00\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2833 - precision: 0.0000e+00 - val_loss: 0.3034 - val_precision: 0.0000e+00\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2829 - precision: 0.0000e+00 - val_loss: 0.3032 - val_precision: 0.0000e+00\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2827 - precision: 0.0000e+00 - val_loss: 0.3030 - val_precision: 0.0000e+00\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2823 - precision: 0.0000e+00 - val_loss: 0.3028 - val_precision: 0.0000e+00\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2821 - precision: 0.0000e+00 - val_loss: 0.3027 - val_precision: 0.0000e+00\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2817 - precision: 0.0000e+00 - val_loss: 0.3024 - val_precision: 0.0000e+00\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2815 - precision: 0.0000e+00 - val_loss: 0.3023 - val_precision: 0.0000e+00\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2810 - precision: 0.0000e+00 - val_loss: 0.3022 - val_precision: 0.0000e+00\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2807 - precision: 0.0000e+00 - val_loss: 0.3022 - val_precision: 0.0000e+00\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2806 - precision: 0.0000e+00 - val_loss: 0.3023 - val_precision: 0.0000e+00\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2804 - precision: 0.0000e+00 - val_loss: 0.3023 - val_precision: 0.0000e+00\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2803 - precision: 0.0000e+00 - val_loss: 0.3023 - val_precision: 0.0000e+00\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2799 - precision: 0.0000e+00 - val_loss: 0.3021 - val_precision: 0.0000e+00\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2796 - precision: 0.0000e+00 - val_loss: 0.3018 - val_precision: 0.0000e+00\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2791 - precision: 0.0000e+00 - val_loss: 0.3013 - val_precision: 0.0000e+00\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2787 - precision: 0.0000e+00 - val_loss: 0.3011 - val_precision: 0.0000e+00\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2785 - precision: 0.0000e+00 - val_loss: 0.3009 - val_precision: 0.0000e+00\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2785 - precision: 0.0000e+00 - val_loss: 0.3003 - val_precision: 0.0000e+00\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2777 - precision: 0.0000e+00 - val_loss: 0.3001 - val_precision: 0.0000e+00\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2773 - precision: 0.0000e+00 - val_loss: 0.3000 - val_precision: 0.0000e+00\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2770 - precision: 0.0000e+00 - val_loss: 0.2999 - val_precision: 0.0000e+00\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2768 - precision: 0.0000e+00 - val_loss: 0.2998 - val_precision: 0.0000e+00\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2765 - precision: 0.0000e+00 - val_loss: 0.2994 - val_precision: 0.0000e+00\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2761 - precision: 0.0000e+00 - val_loss: 0.2992 - val_precision: 0.0000e+00\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2756 - precision: 0.0000e+00 - val_loss: 0.2989 - val_precision: 0.0000e+00\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2754 - precision: 0.0000e+00 - val_loss: 0.2987 - val_precision: 0.0000e+00\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2751 - precision: 0.0000e+00 - val_loss: 0.2985 - val_precision: 0.0000e+00\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2750 - precision: 0.0000e+00 - val_loss: 0.2982 - val_precision: 0.0000e+00\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2744 - precision: 0.0000e+00 - val_loss: 0.2979 - val_precision: 0.0000e+00\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2742 - precision: 0.0000e+00 - val_loss: 0.2978 - val_precision: 0.0000e+00\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2739 - precision: 0.0000e+00 - val_loss: 0.2976 - val_precision: 0.0000e+00\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2735 - precision: 0.0000e+00 - val_loss: 0.2974 - val_precision: 0.0000e+00\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2731 - precision: 0.0000e+00 - val_loss: 0.2973 - val_precision: 0.0000e+00\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2729 - precision: 0.0000e+00 - val_loss: 0.2972 - val_precision: 0.0000e+00\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2726 - precision: 0.0000e+00 - val_loss: 0.2972 - val_precision: 0.0000e+00\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2724 - precision: 0.0000e+00 - val_loss: 0.2972 - val_precision: 0.0000e+00\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2723 - precision: 0.0000e+00 - val_loss: 0.2968 - val_precision: 0.0000e+00\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2720 - precision: 0.0000e+00 - val_loss: 0.2965 - val_precision: 0.0000e+00\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2715 - precision: 0.0000e+00 - val_loss: 0.2964 - val_precision: 0.0000e+00\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2713 - precision: 0.0000e+00 - val_loss: 0.2963 - val_precision: 0.0000e+00\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2710 - precision: 0.0000e+00 - val_loss: 0.2961 - val_precision: 0.0000e+00\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2707 - precision: 0.0000e+00 - val_loss: 0.2959 - val_precision: 0.0000e+00\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2702 - precision: 0.0000e+00 - val_loss: 0.2957 - val_precision: 0.0000e+00\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2703 - precision: 0.0000e+00 - val_loss: 0.2955 - val_precision: 0.0000e+00\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2701 - precision: 0.0000e+00 - val_loss: 0.2955 - val_precision: 0.0000e+00\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2702 - precision: 0.0000e+00 - val_loss: 0.2957 - val_precision: 0.0000e+00\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2700 - precision: 0.0000e+00 - val_loss: 0.2954 - val_precision: 0.0000e+00\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2694 - precision: 0.0000e+00 - val_loss: 0.2951 - val_precision: 0.0000e+00\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2691 - precision: 0.0000e+00 - val_loss: 0.2949 - val_precision: 0.0000e+00\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2688 - precision: 0.0000e+00 - val_loss: 0.2948 - val_precision: 0.0000e+00\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2686 - precision: 0.0000e+00 - val_loss: 0.2948 - val_precision: 0.0000e+00\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2684 - precision: 0.0000e+00 - val_loss: 0.2947 - val_precision: 0.0000e+00\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2681 - precision: 0.0000e+00 - val_loss: 0.2947 - val_precision: 0.0000e+00\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2681 - precision: 0.0000e+00 - val_loss: 0.2946 - val_precision: 0.0000e+00\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2679 - precision: 0.0000e+00 - val_loss: 0.2945 - val_precision: 0.0000e+00\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2674 - precision: 0.0000e+00 - val_loss: 0.2940 - val_precision: 0.0000e+00\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2666 - precision: 0.0000e+00 - val_loss: 0.2936 - val_precision: 0.0000e+00\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2664 - precision: 0.0000e+00 - val_loss: 0.2935 - val_precision: 0.0000e+00\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2660 - precision: 0.0000e+00 - val_loss: 0.2933 - val_precision: 0.0000e+00\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2657 - precision: 0.0000e+00 - val_loss: 0.2931 - val_precision: 0.0000e+00\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2653 - precision: 0.0000e+00 - val_loss: 0.2930 - val_precision: 0.0000e+00\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2649 - precision: 0.0000e+00 - val_loss: 0.2929 - val_precision: 0.0000e+00\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2646 - precision: 0.0000e+00 - val_loss: 0.2928 - val_precision: 0.0000e+00\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2647 - precision: 0.0000e+00 - val_loss: 0.2928 - val_precision: 0.0000e+00\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2643 - precision: 0.0000e+00 - val_loss: 0.2928 - val_precision: 0.0000e+00\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2643 - precision: 0.0000e+00 - val_loss: 0.2928 - val_precision: 0.0000e+00\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2639 - precision: 0.0000e+00 - val_loss: 0.2926 - val_precision: 0.0000e+00\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2639 - precision: 0.0000e+00 - val_loss: 0.2922 - val_precision: 0.0000e+00\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2632 - precision: 0.0000e+00 - val_loss: 0.2921 - val_precision: 0.0000e+00\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2630 - precision: 0.0000e+00 - val_loss: 0.2920 - val_precision: 0.0000e+00\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2627 - precision: 0.0000e+00 - val_loss: 0.2919 - val_precision: 0.0000e+00\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2624 - precision: 0.0000e+00 - val_loss: 0.2918 - val_precision: 0.0000e+00\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2623 - precision: 0.0000e+00 - val_loss: 0.2918 - val_precision: 0.0000e+00\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2619 - precision: 0.0000e+00 - val_loss: 0.2914 - val_precision: 0.0000e+00\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2613 - precision: 0.0000e+00 - val_loss: 0.2911 - val_precision: 0.0000e+00\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2612 - precision: 0.0000e+00 - val_loss: 0.2911 - val_precision: 0.0000e+00\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2610 - precision: 0.0000e+00 - val_loss: 0.2910 - val_precision: 0.0000e+00\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2608 - precision: 0.0000e+00 - val_loss: 0.2908 - val_precision: 0.0000e+00\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2604 - precision: 0.0000e+00 - val_loss: 0.2906 - val_precision: 0.0000e+00\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2600 - precision: 0.0000e+00 - val_loss: 0.2905 - val_precision: 0.0000e+00\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2598 - precision: 0.0000e+00 - val_loss: 0.2903 - val_precision: 0.0000e+00\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2595 - precision: 0.0000e+00 - val_loss: 0.2902 - val_precision: 0.0000e+00\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2592 - precision: 0.0000e+00 - val_loss: 0.2901 - val_precision: 0.0000e+00\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2589 - precision: 0.0000e+00 - val_loss: 0.2900 - val_precision: 0.0000e+00\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2585 - precision: 0.0000e+00 - val_loss: 0.2898 - val_precision: 0.0000e+00\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2582 - precision: 0.0000e+00 - val_loss: 0.2897 - val_precision: 0.0000e+00\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2581 - precision: 0.0000e+00 - val_loss: 0.2895 - val_precision: 0.0000e+00\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2578 - precision: 0.0000e+00 - val_loss: 0.2894 - val_precision: 0.0000e+00\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2576 - precision: 0.0000e+00 - val_loss: 0.2893 - val_precision: 0.0000e+00\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2570 - precision: 0.0000e+00 - val_loss: 0.2891 - val_precision: 0.0000e+00\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2568 - precision: 0.0000e+00 - val_loss: 0.2891 - val_precision: 0.0000e+00\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2565 - precision: 0.0000e+00 - val_loss: 0.2889 - val_precision: 0.0000e+00\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2561 - precision: 0.0000e+00 - val_loss: 0.2887 - val_precision: 0.0000e+00\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2558 - precision: 0.0000e+00 - val_loss: 0.2885 - val_precision: 0.0000e+00\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2557 - precision: 0.0000e+00 - val_loss: 0.2885 - val_precision: 0.0000e+00\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2553 - precision: 0.0000e+00 - val_loss: 0.2885 - val_precision: 0.0000e+00\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2552 - precision: 0.0000e+00 - val_loss: 0.2885 - val_precision: 0.0000e+00\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2549 - precision: 0.0000e+00 - val_loss: 0.2884 - val_precision: 0.0000e+00\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2547 - precision: 0.0000e+00 - val_loss: 0.2879 - val_precision: 0.0000e+00\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2540 - precision: 0.0000e+00 - val_loss: 0.2877 - val_precision: 0.0000e+00\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2536 - precision: 0.0000e+00 - val_loss: 0.2876 - val_precision: 0.0000e+00\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2533 - precision: 0.0000e+00 - val_loss: 0.2875 - val_precision: 0.0000e+00\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2531 - precision: 0.0000e+00 - val_loss: 0.2875 - val_precision: 0.0000e+00\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2529 - precision: 0.0000e+00 - val_loss: 0.2872 - val_precision: 0.0000e+00\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2524 - precision: 0.0000e+00 - val_loss: 0.2870 - val_precision: 0.0000e+00\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2520 - precision: 0.0000e+00 - val_loss: 0.2869 - val_precision: 0.0000e+00\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2516 - precision: 0.0000e+00 - val_loss: 0.2869 - val_precision: 0.0000e+00\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2519 - precision: 0.0000e+00 - val_loss: 0.2869 - val_precision: 0.0000e+00\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2513 - precision: 0.0000e+00 - val_loss: 0.2866 - val_precision: 0.0000e+00\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2510 - precision: 0.0000e+00 - val_loss: 0.2865 - val_precision: 0.0000e+00\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2505 - precision: 0.0000e+00 - val_loss: 0.2863 - val_precision: 0.0000e+00\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2502 - precision: 0.0000e+00 - val_loss: 0.2862 - val_precision: 0.0000e+00\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2500 - precision: 0.0000e+00 - val_loss: 0.2862 - val_precision: 0.0000e+00\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2498 - precision: 0.0000e+00 - val_loss: 0.2862 - val_precision: 0.0000e+00\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2495 - precision: 0.0000e+00 - val_loss: 0.2861 - val_precision: 0.0000e+00\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2492 - precision: 0.0000e+00 - val_loss: 0.2859 - val_precision: 0.0000e+00\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2488 - precision: 0.0000e+00 - val_loss: 0.2858 - val_precision: 0.0000e+00\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2488 - precision: 0.0000e+00 - val_loss: 0.2858 - val_precision: 0.0000e+00\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2484 - precision: 0.0000e+00 - val_loss: 0.2852 - val_precision: 0.0000e+00\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2476 - precision: 0.0000e+00 - val_loss: 0.2850 - val_precision: 0.0000e+00\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2472 - precision: 0.0000e+00 - val_loss: 0.2850 - val_precision: 0.0000e+00\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2470 - precision: 0.0000e+00 - val_loss: 0.2848 - val_precision: 0.0000e+00\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2466 - precision: 0.0000e+00 - val_loss: 0.2848 - val_precision: 0.0000e+00\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2463 - precision: 0.0000e+00 - val_loss: 0.2847 - val_precision: 0.0000e+00\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2460 - precision: 0.0000e+00 - val_loss: 0.2846 - val_precision: 0.0000e+00\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2458 - precision: 0.0000e+00 - val_loss: 0.2845 - val_precision: 0.0000e+00\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2454 - precision: 0.0000e+00 - val_loss: 0.2844 - val_precision: 0.0000e+00\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2450 - precision: 0.0000e+00 - val_loss: 0.2843 - val_precision: 0.0000e+00\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2455 - precision: 0.0000e+00 - val_loss: 0.2845 - val_precision: 0.0000e+00\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2449 - precision: 0.0000e+00 - val_loss: 0.2841 - val_precision: 0.0000e+00\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2440 - precision: 0.0000e+00 - val_loss: 0.2839 - val_precision: 0.0000e+00\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2436 - precision: 0.0000e+00 - val_loss: 0.2838 - val_precision: 0.0000e+00\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2434 - precision: 0.0000e+00 - val_loss: 0.2835 - val_precision: 0.0000e+00\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2433 - precision: 0.0000e+00 - val_loss: 0.2831 - val_precision: 0.0000e+00\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2423 - precision: 0.0000e+00 - val_loss: 0.2829 - val_precision: 0.0000e+00\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2417 - precision: 0.0000e+00 - val_loss: 0.2828 - val_precision: 0.0000e+00\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2413 - precision: 0.0000e+00 - val_loss: 0.2827 - val_precision: 0.0000e+00\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2411 - precision: 0.0000e+00 - val_loss: 0.2828 - val_precision: 0.0000e+00\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2407 - precision: 0.0000e+00 - val_loss: 0.2825 - val_precision: 0.0000e+00\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2403 - precision: 0.0000e+00 - val_loss: 0.2823 - val_precision: 0.0000e+00\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2396 - precision: 0.0000e+00 - val_loss: 0.2821 - val_precision: 0.0000e+00\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2392 - precision: 0.0000e+00 - val_loss: 0.2819 - val_precision: 0.0000e+00\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2392 - precision: 0.0000e+00 - val_loss: 0.2819 - val_precision: 0.0000e+00\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2387 - precision: 0.0000e+00 - val_loss: 0.2818 - val_precision: 0.0000e+00\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2384 - precision: 0.0000e+00 - val_loss: 0.2816 - val_precision: 0.0000e+00\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2382 - precision: 0.0000e+00 - val_loss: 0.2816 - val_precision: 0.0000e+00\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2377 - precision: 0.0000e+00 - val_loss: 0.2815 - val_precision: 0.0000e+00\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2373 - precision: 0.0000e+00 - val_loss: 0.2812 - val_precision: 0.0000e+00\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2367 - precision: 0.0000e+00 - val_loss: 0.2810 - val_precision: 0.0000e+00\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2363 - precision: 0.0000e+00 - val_loss: 0.2810 - val_precision: 0.0000e+00\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2359 - precision: 0.0000e+00 - val_loss: 0.2808 - val_precision: 0.0000e+00\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2351 - precision: 0.0000e+00 - val_loss: 0.2804 - val_precision: 0.0000e+00\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2342 - precision: 0.0000e+00 - val_loss: 0.2802 - val_precision: 0.0000e+00\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2337 - precision: 0.0000e+00 - val_loss: 0.2802 - val_precision: 0.0000e+00\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2338 - precision: 0.0000e+00 - val_loss: 0.2801 - val_precision: 0.0000e+00\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2332 - precision: 0.0000e+00 - val_loss: 0.2798 - val_precision: 0.0000e+00\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2329 - precision: 0.0000e+00 - val_loss: 0.2794 - val_precision: 0.0000e+00\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2325 - precision: 0.0000e+00 - val_loss: 0.2794 - val_precision: 0.0000e+00\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2316 - precision: 0.0000e+00 - val_loss: 0.2792 - val_precision: 0.0000e+00\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2312 - precision: 0.0000e+00 - val_loss: 0.2790 - val_precision: 0.0000e+00\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2308 - precision: 0.0000e+00 - val_loss: 0.2788 - val_precision: 0.0000e+00\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2306 - precision: 0.0000e+00 - val_loss: 0.2787 - val_precision: 0.0000e+00\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2299 - precision: 0.0000e+00 - val_loss: 0.2788 - val_precision: 0.0000e+00\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2294 - precision: 0.0000e+00 - val_loss: 0.2787 - val_precision: 0.0000e+00\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2287 - precision: 0.0000e+00 - val_loss: 0.2788 - val_precision: 0.0000e+00\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2284 - precision: 0.0000e+00 - val_loss: 0.2785 - val_precision: 0.0000e+00\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2275 - precision: 0.0000e+00 - val_loss: 0.2779 - val_precision: 0.0000e+00\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2272 - precision: 0.0000e+00 - val_loss: 0.2775 - val_precision: 0.0000e+00\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2264 - precision: 0.0000e+00 - val_loss: 0.2774 - val_precision: 0.0000e+00\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2260 - precision: 0.0000e+00 - val_loss: 0.2772 - val_precision: 0.0000e+00\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2255 - precision: 0.0000e+00 - val_loss: 0.2772 - val_precision: 0.0000e+00\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2252 - precision: 0.0000e+00 - val_loss: 0.2771 - val_precision: 0.0000e+00\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2246 - precision: 0.0000e+00 - val_loss: 0.2769 - val_precision: 0.0000e+00\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2241 - precision: 0.0000e+00 - val_loss: 0.2764 - val_precision: 0.0000e+00\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2237 - precision: 0.0000e+00 - val_loss: 0.2769 - val_precision: 0.0000e+00\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2227 - precision: 0.0000e+00 - val_loss: 0.2766 - val_precision: 0.0000e+00\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2222 - precision: 0.0000e+00 - val_loss: 0.2760 - val_precision: 0.0000e+00\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2215 - precision: 0.0000e+00 - val_loss: 0.2760 - val_precision: 0.0000e+00\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2208 - precision: 0.0000e+00 - val_loss: 0.2756 - val_precision: 0.0000e+00\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2202 - precision: 0.0000e+00 - val_loss: 0.2754 - val_precision: 0.0000e+00\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2202 - precision: 0.0000e+00 - val_loss: 0.2752 - val_precision: 0.0000e+00\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2193 - precision: 0.0000e+00 - val_loss: 0.2751 - val_precision: 0.0000e+00\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2188 - precision: 0.0000e+00 - val_loss: 0.2750 - val_precision: 0.0000e+00\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2184 - precision: 0.0000e+00 - val_loss: 0.2749 - val_precision: 0.0000e+00\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2179 - precision: 0.0000e+00 - val_loss: 0.2748 - val_precision: 0.0000e+00\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2176 - precision: 0.0000e+00 - val_loss: 0.2748 - val_precision: 0.0000e+00\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2175 - precision: 0.0000e+00 - val_loss: 0.2748 - val_precision: 0.0000e+00\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2165 - precision: 0.0000e+00 - val_loss: 0.2745 - val_precision: 0.0000e+00\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2155 - precision: 0.0000e+00 - val_loss: 0.2740 - val_precision: 0.0000e+00\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2150 - precision: 0.0000e+00 - val_loss: 0.2741 - val_precision: 0.0000e+00\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2142 - precision: 0.0000e+00 - val_loss: 0.2740 - val_precision: 0.0000e+00\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2132 - precision: 0.0000e+00 - val_loss: 0.2735 - val_precision: 0.0000e+00\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2124 - precision: 0.0000e+00 - val_loss: 0.2732 - val_precision: 0.0000e+00\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2120 - precision: 1.0000 - val_loss: 0.2731 - val_precision: 0.0000e+00\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2113 - precision: 1.0000 - val_loss: 0.2729 - val_precision: 0.0000e+00\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2110 - precision: 1.0000 - val_loss: 0.2730 - val_precision: 0.0000e+00\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2102 - precision: 1.0000 - val_loss: 0.2728 - val_precision: 0.0000e+00\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2093 - precision: 1.0000 - val_loss: 0.2725 - val_precision: 0.0000e+00\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2087 - precision: 1.0000 - val_loss: 0.2724 - val_precision: 0.0000e+00\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2080 - precision: 1.0000 - val_loss: 0.2724 - val_precision: 0.0000e+00\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2088 - precision: 1.0000 - val_loss: 0.2727 - val_precision: 0.0000e+00\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2071 - precision: 1.0000 - val_loss: 0.2720 - val_precision: 0.0000e+00\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2060 - precision: 1.0000 - val_loss: 0.2726 - val_precision: 0.0000e+00\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2061 - precision: 1.0000 - val_loss: 0.2737 - val_precision: 0.0000e+00\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2061 - precision: 1.0000 - val_loss: 0.2727 - val_precision: 0.0000e+00\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2048 - precision: 1.0000 - val_loss: 0.2720 - val_precision: 0.0000e+00\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2036 - precision: 1.0000 - val_loss: 0.2721 - val_precision: 0.0000e+00\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2029 - precision: 1.0000 - val_loss: 0.2718 - val_precision: 0.0000e+00\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2027 - precision: 1.0000 - val_loss: 0.2711 - val_precision: 0.0000e+00\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2011 - precision: 1.0000 - val_loss: 0.2710 - val_precision: 0.0000e+00\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2003 - precision: 1.0000 - val_loss: 0.2710 - val_precision: 0.0000e+00\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2005 - precision: 1.0000 - val_loss: 0.2711 - val_precision: 0.0000e+00\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1995 - precision: 1.0000 - val_loss: 0.2710 - val_precision: 0.0000e+00\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1986 - precision: 1.0000 - val_loss: 0.2708 - val_precision: 0.0000e+00\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1972 - precision: 1.0000 - val_loss: 0.2711 - val_precision: 0.0000e+00\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1974 - precision: 1.0000 - val_loss: 0.2724 - val_precision: 0.0000e+00\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1971 - precision: 1.0000 - val_loss: 0.2714 - val_precision: 0.0000e+00\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1979 - precision: 1.0000 - val_loss: 0.2706 - val_precision: 0.0000e+00\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1954 - precision: 1.0000 - val_loss: 0.2706 - val_precision: 0.0000e+00\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1949 - precision: 1.0000 - val_loss: 0.2707 - val_precision: 0.0000e+00\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1943 - precision: 1.0000 - val_loss: 0.2705 - val_precision: 0.0000e+00\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1937 - precision: 1.0000 - val_loss: 0.2705 - val_precision: 0.0000e+00\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1926 - precision: 1.0000 - val_loss: 0.2707 - val_precision: 0.0000e+00\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1923 - precision: 1.0000 - val_loss: 0.2705 - val_precision: 0.0000e+00\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1914 - precision: 1.0000 - val_loss: 0.2703 - val_precision: 0.0000e+00\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1909 - precision: 1.0000 - val_loss: 0.2703 - val_precision: 0.0000e+00\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1911 - precision: 1.0000 - val_loss: 0.2707 - val_precision: 0.0000e+00\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1904 - precision: 1.0000 - val_loss: 0.2704 - val_precision: 0.0000e+00\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1885 - precision: 1.0000 - val_loss: 0.2703 - val_precision: 0.0000e+00\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1886 - precision: 1.0000 - val_loss: 0.2706 - val_precision: 0.0000e+00\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1881 - precision: 1.0000 - val_loss: 0.2704 - val_precision: 0.0000e+00\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1874 - precision: 1.0000 - val_loss: 0.2703 - val_precision: 0.0000e+00\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1869 - precision: 1.0000 - val_loss: 0.2705 - val_precision: 0.0000e+00\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1867 - precision: 1.0000 - val_loss: 0.2704 - val_precision: 0.0000e+00\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1861 - precision: 1.0000 - val_loss: 0.2704 - val_precision: 0.0000e+00\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1855 - precision: 1.0000 - val_loss: 0.2704 - val_precision: 0.0000e+00\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1848 - precision: 1.0000 - val_loss: 0.2704 - val_precision: 0.0000e+00\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1842 - precision: 1.0000 - val_loss: 0.2704 - val_precision: 0.0000e+00\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1860 - precision: 1.0000 - val_loss: 0.2707 - val_precision: 0.0000e+00\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1831 - precision: 1.0000 - val_loss: 0.2705 - val_precision: 0.0000e+00\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1825 - precision: 1.0000 - val_loss: 0.2706 - val_precision: 0.0000e+00\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1822 - precision: 1.0000 - val_loss: 0.2706 - val_precision: 0.0000e+00\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1816 - precision: 1.0000 - val_loss: 0.2707 - val_precision: 0.0000e+00\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1810 - precision: 1.0000 - val_loss: 0.2708 - val_precision: 0.0000e+00\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1808 - precision: 1.0000 - val_loss: 0.2709 - val_precision: 0.0000e+00\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1803 - precision: 1.0000 - val_loss: 0.2709 - val_precision: 0.0000e+00\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1799 - precision: 1.0000 - val_loss: 0.2710 - val_precision: 0.0000e+00\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1790 - precision: 1.0000 - val_loss: 0.2711 - val_precision: 0.0000e+00\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1788 - precision: 1.0000 - val_loss: 0.2712 - val_precision: 0.0000e+00\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1781 - precision: 1.0000 - val_loss: 0.2714 - val_precision: 0.0000e+00\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1779 - precision: 1.0000 - val_loss: 0.2716 - val_precision: 0.0000e+00\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1772 - precision: 1.0000 - val_loss: 0.2715 - val_precision: 0.0000e+00\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1771 - precision: 1.0000 - val_loss: 0.2716 - val_precision: 0.0000e+00\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1758 - precision: 0.8571 - val_loss: 0.2719 - val_precision: 0.0000e+00\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1757 - precision: 0.8571 - val_loss: 0.2717 - val_precision: 0.0000e+00\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1755 - precision: 0.8571 - val_loss: 0.2719 - val_precision: 0.0000e+00\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1753 - precision: 0.8571 - val_loss: 0.2724 - val_precision: 0.0000e+00\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1736 - precision: 1.0000 - val_loss: 0.2722 - val_precision: 0.0000e+00\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1735 - precision: 1.0000 - val_loss: 0.2728 - val_precision: 0.0000e+00\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1734 - precision: 1.0000 - val_loss: 0.2729 - val_precision: 0.0000e+00\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1728 - precision: 1.0000 - val_loss: 0.2728 - val_precision: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300 #chosen after trial and error\n",
    "history = modela.fit(padded, training_labels_final, \n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(val_padded, val_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "joSWFGt0JSki",
    "outputId": "014c7dba-b00c-4ec3-dfce-5620f2b7c7ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "precision = history.history['precision']\n",
    "val_precision = history.history['val_precision']\n",
    "epochs=range(len(precision))\n",
    "plt.plot(epochs, precision, 'r')\n",
    "plt.plot(epochs, val_precision, 'b')\n",
    "plt.title('Training and validation Precision')\n",
    "plt.ylim((0,1.5))\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k724fI6sK9bi",
    "outputId": "9cc6d7c2-2606-4727-f042-c3c35c788fbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3244 - precision: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32443565130233765, 1.0]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modela.evaluate(test_padded, test_labels_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4PO_JgTJHOT"
   },
   "source": [
    "\n",
    "# Model B experiment with a 1-D convolution layer.  \n",
    "\n",
    "The length of the convolutional window is 3, meaning that the convolutional filter will examine small chunks of 3 elements in the vectorized texts. We specify 16 filters, each filter can identify different features of the text. We chose these hyperparams by trial and error. \n",
    "\n",
    "Overall, the performance of the 1D Convolutional layer is very sensitive to the number of filters and kernels.  The RMSE for Model B is .53 compared to .33 for Model A after 300 epochs (not shown).  Increasing training time to 500 epochs resulted in an RMSE of .51 in the test set, although validation performance improved a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "B3O-MaSi6t42"
   },
   "outputs": [],
   "source": [
    "#This model has a convolutional layer\n",
    "modelb = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Conv1D(16, 3, activation=\"relu\"),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "E7HiYjv668SI"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "modelb.compile(loss='binary_crossentropy', \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2PvHtIjm68Vf",
    "outputId": "1147583e-967e-4eff-bb11-b06262e04272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1200, 16)          80000     \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 1198, 16)          784       \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 16)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 102       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,893\n",
      "Trainable params: 80,893\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AubDKBKQ-QP0",
    "outputId": "5429a036-9748-47d4-8feb-98313d746af1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "9/9 [==============================] - 1s 34ms/step - loss: 0.6827 - precision: 0.0000e+00 - val_loss: 0.6712 - val_precision: 0.0000e+00\n",
      "Epoch 2/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6631 - precision: 0.0000e+00 - val_loss: 0.6503 - val_precision: 0.0000e+00\n",
      "Epoch 3/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6404 - precision: 0.0000e+00 - val_loss: 0.6245 - val_precision: 0.0000e+00\n",
      "Epoch 4/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6115 - precision: 0.0000e+00 - val_loss: 0.5915 - val_precision: 0.0000e+00\n",
      "Epoch 5/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5748 - precision: 0.0000e+00 - val_loss: 0.5502 - val_precision: 0.0000e+00\n",
      "Epoch 6/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5304 - precision: 0.0000e+00 - val_loss: 0.5015 - val_precision: 0.0000e+00\n",
      "Epoch 7/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4761 - precision: 0.0000e+00 - val_loss: 0.4458 - val_precision: 0.0000e+00\n",
      "Epoch 8/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.4180 - precision: 0.0000e+00 - val_loss: 0.3899 - val_precision: 0.0000e+00\n",
      "Epoch 9/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3634 - precision: 0.0000e+00 - val_loss: 0.3464 - val_precision: 0.0000e+00\n",
      "Epoch 10/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3257 - precision: 0.0000e+00 - val_loss: 0.3241 - val_precision: 0.0000e+00\n",
      "Epoch 11/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3064 - precision: 0.0000e+00 - val_loss: 0.3112 - val_precision: 0.0000e+00\n",
      "Epoch 12/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2947 - precision: 0.0000e+00 - val_loss: 0.3086 - val_precision: 0.0000e+00\n",
      "Epoch 13/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2914 - precision: 0.0000e+00 - val_loss: 0.3078 - val_precision: 0.0000e+00\n",
      "Epoch 14/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2897 - precision: 0.0000e+00 - val_loss: 0.3074 - val_precision: 0.0000e+00\n",
      "Epoch 15/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2886 - precision: 0.0000e+00 - val_loss: 0.3067 - val_precision: 0.0000e+00\n",
      "Epoch 16/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2876 - precision: 0.0000e+00 - val_loss: 0.3063 - val_precision: 0.0000e+00\n",
      "Epoch 17/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2870 - precision: 0.0000e+00 - val_loss: 0.3064 - val_precision: 0.0000e+00\n",
      "Epoch 18/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2866 - precision: 0.0000e+00 - val_loss: 0.3064 - val_precision: 0.0000e+00\n",
      "Epoch 19/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2861 - precision: 0.0000e+00 - val_loss: 0.3060 - val_precision: 0.0000e+00\n",
      "Epoch 20/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2844 - precision: 0.0000e+00 - val_loss: 0.3048 - val_precision: 0.0000e+00\n",
      "Epoch 21/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2843 - precision: 0.0000e+00 - val_loss: 0.3040 - val_precision: 0.0000e+00\n",
      "Epoch 22/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2833 - precision: 0.0000e+00 - val_loss: 0.3038 - val_precision: 0.0000e+00\n",
      "Epoch 23/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2828 - precision: 0.0000e+00 - val_loss: 0.3036 - val_precision: 0.0000e+00\n",
      "Epoch 24/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2815 - precision: 0.0000e+00 - val_loss: 0.3024 - val_precision: 0.0000e+00\n",
      "Epoch 25/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2805 - precision: 0.0000e+00 - val_loss: 0.3018 - val_precision: 0.0000e+00\n",
      "Epoch 26/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2813 - precision: 0.0000e+00 - val_loss: 0.3016 - val_precision: 0.0000e+00\n",
      "Epoch 27/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2803 - precision: 0.0000e+00 - val_loss: 0.3008 - val_precision: 0.0000e+00\n",
      "Epoch 28/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2808 - precision: 0.0000e+00 - val_loss: 0.3006 - val_precision: 0.0000e+00\n",
      "Epoch 29/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2784 - precision: 0.0000e+00 - val_loss: 0.3007 - val_precision: 0.0000e+00\n",
      "Epoch 30/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2780 - precision: 0.0000e+00 - val_loss: 0.3007 - val_precision: 0.0000e+00\n",
      "Epoch 31/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2772 - precision: 0.0000e+00 - val_loss: 0.3000 - val_precision: 0.0000e+00\n",
      "Epoch 32/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2768 - precision: 0.0000e+00 - val_loss: 0.2986 - val_precision: 0.0000e+00\n",
      "Epoch 33/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2753 - precision: 0.0000e+00 - val_loss: 0.2981 - val_precision: 0.0000e+00\n",
      "Epoch 34/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2743 - precision: 0.0000e+00 - val_loss: 0.2978 - val_precision: 0.0000e+00\n",
      "Epoch 35/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2737 - precision: 0.0000e+00 - val_loss: 0.2978 - val_precision: 0.0000e+00\n",
      "Epoch 36/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2736 - precision: 0.0000e+00 - val_loss: 0.2974 - val_precision: 0.0000e+00\n",
      "Epoch 37/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2723 - precision: 0.0000e+00 - val_loss: 0.2966 - val_precision: 0.0000e+00\n",
      "Epoch 38/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2719 - precision: 0.0000e+00 - val_loss: 0.2961 - val_precision: 0.0000e+00\n",
      "Epoch 39/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2710 - precision: 0.0000e+00 - val_loss: 0.2956 - val_precision: 0.0000e+00\n",
      "Epoch 40/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2707 - precision: 0.0000e+00 - val_loss: 0.2954 - val_precision: 0.0000e+00\n",
      "Epoch 41/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2700 - precision: 0.0000e+00 - val_loss: 0.2949 - val_precision: 0.0000e+00\n",
      "Epoch 42/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2696 - precision: 0.0000e+00 - val_loss: 0.2946 - val_precision: 0.0000e+00\n",
      "Epoch 43/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2685 - precision: 0.0000e+00 - val_loss: 0.2942 - val_precision: 0.0000e+00\n",
      "Epoch 44/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2679 - precision: 0.0000e+00 - val_loss: 0.2940 - val_precision: 0.0000e+00\n",
      "Epoch 45/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2671 - precision: 0.0000e+00 - val_loss: 0.2935 - val_precision: 0.0000e+00\n",
      "Epoch 46/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2666 - precision: 0.0000e+00 - val_loss: 0.2931 - val_precision: 0.0000e+00\n",
      "Epoch 47/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2654 - precision: 0.0000e+00 - val_loss: 0.2931 - val_precision: 0.0000e+00\n",
      "Epoch 48/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2649 - precision: 0.0000e+00 - val_loss: 0.2932 - val_precision: 0.0000e+00\n",
      "Epoch 49/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2649 - precision: 0.0000e+00 - val_loss: 0.2936 - val_precision: 0.0000e+00\n",
      "Epoch 50/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2645 - precision: 0.0000e+00 - val_loss: 0.2933 - val_precision: 0.0000e+00\n",
      "Epoch 51/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2638 - precision: 0.0000e+00 - val_loss: 0.2926 - val_precision: 0.0000e+00\n",
      "Epoch 52/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2627 - precision: 0.0000e+00 - val_loss: 0.2915 - val_precision: 0.0000e+00\n",
      "Epoch 53/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2615 - precision: 0.0000e+00 - val_loss: 0.2907 - val_precision: 0.0000e+00\n",
      "Epoch 54/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2600 - precision: 0.0000e+00 - val_loss: 0.2900 - val_precision: 0.0000e+00\n",
      "Epoch 55/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2593 - precision: 0.0000e+00 - val_loss: 0.2896 - val_precision: 0.0000e+00\n",
      "Epoch 56/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2587 - precision: 0.0000e+00 - val_loss: 0.2891 - val_precision: 0.0000e+00\n",
      "Epoch 57/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2587 - precision: 0.0000e+00 - val_loss: 0.2888 - val_precision: 0.0000e+00\n",
      "Epoch 58/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2564 - precision: 0.0000e+00 - val_loss: 0.2881 - val_precision: 0.0000e+00\n",
      "Epoch 59/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2551 - precision: 0.0000e+00 - val_loss: 0.2878 - val_precision: 0.0000e+00\n",
      "Epoch 60/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2543 - precision: 0.0000e+00 - val_loss: 0.2875 - val_precision: 0.0000e+00\n",
      "Epoch 61/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2538 - precision: 0.0000e+00 - val_loss: 0.2872 - val_precision: 0.0000e+00\n",
      "Epoch 62/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2526 - precision: 0.0000e+00 - val_loss: 0.2862 - val_precision: 0.0000e+00\n",
      "Epoch 63/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2509 - precision: 0.0000e+00 - val_loss: 0.2857 - val_precision: 0.0000e+00\n",
      "Epoch 64/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2496 - precision: 0.0000e+00 - val_loss: 0.2854 - val_precision: 0.0000e+00\n",
      "Epoch 65/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2486 - precision: 0.0000e+00 - val_loss: 0.2848 - val_precision: 0.0000e+00\n",
      "Epoch 66/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2475 - precision: 0.0000e+00 - val_loss: 0.2842 - val_precision: 0.0000e+00\n",
      "Epoch 67/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2468 - precision: 0.0000e+00 - val_loss: 0.2839 - val_precision: 0.0000e+00\n",
      "Epoch 68/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2449 - precision: 0.0000e+00 - val_loss: 0.2837 - val_precision: 0.0000e+00\n",
      "Epoch 69/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2438 - precision: 0.0000e+00 - val_loss: 0.2826 - val_precision: 0.0000e+00\n",
      "Epoch 70/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2418 - precision: 0.0000e+00 - val_loss: 0.2819 - val_precision: 0.0000e+00\n",
      "Epoch 71/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2398 - precision: 0.0000e+00 - val_loss: 0.2808 - val_precision: 0.0000e+00\n",
      "Epoch 72/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2378 - precision: 0.0000e+00 - val_loss: 0.2804 - val_precision: 0.0000e+00\n",
      "Epoch 73/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2372 - precision: 0.0000e+00 - val_loss: 0.2803 - val_precision: 0.0000e+00\n",
      "Epoch 74/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2362 - precision: 0.0000e+00 - val_loss: 0.2796 - val_precision: 0.0000e+00\n",
      "Epoch 75/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2342 - precision: 0.0000e+00 - val_loss: 0.2787 - val_precision: 0.0000e+00\n",
      "Epoch 76/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2326 - precision: 0.0000e+00 - val_loss: 0.2773 - val_precision: 0.0000e+00\n",
      "Epoch 77/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2317 - precision: 0.0000e+00 - val_loss: 0.2780 - val_precision: 0.0000e+00\n",
      "Epoch 78/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2292 - precision: 0.0000e+00 - val_loss: 0.2761 - val_precision: 0.0000e+00\n",
      "Epoch 79/500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2270 - precision: 0.0000e+00 - val_loss: 0.2757 - val_precision: 0.0000e+00\n",
      "Epoch 80/500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2253 - precision: 0.0000e+00 - val_loss: 0.2751 - val_precision: 0.0000e+00\n",
      "Epoch 81/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2239 - precision: 0.0000e+00 - val_loss: 0.2747 - val_precision: 0.0000e+00\n",
      "Epoch 82/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2225 - precision: 0.0000e+00 - val_loss: 0.2763 - val_precision: 0.0000e+00\n",
      "Epoch 83/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2225 - precision: 0.0000e+00 - val_loss: 0.2746 - val_precision: 0.0000e+00\n",
      "Epoch 84/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2206 - precision: 0.0000e+00 - val_loss: 0.2750 - val_precision: 0.0000e+00\n",
      "Epoch 85/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2214 - precision: 0.0000e+00 - val_loss: 0.2778 - val_precision: 0.0000e+00\n",
      "Epoch 86/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2189 - precision: 0.0000e+00 - val_loss: 0.2728 - val_precision: 0.0000e+00\n",
      "Epoch 87/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2143 - precision: 0.0000e+00 - val_loss: 0.2718 - val_precision: 0.0000e+00\n",
      "Epoch 88/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2129 - precision: 0.0000e+00 - val_loss: 0.2713 - val_precision: 0.0000e+00\n",
      "Epoch 89/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2113 - precision: 0.0000e+00 - val_loss: 0.2707 - val_precision: 0.0000e+00\n",
      "Epoch 90/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2098 - precision: 0.0000e+00 - val_loss: 0.2711 - val_precision: 0.0000e+00\n",
      "Epoch 91/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2094 - precision: 0.0000e+00 - val_loss: 0.2713 - val_precision: 0.0000e+00\n",
      "Epoch 92/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2082 - precision: 0.0000e+00 - val_loss: 0.2713 - val_precision: 0.0000e+00\n",
      "Epoch 93/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2067 - precision: 0.0000e+00 - val_loss: 0.2693 - val_precision: 0.0000e+00\n",
      "Epoch 94/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2038 - precision: 1.0000 - val_loss: 0.2688 - val_precision: 0.0000e+00\n",
      "Epoch 95/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2013 - precision: 1.0000 - val_loss: 0.2680 - val_precision: 0.0000e+00\n",
      "Epoch 96/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2003 - precision: 1.0000 - val_loss: 0.2684 - val_precision: 0.0000e+00\n",
      "Epoch 97/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1987 - precision: 1.0000 - val_loss: 0.2667 - val_precision: 0.0000e+00\n",
      "Epoch 98/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1959 - precision: 1.0000 - val_loss: 0.2669 - val_precision: 0.0000e+00\n",
      "Epoch 99/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1956 - precision: 1.0000 - val_loss: 0.2665 - val_precision: 0.0000e+00\n",
      "Epoch 100/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1939 - precision: 1.0000 - val_loss: 0.2663 - val_precision: 0.0000e+00\n",
      "Epoch 101/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1923 - precision: 1.0000 - val_loss: 0.2662 - val_precision: 0.0000e+00\n",
      "Epoch 102/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.1909 - precision: 1.0000 - val_loss: 0.2664 - val_precision: 0.0000e+00\n",
      "Epoch 103/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1904 - precision: 1.0000 - val_loss: 0.2660 - val_precision: 0.0000e+00\n",
      "Epoch 104/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.1883 - precision: 1.0000 - val_loss: 0.2657 - val_precision: 0.0000e+00\n",
      "Epoch 105/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1872 - precision: 1.0000 - val_loss: 0.2658 - val_precision: 0.0000e+00\n",
      "Epoch 106/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1859 - precision: 1.0000 - val_loss: 0.2651 - val_precision: 0.0000e+00\n",
      "Epoch 107/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1906 - precision: 1.0000 - val_loss: 0.2669 - val_precision: 0.0000e+00\n",
      "Epoch 108/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1854 - precision: 1.0000 - val_loss: 0.2673 - val_precision: 0.0000e+00\n",
      "Epoch 109/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1848 - precision: 1.0000 - val_loss: 0.2684 - val_precision: 0.0000e+00\n",
      "Epoch 110/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1841 - precision: 1.0000 - val_loss: 0.2653 - val_precision: 0.0000e+00\n",
      "Epoch 111/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1800 - precision: 1.0000 - val_loss: 0.2655 - val_precision: 0.0000e+00\n",
      "Epoch 112/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1790 - precision: 1.0000 - val_loss: 0.2654 - val_precision: 0.0000e+00\n",
      "Epoch 113/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1780 - precision: 1.0000 - val_loss: 0.2660 - val_precision: 0.0000e+00\n",
      "Epoch 114/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1774 - precision: 0.8571 - val_loss: 0.2652 - val_precision: 0.0000e+00\n",
      "Epoch 115/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1753 - precision: 1.0000 - val_loss: 0.2654 - val_precision: 0.0000e+00\n",
      "Epoch 116/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1742 - precision: 1.0000 - val_loss: 0.2655 - val_precision: 0.0000e+00\n",
      "Epoch 117/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1720 - precision: 1.0000 - val_loss: 0.2663 - val_precision: 0.0000e+00\n",
      "Epoch 118/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1708 - precision: 1.0000 - val_loss: 0.2662 - val_precision: 0.0000e+00\n",
      "Epoch 119/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1691 - precision: 0.8750 - val_loss: 0.2658 - val_precision: 0.0000e+00\n",
      "Epoch 120/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1689 - precision: 0.8750 - val_loss: 0.2659 - val_precision: 0.5000\n",
      "Epoch 121/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1691 - precision: 0.8889 - val_loss: 0.2665 - val_precision: 0.5000\n",
      "Epoch 122/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1654 - precision: 0.8889 - val_loss: 0.2667 - val_precision: 0.0000e+00\n",
      "Epoch 123/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1656 - precision: 0.8750 - val_loss: 0.2669 - val_precision: 0.0000e+00\n",
      "Epoch 124/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1640 - precision: 0.8750 - val_loss: 0.2674 - val_precision: 0.0000e+00\n",
      "Epoch 125/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1624 - precision: 0.8889 - val_loss: 0.2676 - val_precision: 0.0000e+00\n",
      "Epoch 126/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1627 - precision: 0.8750 - val_loss: 0.2681 - val_precision: 0.0000e+00\n",
      "Epoch 127/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1628 - precision: 0.8889 - val_loss: 0.2697 - val_precision: 0.5000\n",
      "Epoch 128/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1611 - precision: 0.8889 - val_loss: 0.2689 - val_precision: 0.0000e+00\n",
      "Epoch 129/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1595 - precision: 0.8750 - val_loss: 0.2703 - val_precision: 0.0000e+00\n",
      "Epoch 130/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1573 - precision: 0.8889 - val_loss: 0.2696 - val_precision: 0.5000\n",
      "Epoch 131/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1571 - precision: 0.8889 - val_loss: 0.2699 - val_precision: 0.0000e+00\n",
      "Epoch 132/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1556 - precision: 0.8889 - val_loss: 0.2711 - val_precision: 0.0000e+00\n",
      "Epoch 133/500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1552 - precision: 0.8889 - val_loss: 0.2731 - val_precision: 0.0000e+00\n",
      "Epoch 134/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1540 - precision: 0.8889 - val_loss: 0.2736 - val_precision: 0.0000e+00\n",
      "Epoch 135/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1538 - precision: 1.0000 - val_loss: 0.2763 - val_precision: 0.0000e+00\n",
      "Epoch 136/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1539 - precision: 1.0000 - val_loss: 0.2766 - val_precision: 0.0000e+00\n",
      "Epoch 137/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1523 - precision: 1.0000 - val_loss: 0.2747 - val_precision: 0.0000e+00\n",
      "Epoch 138/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1512 - precision: 0.8889 - val_loss: 0.2731 - val_precision: 0.5000\n",
      "Epoch 139/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1492 - precision: 0.8889 - val_loss: 0.2728 - val_precision: 0.0000e+00\n",
      "Epoch 140/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1479 - precision: 0.8889 - val_loss: 0.2750 - val_precision: 0.0000e+00\n",
      "Epoch 141/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1479 - precision: 0.8889 - val_loss: 0.2755 - val_precision: 0.0000e+00\n",
      "Epoch 142/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1469 - precision: 0.8889 - val_loss: 0.2759 - val_precision: 0.0000e+00\n",
      "Epoch 143/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1449 - precision: 0.9000 - val_loss: 0.2737 - val_precision: 0.5000\n",
      "Epoch 144/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1451 - precision: 0.9091 - val_loss: 0.2744 - val_precision: 0.5000\n",
      "Epoch 145/500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1432 - precision: 0.9000 - val_loss: 0.2763 - val_precision: 0.0000e+00\n",
      "Epoch 146/500\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.1421 - precision: 0.9000 - val_loss: 0.2799 - val_precision: 0.0000e+00\n",
      "Epoch 147/500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1458 - precision: 1.0000 - val_loss: 0.2814 - val_precision: 0.0000e+00\n",
      "Epoch 148/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1412 - precision: 0.9000 - val_loss: 0.2772 - val_precision: 0.5000\n",
      "Epoch 149/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1414 - precision: 0.9091 - val_loss: 0.2780 - val_precision: 0.5000\n",
      "Epoch 150/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1395 - precision: 0.9091 - val_loss: 0.2793 - val_precision: 0.0000e+00\n",
      "Epoch 151/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1392 - precision: 0.9000 - val_loss: 0.2813 - val_precision: 0.0000e+00\n",
      "Epoch 152/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.1385 - precision: 1.0000 - val_loss: 0.2828 - val_precision: 0.0000e+00\n",
      "Epoch 153/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1372 - precision: 1.0000 - val_loss: 0.2830 - val_precision: 0.0000e+00\n",
      "Epoch 154/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1365 - precision: 0.9091 - val_loss: 0.2832 - val_precision: 0.0000e+00\n",
      "Epoch 155/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1361 - precision: 0.9091 - val_loss: 0.2847 - val_precision: 0.0000e+00\n",
      "Epoch 156/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1365 - precision: 1.0000 - val_loss: 0.2893 - val_precision: 0.0000e+00\n",
      "Epoch 157/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1372 - precision: 1.0000 - val_loss: 0.2868 - val_precision: 0.0000e+00\n",
      "Epoch 158/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.1384 - precision: 0.9091 - val_loss: 0.2851 - val_precision: 0.5000\n",
      "Epoch 159/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1341 - precision: 0.9091 - val_loss: 0.2857 - val_precision: 0.5000\n",
      "Epoch 160/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1342 - precision: 0.9091 - val_loss: 0.2906 - val_precision: 0.0000e+00\n",
      "Epoch 161/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1348 - precision: 1.0000 - val_loss: 0.2897 - val_precision: 0.0000e+00\n",
      "Epoch 162/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1320 - precision: 1.0000 - val_loss: 0.2893 - val_precision: 0.0000e+00\n",
      "Epoch 163/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1315 - precision: 0.9091 - val_loss: 0.2892 - val_precision: 0.0000e+00\n",
      "Epoch 164/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1305 - precision: 0.9091 - val_loss: 0.2901 - val_precision: 0.0000e+00\n",
      "Epoch 165/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1303 - precision: 1.0000 - val_loss: 0.2918 - val_precision: 0.0000e+00\n",
      "Epoch 166/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1304 - precision: 0.9091 - val_loss: 0.2924 - val_precision: 0.0000e+00\n",
      "Epoch 167/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1297 - precision: 1.0000 - val_loss: 0.2961 - val_precision: 0.0000e+00\n",
      "Epoch 168/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.1308 - precision: 1.0000 - val_loss: 0.2971 - val_precision: 0.0000e+00\n",
      "Epoch 169/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1296 - precision: 1.0000 - val_loss: 0.2936 - val_precision: 0.5000\n",
      "Epoch 170/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1277 - precision: 0.9091 - val_loss: 0.2943 - val_precision: 0.0000e+00\n",
      "Epoch 171/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1277 - precision: 1.0000 - val_loss: 0.2951 - val_precision: 0.0000e+00\n",
      "Epoch 172/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1271 - precision: 0.9091 - val_loss: 0.2947 - val_precision: 0.5000\n",
      "Epoch 173/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1282 - precision: 0.9091 - val_loss: 0.2940 - val_precision: 0.5000\n",
      "Epoch 174/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1278 - precision: 0.9091 - val_loss: 0.2953 - val_precision: 0.5000\n",
      "Epoch 175/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1264 - precision: 0.9091 - val_loss: 0.2968 - val_precision: 0.5000\n",
      "Epoch 176/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1256 - precision: 1.0000 - val_loss: 0.2986 - val_precision: 0.0000e+00\n",
      "Epoch 177/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1251 - precision: 1.0000 - val_loss: 0.2988 - val_precision: 0.5000\n",
      "Epoch 178/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1253 - precision: 1.0000 - val_loss: 0.3007 - val_precision: 0.0000e+00\n",
      "Epoch 179/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1237 - precision: 1.0000 - val_loss: 0.3021 - val_precision: 0.0000e+00\n",
      "Epoch 180/500\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1233 - precision: 1.0000 - val_loss: 0.3038 - val_precision: 0.0000e+00\n",
      "Epoch 181/500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1231 - precision: 1.0000 - val_loss: 0.3055 - val_precision: 0.0000e+00\n",
      "Epoch 182/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1234 - precision: 1.0000 - val_loss: 0.3073 - val_precision: 0.0000e+00\n",
      "Epoch 183/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1230 - precision: 1.0000 - val_loss: 0.3060 - val_precision: 0.0000e+00\n",
      "Epoch 184/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1228 - precision: 1.0000 - val_loss: 0.3040 - val_precision: 0.5000\n",
      "Epoch 185/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1224 - precision: 1.0000 - val_loss: 0.3057 - val_precision: 0.5000\n",
      "Epoch 186/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1217 - precision: 1.0000 - val_loss: 0.3065 - val_precision: 0.0000e+00\n",
      "Epoch 187/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1211 - precision: 1.0000 - val_loss: 0.3050 - val_precision: 0.5000\n",
      "Epoch 188/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1205 - precision: 1.0000 - val_loss: 0.3056 - val_precision: 0.5000\n",
      "Epoch 189/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1201 - precision: 1.0000 - val_loss: 0.3086 - val_precision: 0.0000e+00\n",
      "Epoch 190/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1200 - precision: 1.0000 - val_loss: 0.3092 - val_precision: 0.0000e+00\n",
      "Epoch 191/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1211 - precision: 0.9231 - val_loss: 0.3058 - val_precision: 0.5000\n",
      "Epoch 192/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1208 - precision: 1.0000 - val_loss: 0.3070 - val_precision: 0.5000\n",
      "Epoch 193/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1198 - precision: 1.0000 - val_loss: 0.3087 - val_precision: 0.5000\n",
      "Epoch 194/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1187 - precision: 1.0000 - val_loss: 0.3094 - val_precision: 0.0000e+00\n",
      "Epoch 195/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1185 - precision: 1.0000 - val_loss: 0.3089 - val_precision: 0.5000\n",
      "Epoch 196/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1186 - precision: 1.0000 - val_loss: 0.3106 - val_precision: 0.5000\n",
      "Epoch 197/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1184 - precision: 1.0000 - val_loss: 0.3082 - val_precision: 0.5000\n",
      "Epoch 198/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1188 - precision: 0.9231 - val_loss: 0.3090 - val_precision: 0.5000\n",
      "Epoch 199/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1179 - precision: 1.0000 - val_loss: 0.3129 - val_precision: 0.0000e+00\n",
      "Epoch 200/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1167 - precision: 1.0000 - val_loss: 0.3149 - val_precision: 0.0000e+00\n",
      "Epoch 201/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1174 - precision: 1.0000 - val_loss: 0.3135 - val_precision: 0.5000\n",
      "Epoch 202/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1163 - precision: 1.0000 - val_loss: 0.3156 - val_precision: 0.5000\n",
      "Epoch 203/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1158 - precision: 1.0000 - val_loss: 0.3166 - val_precision: 0.5000\n",
      "Epoch 204/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1151 - precision: 1.0000 - val_loss: 0.3165 - val_precision: 0.5000\n",
      "Epoch 205/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1149 - precision: 1.0000 - val_loss: 0.3165 - val_precision: 0.5000\n",
      "Epoch 206/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1147 - precision: 1.0000 - val_loss: 0.3182 - val_precision: 0.5000\n",
      "Epoch 207/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1149 - precision: 1.0000 - val_loss: 0.3204 - val_precision: 0.5000\n",
      "Epoch 208/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1145 - precision: 1.0000 - val_loss: 0.3220 - val_precision: 0.5000\n",
      "Epoch 209/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1148 - precision: 1.0000 - val_loss: 0.3198 - val_precision: 0.5000\n",
      "Epoch 210/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1137 - precision: 1.0000 - val_loss: 0.3221 - val_precision: 0.5000\n",
      "Epoch 211/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1138 - precision: 1.0000 - val_loss: 0.3226 - val_precision: 0.5000\n",
      "Epoch 212/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1130 - precision: 1.0000 - val_loss: 0.3218 - val_precision: 0.5000\n",
      "Epoch 213/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1132 - precision: 1.0000 - val_loss: 0.3206 - val_precision: 0.5000\n",
      "Epoch 214/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1127 - precision: 1.0000 - val_loss: 0.3207 - val_precision: 0.5000\n",
      "Epoch 215/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1124 - precision: 1.0000 - val_loss: 0.3227 - val_precision: 0.5000\n",
      "Epoch 216/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1129 - precision: 1.0000 - val_loss: 0.3240 - val_precision: 0.5000\n",
      "Epoch 217/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1114 - precision: 1.0000 - val_loss: 0.3211 - val_precision: 0.5000\n",
      "Epoch 218/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1119 - precision: 1.0000 - val_loss: 0.3216 - val_precision: 0.5000\n",
      "Epoch 219/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1113 - precision: 1.0000 - val_loss: 0.3238 - val_precision: 0.3333\n",
      "Epoch 220/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1113 - precision: 1.0000 - val_loss: 0.3262 - val_precision: 0.5000\n",
      "Epoch 221/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1108 - precision: 1.0000 - val_loss: 0.3255 - val_precision: 0.3333\n",
      "Epoch 222/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1103 - precision: 1.0000 - val_loss: 0.3275 - val_precision: 0.3333\n",
      "Epoch 223/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1101 - precision: 1.0000 - val_loss: 0.3357 - val_precision: 0.0000e+00\n",
      "Epoch 224/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1109 - precision: 1.0000 - val_loss: 0.3363 - val_precision: 0.0000e+00\n",
      "Epoch 225/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1107 - precision: 1.0000 - val_loss: 0.3351 - val_precision: 0.0000e+00\n",
      "Epoch 226/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1104 - precision: 1.0000 - val_loss: 0.3334 - val_precision: 0.0000e+00\n",
      "Epoch 227/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1093 - precision: 1.0000 - val_loss: 0.3311 - val_precision: 0.5000\n",
      "Epoch 228/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1088 - precision: 1.0000 - val_loss: 0.3284 - val_precision: 0.3333\n",
      "Epoch 229/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1087 - precision: 1.0000 - val_loss: 0.3287 - val_precision: 0.5000\n",
      "Epoch 230/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1086 - precision: 1.0000 - val_loss: 0.3304 - val_precision: 0.5000\n",
      "Epoch 231/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1081 - precision: 1.0000 - val_loss: 0.3312 - val_precision: 0.5000\n",
      "Epoch 232/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1077 - precision: 1.0000 - val_loss: 0.3325 - val_precision: 0.3333\n",
      "Epoch 233/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1073 - precision: 1.0000 - val_loss: 0.3334 - val_precision: 0.5000\n",
      "Epoch 234/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1074 - precision: 1.0000 - val_loss: 0.3347 - val_precision: 0.3333\n",
      "Epoch 235/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1075 - precision: 1.0000 - val_loss: 0.3330 - val_precision: 0.5000\n",
      "Epoch 236/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1073 - precision: 1.0000 - val_loss: 0.3333 - val_precision: 0.5000\n",
      "Epoch 237/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1065 - precision: 1.0000 - val_loss: 0.3353 - val_precision: 0.5000\n",
      "Epoch 238/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1059 - precision: 1.0000 - val_loss: 0.3368 - val_precision: 0.3333\n",
      "Epoch 239/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1059 - precision: 1.0000 - val_loss: 0.3436 - val_precision: 0.0000e+00\n",
      "Epoch 240/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1080 - precision: 1.0000 - val_loss: 0.3448 - val_precision: 0.0000e+00\n",
      "Epoch 241/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1060 - precision: 1.0000 - val_loss: 0.3397 - val_precision: 0.3333\n",
      "Epoch 242/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1047 - precision: 1.0000 - val_loss: 0.3357 - val_precision: 0.5000\n",
      "Epoch 243/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1068 - precision: 0.9375 - val_loss: 0.3356 - val_precision: 0.3750\n",
      "Epoch 244/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1074 - precision: 0.8889 - val_loss: 0.3364 - val_precision: 0.5000\n",
      "Epoch 245/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1056 - precision: 1.0000 - val_loss: 0.3373 - val_precision: 0.5000\n",
      "Epoch 246/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1045 - precision: 1.0000 - val_loss: 0.3393 - val_precision: 0.5000\n",
      "Epoch 247/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1034 - precision: 1.0000 - val_loss: 0.3408 - val_precision: 0.5000\n",
      "Epoch 248/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1039 - precision: 1.0000 - val_loss: 0.3426 - val_precision: 0.3333\n",
      "Epoch 249/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1035 - precision: 1.0000 - val_loss: 0.3410 - val_precision: 0.5000\n",
      "Epoch 250/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1030 - precision: 1.0000 - val_loss: 0.3419 - val_precision: 0.5000\n",
      "Epoch 251/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1031 - precision: 1.0000 - val_loss: 0.3420 - val_precision: 0.5000\n",
      "Epoch 252/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1025 - precision: 1.0000 - val_loss: 0.3423 - val_precision: 0.5000\n",
      "Epoch 253/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1021 - precision: 1.0000 - val_loss: 0.3417 - val_precision: 0.5000\n",
      "Epoch 254/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1019 - precision: 1.0000 - val_loss: 0.3400 - val_precision: 0.5000\n",
      "Epoch 255/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1021 - precision: 1.0000 - val_loss: 0.3411 - val_precision: 0.5000\n",
      "Epoch 256/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.1019 - precision: 1.0000 - val_loss: 0.3427 - val_precision: 0.5000\n",
      "Epoch 257/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1022 - precision: 1.0000 - val_loss: 0.3461 - val_precision: 0.5000\n",
      "Epoch 258/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.1014 - precision: 1.0000 - val_loss: 0.3466 - val_precision: 0.5000\n",
      "Epoch 259/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1009 - precision: 1.0000 - val_loss: 0.3450 - val_precision: 0.5000\n",
      "Epoch 260/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1009 - precision: 1.0000 - val_loss: 0.3435 - val_precision: 0.5000\n",
      "Epoch 261/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1005 - precision: 1.0000 - val_loss: 0.3445 - val_precision: 0.5000\n",
      "Epoch 262/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0997 - precision: 1.0000 - val_loss: 0.3406 - val_precision: 0.5000\n",
      "Epoch 263/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1007 - precision: 1.0000 - val_loss: 0.3413 - val_precision: 0.5000\n",
      "Epoch 264/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1001 - precision: 1.0000 - val_loss: 0.3423 - val_precision: 0.5000\n",
      "Epoch 265/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0995 - precision: 1.0000 - val_loss: 0.3437 - val_precision: 0.5000\n",
      "Epoch 266/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0996 - precision: 1.0000 - val_loss: 0.3474 - val_precision: 0.5000\n",
      "Epoch 267/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0994 - precision: 1.0000 - val_loss: 0.3477 - val_precision: 0.5000\n",
      "Epoch 268/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0981 - precision: 1.0000 - val_loss: 0.3431 - val_precision: 0.5000\n",
      "Epoch 269/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0994 - precision: 1.0000 - val_loss: 0.3424 - val_precision: 0.5000\n",
      "Epoch 270/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0991 - precision: 1.0000 - val_loss: 0.3435 - val_precision: 0.5000\n",
      "Epoch 271/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0985 - precision: 1.0000 - val_loss: 0.3450 - val_precision: 0.5000\n",
      "Epoch 272/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0981 - precision: 1.0000 - val_loss: 0.3443 - val_precision: 0.5000\n",
      "Epoch 273/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0980 - precision: 1.0000 - val_loss: 0.3444 - val_precision: 0.5000\n",
      "Epoch 274/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0978 - precision: 1.0000 - val_loss: 0.3459 - val_precision: 0.5000\n",
      "Epoch 275/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0972 - precision: 1.0000 - val_loss: 0.3474 - val_precision: 0.5000\n",
      "Epoch 276/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0981 - precision: 1.0000 - val_loss: 0.3491 - val_precision: 0.5000\n",
      "Epoch 277/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0971 - precision: 1.0000 - val_loss: 0.3483 - val_precision: 0.5000\n",
      "Epoch 278/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0974 - precision: 1.0000 - val_loss: 0.3498 - val_precision: 0.5000\n",
      "Epoch 279/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0972 - precision: 1.0000 - val_loss: 0.3530 - val_precision: 0.5000\n",
      "Epoch 280/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0961 - precision: 1.0000 - val_loss: 0.3484 - val_precision: 0.5000\n",
      "Epoch 281/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0961 - precision: 1.0000 - val_loss: 0.3477 - val_precision: 0.5000\n",
      "Epoch 282/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0958 - precision: 1.0000 - val_loss: 0.3487 - val_precision: 0.5000\n",
      "Epoch 283/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0955 - precision: 1.0000 - val_loss: 0.3495 - val_precision: 0.5000\n",
      "Epoch 284/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0955 - precision: 1.0000 - val_loss: 0.3505 - val_precision: 0.5000\n",
      "Epoch 285/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0953 - precision: 1.0000 - val_loss: 0.3504 - val_precision: 0.5000\n",
      "Epoch 286/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0949 - precision: 1.0000 - val_loss: 0.3504 - val_precision: 0.5000\n",
      "Epoch 287/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0948 - precision: 1.0000 - val_loss: 0.3502 - val_precision: 0.5000\n",
      "Epoch 288/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0944 - precision: 1.0000 - val_loss: 0.3513 - val_precision: 0.5000\n",
      "Epoch 289/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0943 - precision: 1.0000 - val_loss: 0.3516 - val_precision: 0.5000\n",
      "Epoch 290/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0945 - precision: 1.0000 - val_loss: 0.3537 - val_precision: 0.5000\n",
      "Epoch 291/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0942 - precision: 1.0000 - val_loss: 0.3543 - val_precision: 0.5000\n",
      "Epoch 292/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0943 - precision: 1.0000 - val_loss: 0.3524 - val_precision: 0.5000\n",
      "Epoch 293/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0937 - precision: 1.0000 - val_loss: 0.3532 - val_precision: 0.5000\n",
      "Epoch 294/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0936 - precision: 1.0000 - val_loss: 0.3545 - val_precision: 0.5000\n",
      "Epoch 295/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0938 - precision: 1.0000 - val_loss: 0.3535 - val_precision: 0.5000\n",
      "Epoch 296/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0931 - precision: 1.0000 - val_loss: 0.3547 - val_precision: 0.5000\n",
      "Epoch 297/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0925 - precision: 1.0000 - val_loss: 0.3611 - val_precision: 0.5000\n",
      "Epoch 298/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0935 - precision: 1.0000 - val_loss: 0.3641 - val_precision: 0.5000\n",
      "Epoch 299/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0932 - precision: 1.0000 - val_loss: 0.3623 - val_precision: 0.5000\n",
      "Epoch 300/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0927 - precision: 1.0000 - val_loss: 0.3596 - val_precision: 0.5000\n",
      "Epoch 301/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0927 - precision: 1.0000 - val_loss: 0.3577 - val_precision: 0.5000\n",
      "Epoch 302/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0917 - precision: 1.0000 - val_loss: 0.3580 - val_precision: 0.5000\n",
      "Epoch 303/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0916 - precision: 1.0000 - val_loss: 0.3581 - val_precision: 0.5000\n",
      "Epoch 304/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0916 - precision: 1.0000 - val_loss: 0.3570 - val_precision: 0.5000\n",
      "Epoch 305/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0911 - precision: 1.0000 - val_loss: 0.3582 - val_precision: 0.5000\n",
      "Epoch 306/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0908 - precision: 1.0000 - val_loss: 0.3593 - val_precision: 0.5000\n",
      "Epoch 307/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0904 - precision: 1.0000 - val_loss: 0.3615 - val_precision: 0.5000\n",
      "Epoch 308/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0904 - precision: 1.0000 - val_loss: 0.3639 - val_precision: 0.5000\n",
      "Epoch 309/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0907 - precision: 1.0000 - val_loss: 0.3622 - val_precision: 0.5000\n",
      "Epoch 310/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0902 - precision: 1.0000 - val_loss: 0.3641 - val_precision: 0.5000\n",
      "Epoch 311/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0904 - precision: 1.0000 - val_loss: 0.3642 - val_precision: 0.5000\n",
      "Epoch 312/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0903 - precision: 1.0000 - val_loss: 0.3646 - val_precision: 0.5000\n",
      "Epoch 313/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0899 - precision: 1.0000 - val_loss: 0.3621 - val_precision: 0.5000\n",
      "Epoch 314/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0900 - precision: 1.0000 - val_loss: 0.3603 - val_precision: 0.5000\n",
      "Epoch 315/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0908 - precision: 1.0000 - val_loss: 0.3619 - val_precision: 0.5000\n",
      "Epoch 316/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0894 - precision: 1.0000 - val_loss: 0.3636 - val_precision: 0.5000\n",
      "Epoch 317/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0888 - precision: 1.0000 - val_loss: 0.3654 - val_precision: 0.5000\n",
      "Epoch 318/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0890 - precision: 1.0000 - val_loss: 0.3649 - val_precision: 0.5000\n",
      "Epoch 319/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0891 - precision: 1.0000 - val_loss: 0.3663 - val_precision: 0.5000\n",
      "Epoch 320/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0879 - precision: 1.0000 - val_loss: 0.3682 - val_precision: 0.5000\n",
      "Epoch 321/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0877 - precision: 1.0000 - val_loss: 0.3704 - val_precision: 0.5000\n",
      "Epoch 322/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0876 - precision: 1.0000 - val_loss: 0.3722 - val_precision: 0.5000\n",
      "Epoch 323/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0875 - precision: 1.0000 - val_loss: 0.3715 - val_precision: 0.5000\n",
      "Epoch 324/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0871 - precision: 1.0000 - val_loss: 0.3711 - val_precision: 0.5000\n",
      "Epoch 325/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0873 - precision: 1.0000 - val_loss: 0.3716 - val_precision: 0.5000\n",
      "Epoch 326/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0873 - precision: 1.0000 - val_loss: 0.3732 - val_precision: 0.5000\n",
      "Epoch 327/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0887 - precision: 1.0000 - val_loss: 0.3697 - val_precision: 0.5000\n",
      "Epoch 328/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0879 - precision: 1.0000 - val_loss: 0.3706 - val_precision: 0.5000\n",
      "Epoch 329/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0885 - precision: 1.0000 - val_loss: 0.3708 - val_precision: 0.5000\n",
      "Epoch 330/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0872 - precision: 1.0000 - val_loss: 0.3732 - val_precision: 0.5000\n",
      "Epoch 331/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0859 - precision: 1.0000 - val_loss: 0.3752 - val_precision: 0.5000\n",
      "Epoch 332/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0859 - precision: 1.0000 - val_loss: 0.3772 - val_precision: 0.5000\n",
      "Epoch 333/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0858 - precision: 1.0000 - val_loss: 0.3761 - val_precision: 0.5000\n",
      "Epoch 334/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0860 - precision: 1.0000 - val_loss: 0.3723 - val_precision: 0.5000\n",
      "Epoch 335/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0872 - precision: 1.0000 - val_loss: 0.3754 - val_precision: 0.5000\n",
      "Epoch 336/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0862 - precision: 1.0000 - val_loss: 0.3782 - val_precision: 0.5000\n",
      "Epoch 337/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0859 - precision: 1.0000 - val_loss: 0.3784 - val_precision: 0.5000\n",
      "Epoch 338/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0854 - precision: 1.0000 - val_loss: 0.3786 - val_precision: 0.5000\n",
      "Epoch 339/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0850 - precision: 1.0000 - val_loss: 0.3805 - val_precision: 0.5000\n",
      "Epoch 340/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0854 - precision: 1.0000 - val_loss: 0.3873 - val_precision: 0.5000\n",
      "Epoch 341/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0854 - precision: 1.0000 - val_loss: 0.3874 - val_precision: 0.5000\n",
      "Epoch 342/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0853 - precision: 1.0000 - val_loss: 0.3878 - val_precision: 0.5000\n",
      "Epoch 343/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0853 - precision: 1.0000 - val_loss: 0.3852 - val_precision: 0.5000\n",
      "Epoch 344/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0844 - precision: 1.0000 - val_loss: 0.3839 - val_precision: 0.5000\n",
      "Epoch 345/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0841 - precision: 1.0000 - val_loss: 0.3837 - val_precision: 0.5000\n",
      "Epoch 346/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0836 - precision: 1.0000 - val_loss: 0.3803 - val_precision: 0.5000\n",
      "Epoch 347/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0854 - precision: 1.0000 - val_loss: 0.3798 - val_precision: 0.5000\n",
      "Epoch 348/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0838 - precision: 1.0000 - val_loss: 0.3834 - val_precision: 0.5000\n",
      "Epoch 349/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0853 - precision: 1.0000 - val_loss: 0.3884 - val_precision: 0.5000\n",
      "Epoch 350/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0844 - precision: 1.0000 - val_loss: 0.3868 - val_precision: 0.5000\n",
      "Epoch 351/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0828 - precision: 1.0000 - val_loss: 0.3831 - val_precision: 0.5000\n",
      "Epoch 352/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0833 - precision: 1.0000 - val_loss: 0.3832 - val_precision: 0.5000\n",
      "Epoch 353/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0833 - precision: 1.0000 - val_loss: 0.3841 - val_precision: 0.5000\n",
      "Epoch 354/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0834 - precision: 1.0000 - val_loss: 0.3837 - val_precision: 0.5000\n",
      "Epoch 355/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0834 - precision: 1.0000 - val_loss: 0.3855 - val_precision: 0.5000\n",
      "Epoch 356/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0827 - precision: 1.0000 - val_loss: 0.3877 - val_precision: 0.5000\n",
      "Epoch 357/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0829 - precision: 1.0000 - val_loss: 0.3901 - val_precision: 0.5000\n",
      "Epoch 358/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0829 - precision: 1.0000 - val_loss: 0.3894 - val_precision: 0.5000\n",
      "Epoch 359/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0827 - precision: 1.0000 - val_loss: 0.3925 - val_precision: 0.5000\n",
      "Epoch 360/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0827 - precision: 1.0000 - val_loss: 0.3978 - val_precision: 0.5000\n",
      "Epoch 361/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0832 - precision: 1.0000 - val_loss: 0.3985 - val_precision: 0.5000\n",
      "Epoch 362/500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0829 - precision: 1.0000 - val_loss: 0.3953 - val_precision: 0.5000\n",
      "Epoch 363/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0822 - precision: 1.0000 - val_loss: 0.3935 - val_precision: 0.5000\n",
      "Epoch 364/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0821 - precision: 1.0000 - val_loss: 0.3945 - val_precision: 0.5000\n",
      "Epoch 365/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0812 - precision: 1.0000 - val_loss: 0.3913 - val_precision: 0.5000\n",
      "Epoch 366/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0818 - precision: 1.0000 - val_loss: 0.3903 - val_precision: 0.5000\n",
      "Epoch 367/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0820 - precision: 1.0000 - val_loss: 0.3922 - val_precision: 0.5000\n",
      "Epoch 368/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0813 - precision: 1.0000 - val_loss: 0.3936 - val_precision: 0.5000\n",
      "Epoch 369/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0811 - precision: 1.0000 - val_loss: 0.3956 - val_precision: 0.5000\n",
      "Epoch 370/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0811 - precision: 1.0000 - val_loss: 0.3986 - val_precision: 0.5000\n",
      "Epoch 371/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0820 - precision: 1.0000 - val_loss: 0.3996 - val_precision: 0.5000\n",
      "Epoch 372/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0812 - precision: 1.0000 - val_loss: 0.3964 - val_precision: 0.5000\n",
      "Epoch 373/500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0810 - precision: 1.0000 - val_loss: 0.3936 - val_precision: 0.5000\n",
      "Epoch 374/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0811 - precision: 1.0000 - val_loss: 0.3936 - val_precision: 0.5000\n",
      "Epoch 375/500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0820 - precision: 1.0000 - val_loss: 0.3971 - val_precision: 0.5000\n",
      "Epoch 376/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0813 - precision: 1.0000 - val_loss: 0.3952 - val_precision: 0.5000\n",
      "Epoch 377/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0807 - precision: 1.0000 - val_loss: 0.3966 - val_precision: 0.5000\n",
      "Epoch 378/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0809 - precision: 1.0000 - val_loss: 0.3996 - val_precision: 0.5000\n",
      "Epoch 379/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0805 - precision: 1.0000 - val_loss: 0.4003 - val_precision: 0.5000\n",
      "Epoch 380/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0798 - precision: 1.0000 - val_loss: 0.3999 - val_precision: 0.5000\n",
      "Epoch 381/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0806 - precision: 1.0000 - val_loss: 0.4007 - val_precision: 0.5000\n",
      "Epoch 382/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0814 - precision: 1.0000 - val_loss: 0.4026 - val_precision: 0.5000\n",
      "Epoch 383/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0812 - precision: 1.0000 - val_loss: 0.4008 - val_precision: 0.4000\n",
      "Epoch 384/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0809 - precision: 1.0000 - val_loss: 0.4015 - val_precision: 0.5000\n",
      "Epoch 385/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0797 - precision: 1.0000 - val_loss: 0.4032 - val_precision: 0.5000\n",
      "Epoch 386/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0792 - precision: 1.0000 - val_loss: 0.4061 - val_precision: 0.5000\n",
      "Epoch 387/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0797 - precision: 1.0000 - val_loss: 0.4074 - val_precision: 0.5000\n",
      "Epoch 388/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0791 - precision: 1.0000 - val_loss: 0.4052 - val_precision: 0.5000\n",
      "Epoch 389/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0793 - precision: 1.0000 - val_loss: 0.4060 - val_precision: 0.5000\n",
      "Epoch 390/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0797 - precision: 1.0000 - val_loss: 0.4076 - val_precision: 0.5000\n",
      "Epoch 391/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0792 - precision: 1.0000 - val_loss: 0.4078 - val_precision: 0.5000\n",
      "Epoch 392/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0790 - precision: 1.0000 - val_loss: 0.4096 - val_precision: 0.5000\n",
      "Epoch 393/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0788 - precision: 1.0000 - val_loss: 0.4156 - val_precision: 0.5000\n",
      "Epoch 394/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0792 - precision: 1.0000 - val_loss: 0.4155 - val_precision: 0.5000\n",
      "Epoch 395/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0791 - precision: 1.0000 - val_loss: 0.4144 - val_precision: 0.5000\n",
      "Epoch 396/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0794 - precision: 1.0000 - val_loss: 0.4128 - val_precision: 0.5000\n",
      "Epoch 397/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0788 - precision: 1.0000 - val_loss: 0.4140 - val_precision: 0.5000\n",
      "Epoch 398/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0786 - precision: 1.0000 - val_loss: 0.4147 - val_precision: 0.5000\n",
      "Epoch 399/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0783 - precision: 1.0000 - val_loss: 0.4163 - val_precision: 0.5000\n",
      "Epoch 400/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0790 - precision: 1.0000 - val_loss: 0.4126 - val_precision: 0.5000\n",
      "Epoch 401/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0781 - precision: 1.0000 - val_loss: 0.4143 - val_precision: 0.5000\n",
      "Epoch 402/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0785 - precision: 1.0000 - val_loss: 0.4169 - val_precision: 0.5000\n",
      "Epoch 403/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0787 - precision: 1.0000 - val_loss: 0.4166 - val_precision: 0.5000\n",
      "Epoch 404/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0782 - precision: 1.0000 - val_loss: 0.4168 - val_precision: 0.5000\n",
      "Epoch 405/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0785 - precision: 1.0000 - val_loss: 0.4144 - val_precision: 0.5000\n",
      "Epoch 406/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0781 - precision: 1.0000 - val_loss: 0.4161 - val_precision: 0.5000\n",
      "Epoch 407/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0777 - precision: 1.0000 - val_loss: 0.4176 - val_precision: 0.5000\n",
      "Epoch 408/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0783 - precision: 1.0000 - val_loss: 0.4222 - val_precision: 0.5000\n",
      "Epoch 409/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0778 - precision: 1.0000 - val_loss: 0.4273 - val_precision: 0.5000\n",
      "Epoch 410/500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0783 - precision: 1.0000 - val_loss: 0.4234 - val_precision: 0.5000\n",
      "Epoch 411/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0780 - precision: 1.0000 - val_loss: 0.4244 - val_precision: 0.5000\n",
      "Epoch 412/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0784 - precision: 1.0000 - val_loss: 0.4243 - val_precision: 0.5000\n",
      "Epoch 413/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0780 - precision: 1.0000 - val_loss: 0.4273 - val_precision: 0.5000\n",
      "Epoch 414/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0774 - precision: 1.0000 - val_loss: 0.4275 - val_precision: 0.5000\n",
      "Epoch 415/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0778 - precision: 1.0000 - val_loss: 0.4264 - val_precision: 0.5000\n",
      "Epoch 416/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0790 - precision: 1.0000 - val_loss: 0.4205 - val_precision: 0.4000\n",
      "Epoch 417/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0801 - precision: 0.9444 - val_loss: 0.4193 - val_precision: 0.4000\n",
      "Epoch 418/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0785 - precision: 0.9412 - val_loss: 0.4199 - val_precision: 0.4000\n",
      "Epoch 419/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0774 - precision: 1.0000 - val_loss: 0.4236 - val_precision: 0.5000\n",
      "Epoch 420/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0780 - precision: 1.0000 - val_loss: 0.4275 - val_precision: 0.5000\n",
      "Epoch 421/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0774 - precision: 1.0000 - val_loss: 0.4246 - val_precision: 0.5000\n",
      "Epoch 422/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0768 - precision: 1.0000 - val_loss: 0.4233 - val_precision: 0.5000\n",
      "Epoch 423/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0773 - precision: 1.0000 - val_loss: 0.4213 - val_precision: 0.4000\n",
      "Epoch 424/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0769 - precision: 1.0000 - val_loss: 0.4228 - val_precision: 0.5000\n",
      "Epoch 425/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0765 - precision: 1.0000 - val_loss: 0.4244 - val_precision: 0.5000\n",
      "Epoch 426/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0768 - precision: 1.0000 - val_loss: 0.4263 - val_precision: 0.5000\n",
      "Epoch 427/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0759 - precision: 1.0000 - val_loss: 0.4211 - val_precision: 0.4000\n",
      "Epoch 428/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0768 - precision: 1.0000 - val_loss: 0.4212 - val_precision: 0.4000\n",
      "Epoch 429/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0766 - precision: 1.0000 - val_loss: 0.4247 - val_precision: 0.5000\n",
      "Epoch 430/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0773 - precision: 1.0000 - val_loss: 0.4277 - val_precision: 0.5000\n",
      "Epoch 431/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0764 - precision: 1.0000 - val_loss: 0.4237 - val_precision: 0.5000\n",
      "Epoch 432/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0761 - precision: 1.0000 - val_loss: 0.4243 - val_precision: 0.5000\n",
      "Epoch 433/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0759 - precision: 1.0000 - val_loss: 0.4263 - val_precision: 0.5000\n",
      "Epoch 434/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0757 - precision: 1.0000 - val_loss: 0.4259 - val_precision: 0.5000\n",
      "Epoch 435/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0770 - precision: 1.0000 - val_loss: 0.4256 - val_precision: 0.4000\n",
      "Epoch 436/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0762 - precision: 1.0000 - val_loss: 0.4255 - val_precision: 0.4000\n",
      "Epoch 437/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0778 - precision: 0.9444 - val_loss: 0.4245 - val_precision: 0.4000\n",
      "Epoch 438/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0791 - precision: 0.9444 - val_loss: 0.4231 - val_precision: 0.4000\n",
      "Epoch 439/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0767 - precision: 0.9412 - val_loss: 0.4246 - val_precision: 0.4000\n",
      "Epoch 440/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0753 - precision: 1.0000 - val_loss: 0.4276 - val_precision: 0.5000\n",
      "Epoch 441/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0755 - precision: 1.0000 - val_loss: 0.4293 - val_precision: 0.5000\n",
      "Epoch 442/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0753 - precision: 1.0000 - val_loss: 0.4291 - val_precision: 0.5000\n",
      "Epoch 443/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0754 - precision: 1.0000 - val_loss: 0.4273 - val_precision: 0.5000\n",
      "Epoch 444/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0750 - precision: 1.0000 - val_loss: 0.4288 - val_precision: 0.5000\n",
      "Epoch 445/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0751 - precision: 1.0000 - val_loss: 0.4308 - val_precision: 0.5000\n",
      "Epoch 446/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0767 - precision: 1.0000 - val_loss: 0.4378 - val_precision: 0.5000\n",
      "Epoch 447/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0754 - precision: 1.0000 - val_loss: 0.4368 - val_precision: 0.5000\n",
      "Epoch 448/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0752 - precision: 1.0000 - val_loss: 0.4353 - val_precision: 0.5000\n",
      "Epoch 449/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0739 - precision: 1.0000 - val_loss: 0.4319 - val_precision: 0.4000\n",
      "Epoch 450/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0787 - precision: 1.0000 - val_loss: 0.4332 - val_precision: 0.4000\n",
      "Epoch 451/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0803 - precision: 0.9444 - val_loss: 0.4309 - val_precision: 0.4000\n",
      "Epoch 452/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0777 - precision: 0.9444 - val_loss: 0.4310 - val_precision: 0.4000\n",
      "Epoch 453/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0754 - precision: 0.9444 - val_loss: 0.4318 - val_precision: 0.4000\n",
      "Epoch 454/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0746 - precision: 1.0000 - val_loss: 0.4343 - val_precision: 0.5000\n",
      "Epoch 455/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0747 - precision: 1.0000 - val_loss: 0.4373 - val_precision: 0.5000\n",
      "Epoch 456/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0741 - precision: 1.0000 - val_loss: 0.4363 - val_precision: 0.5000\n",
      "Epoch 457/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0746 - precision: 1.0000 - val_loss: 0.4367 - val_precision: 0.4000\n",
      "Epoch 458/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0748 - precision: 1.0000 - val_loss: 0.4391 - val_precision: 0.5000\n",
      "Epoch 459/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0742 - precision: 1.0000 - val_loss: 0.4394 - val_precision: 0.5000\n",
      "Epoch 460/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0741 - precision: 1.0000 - val_loss: 0.4403 - val_precision: 0.5000\n",
      "Epoch 461/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0746 - precision: 1.0000 - val_loss: 0.4425 - val_precision: 0.5000\n",
      "Epoch 462/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0742 - precision: 1.0000 - val_loss: 0.4417 - val_precision: 0.5000\n",
      "Epoch 463/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0742 - precision: 1.0000 - val_loss: 0.4415 - val_precision: 0.5000\n",
      "Epoch 464/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0740 - precision: 1.0000 - val_loss: 0.4413 - val_precision: 0.5000\n",
      "Epoch 465/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0743 - precision: 1.0000 - val_loss: 0.4416 - val_precision: 0.5000\n",
      "Epoch 466/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0741 - precision: 1.0000 - val_loss: 0.4421 - val_precision: 0.5000\n",
      "Epoch 467/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0742 - precision: 1.0000 - val_loss: 0.4408 - val_precision: 0.5000\n",
      "Epoch 468/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0737 - precision: 1.0000 - val_loss: 0.4421 - val_precision: 0.5000\n",
      "Epoch 469/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0738 - precision: 1.0000 - val_loss: 0.4442 - val_precision: 0.5000\n",
      "Epoch 470/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0738 - precision: 1.0000 - val_loss: 0.4446 - val_precision: 0.5000\n",
      "Epoch 471/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0737 - precision: 1.0000 - val_loss: 0.4451 - val_precision: 0.5000\n",
      "Epoch 472/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0739 - precision: 1.0000 - val_loss: 0.4453 - val_precision: 0.5000\n",
      "Epoch 473/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0737 - precision: 1.0000 - val_loss: 0.4454 - val_precision: 0.5000\n",
      "Epoch 474/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0742 - precision: 1.0000 - val_loss: 0.4496 - val_precision: 0.5000\n",
      "Epoch 475/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0747 - precision: 1.0000 - val_loss: 0.4484 - val_precision: 0.5000\n",
      "Epoch 476/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0736 - precision: 1.0000 - val_loss: 0.4457 - val_precision: 0.5000\n",
      "Epoch 477/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0730 - precision: 1.0000 - val_loss: 0.4428 - val_precision: 0.5000\n",
      "Epoch 478/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0734 - precision: 1.0000 - val_loss: 0.4420 - val_precision: 0.4000\n",
      "Epoch 479/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0730 - precision: 1.0000 - val_loss: 0.4428 - val_precision: 0.5000\n",
      "Epoch 480/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0730 - precision: 1.0000 - val_loss: 0.4440 - val_precision: 0.5000\n",
      "Epoch 481/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0729 - precision: 1.0000 - val_loss: 0.4437 - val_precision: 0.4000\n",
      "Epoch 482/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0750 - precision: 0.9444 - val_loss: 0.4433 - val_precision: 0.4000\n",
      "Epoch 483/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0764 - precision: 0.9444 - val_loss: 0.4431 - val_precision: 0.4000\n",
      "Epoch 484/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0749 - precision: 0.9444 - val_loss: 0.4440 - val_precision: 0.4000\n",
      "Epoch 485/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0740 - precision: 0.9444 - val_loss: 0.4461 - val_precision: 0.4000\n",
      "Epoch 486/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0730 - precision: 0.9444 - val_loss: 0.4463 - val_precision: 0.4000\n",
      "Epoch 487/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0734 - precision: 0.9444 - val_loss: 0.4470 - val_precision: 0.4000\n",
      "Epoch 488/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0738 - precision: 0.9444 - val_loss: 0.4479 - val_precision: 0.4000\n",
      "Epoch 489/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0733 - precision: 0.9444 - val_loss: 0.4504 - val_precision: 0.4000\n",
      "Epoch 490/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0727 - precision: 0.9444 - val_loss: 0.4515 - val_precision: 0.4000\n",
      "Epoch 491/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0726 - precision: 1.0000 - val_loss: 0.4526 - val_precision: 0.5000\n",
      "Epoch 492/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0723 - precision: 1.0000 - val_loss: 0.4540 - val_precision: 0.5000\n",
      "Epoch 493/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0723 - precision: 1.0000 - val_loss: 0.4563 - val_precision: 0.5000\n",
      "Epoch 494/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0726 - precision: 1.0000 - val_loss: 0.4570 - val_precision: 0.5000\n",
      "Epoch 495/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0731 - precision: 1.0000 - val_loss: 0.4602 - val_precision: 0.5000\n",
      "Epoch 496/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0736 - precision: 1.0000 - val_loss: 0.4579 - val_precision: 0.5000\n",
      "Epoch 497/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0730 - precision: 1.0000 - val_loss: 0.4548 - val_precision: 0.5000\n",
      "Epoch 498/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0721 - precision: 1.0000 - val_loss: 0.4527 - val_precision: 0.5000\n",
      "Epoch 499/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0724 - precision: 1.0000 - val_loss: 0.4529 - val_precision: 0.5000\n",
      "Epoch 500/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0724 - precision: 0.9444 - val_loss: 0.4481 - val_precision: 0.4000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "history = modelb.fit(padded, training_labels_final, \n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(val_padded, val_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "zznkunIyBt9Q",
    "outputId": "223a6f2f-9b8e-4071-e31c-70134f3a0d15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "precision = history.history['precision']\n",
    "val_precision = history.history['val_precision']\n",
    "epochs=range(len(precision))\n",
    "plt.plot(epochs, precision, 'r')\n",
    "plt.plot(epochs, val_precision, 'b')\n",
    "plt.title('Training and validation Precision')\n",
    "plt.ylim((0,1.5))\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c5mZK0lJ8eSR",
    "outputId": "7312e877-4e9c-4604-cd0d-3471e0350912",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5189 - precision: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5189329385757446, 0.800000011920929]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelb.evaluate(test_padded, test_labels_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_k1wZhYND2H"
   },
   "source": [
    "# Part II. Pre-trained embedding specialized for Central Banks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UE75Z1v6ND2H"
   },
   "source": [
    "### First we apply the central bank-specific embeddings by Zahner and Baumgaertner predicting the next rate.  We will first explore the embeddings then run the models.  We find there are over 72,000 word vectors and 300 features per word.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "MErAW7f3ND2I"
   },
   "outputs": [],
   "source": [
    "zb = pd.read_csv('word_embeddings_3b.csv') #, header=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jfz9L4GyYjiL",
    "outputId": "a656809e-b61b-4ff4-c6ec-fb1b547c3526"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73082, 301)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "YnBXoREAND2I",
    "outputId": "252cbc74-4227-474d-843a-938e8ec41f28"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V291</th>\n",
       "      <th>V292</th>\n",
       "      <th>V293</th>\n",
       "      <th>V294</th>\n",
       "      <th>V295</th>\n",
       "      <th>V296</th>\n",
       "      <th>V297</th>\n",
       "      <th>V298</th>\n",
       "      <th>V299</th>\n",
       "      <th>V300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>0.080156</td>\n",
       "      <td>0.088501</td>\n",
       "      <td>-0.076703</td>\n",
       "      <td>-0.065645</td>\n",
       "      <td>0.027367</td>\n",
       "      <td>0.060499</td>\n",
       "      <td>0.018841</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>-0.072163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025759</td>\n",
       "      <td>0.030279</td>\n",
       "      <td>0.019642</td>\n",
       "      <td>-0.030535</td>\n",
       "      <td>0.058834</td>\n",
       "      <td>-0.092278</td>\n",
       "      <td>-0.028259</td>\n",
       "      <td>-0.026270</td>\n",
       "      <td>-0.033166</td>\n",
       "      <td>0.061495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>-0.038091</td>\n",
       "      <td>-0.049348</td>\n",
       "      <td>-0.028680</td>\n",
       "      <td>-0.018713</td>\n",
       "      <td>0.063518</td>\n",
       "      <td>0.057007</td>\n",
       "      <td>0.021474</td>\n",
       "      <td>0.084622</td>\n",
       "      <td>-0.108604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004401</td>\n",
       "      <td>0.030320</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>-0.081768</td>\n",
       "      <td>0.011895</td>\n",
       "      <td>0.025118</td>\n",
       "      <td>0.029903</td>\n",
       "      <td>0.029950</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>-0.065045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.061148</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>-0.058344</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>0.039084</td>\n",
       "      <td>0.056894</td>\n",
       "      <td>-0.048181</td>\n",
       "      <td>0.049727</td>\n",
       "      <td>-0.075358</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038889</td>\n",
       "      <td>0.069039</td>\n",
       "      <td>0.018876</td>\n",
       "      <td>-0.050831</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>0.018375</td>\n",
       "      <td>0.052614</td>\n",
       "      <td>0.057787</td>\n",
       "      <td>-0.000694</td>\n",
       "      <td>-0.043442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.</td>\n",
       "      <td>-0.099335</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>-0.048134</td>\n",
       "      <td>-0.010280</td>\n",
       "      <td>-0.000963</td>\n",
       "      <td>0.022920</td>\n",
       "      <td>-0.026348</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>-0.068051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032482</td>\n",
       "      <td>0.063615</td>\n",
       "      <td>-0.020517</td>\n",
       "      <td>-0.017632</td>\n",
       "      <td>0.029572</td>\n",
       "      <td>0.061214</td>\n",
       "      <td>0.075277</td>\n",
       "      <td>0.135811</td>\n",
       "      <td>-0.011819</td>\n",
       "      <td>-0.106832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>-0.092714</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>-0.048257</td>\n",
       "      <td>0.010404</td>\n",
       "      <td>0.047617</td>\n",
       "      <td>0.060156</td>\n",
       "      <td>-0.019659</td>\n",
       "      <td>0.040367</td>\n",
       "      <td>-0.107395</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036493</td>\n",
       "      <td>0.109343</td>\n",
       "      <td>-0.000342</td>\n",
       "      <td>-0.072286</td>\n",
       "      <td>0.045893</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.056748</td>\n",
       "      <td>0.037754</td>\n",
       "      <td>-0.022448</td>\n",
       "      <td>-0.029516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  </s>  0.080156  0.088501 -0.076703 -0.065645  0.027367  0.060499  0.018841   \n",
       "1   the -0.038091 -0.049348 -0.028680 -0.018713  0.063518  0.057007  0.021474   \n",
       "2   NaN -0.061148 -0.000166 -0.058344  0.014657  0.039084  0.056894 -0.048181   \n",
       "3     . -0.099335  0.001326 -0.048134 -0.010280 -0.000963  0.022920 -0.026348   \n",
       "4    of -0.092714  0.016854 -0.048257  0.010404  0.047617  0.060156 -0.019659   \n",
       "\n",
       "         V8        V9  ...      V291      V292      V293      V294      V295  \\\n",
       "0  0.004232 -0.072163  ... -0.025759  0.030279  0.019642 -0.030535  0.058834   \n",
       "1  0.084622 -0.108604  ...  0.004401  0.030320  0.001037 -0.081768  0.011895   \n",
       "2  0.049727 -0.075358  ... -0.038889  0.069039  0.018876 -0.050831  0.029056   \n",
       "3  0.010025 -0.068051  ... -0.032482  0.063615 -0.020517 -0.017632  0.029572   \n",
       "4  0.040367 -0.107395  ... -0.036493  0.109343 -0.000342 -0.072286  0.045893   \n",
       "\n",
       "       V296      V297      V298      V299      V300  \n",
       "0 -0.092278 -0.028259 -0.026270 -0.033166  0.061495  \n",
       "1  0.025118  0.029903  0.029950  0.002812 -0.065045  \n",
       "2  0.018375  0.052614  0.057787 -0.000694 -0.043442  \n",
       "3  0.061214  0.075277  0.135811 -0.011819 -0.106832  \n",
       "4  0.002628  0.056748  0.037754 -0.022448 -0.029516  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "Egu7UblMND2J"
   },
   "outputs": [],
   "source": [
    "zb=zb.set_index('word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "r2qwWbayND2J"
   },
   "outputs": [],
   "source": [
    "zb_transposed = zb.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "MvNwD17GND2K",
    "outputId": "ad932ccd-bf90-4031-9896-6e497659559e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>word</th>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "      <th>the</th>\n",
       "      <th>NaN</th>\n",
       "      <th>.</th>\n",
       "      <th>of</th>\n",
       "      <th>to</th>\n",
       "      <th>and</th>\n",
       "      <th>in</th>\n",
       "      <th>[decimal]</th>\n",
       "      <th>a</th>\n",
       "      <th>...</th>\n",
       "      <th>cop25</th>\n",
       "      <th>alistair</th>\n",
       "      <th>effectuation</th>\n",
       "      <th>fhfas</th>\n",
       "      <th>vaciago</th>\n",
       "      <th>just-i</th>\n",
       "      <th>ancona</th>\n",
       "      <th>1999–2001</th>\n",
       "      <th>ctos</th>\n",
       "      <th>altcoins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>0.080156</td>\n",
       "      <td>-0.038091</td>\n",
       "      <td>-0.061148</td>\n",
       "      <td>-0.099335</td>\n",
       "      <td>-0.092714</td>\n",
       "      <td>0.019735</td>\n",
       "      <td>-0.015383</td>\n",
       "      <td>0.009759</td>\n",
       "      <td>-0.047645</td>\n",
       "      <td>0.060641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078843</td>\n",
       "      <td>-0.023943</td>\n",
       "      <td>0.021798</td>\n",
       "      <td>0.034371</td>\n",
       "      <td>-0.039774</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>-0.061320</td>\n",
       "      <td>-0.033173</td>\n",
       "      <td>-0.207396</td>\n",
       "      <td>0.019181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>0.088501</td>\n",
       "      <td>-0.049348</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>0.017912</td>\n",
       "      <td>0.014828</td>\n",
       "      <td>-0.050921</td>\n",
       "      <td>-0.077989</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026619</td>\n",
       "      <td>-0.013862</td>\n",
       "      <td>0.074990</td>\n",
       "      <td>-0.068248</td>\n",
       "      <td>0.046751</td>\n",
       "      <td>0.017442</td>\n",
       "      <td>-0.031018</td>\n",
       "      <td>-0.095737</td>\n",
       "      <td>0.106908</td>\n",
       "      <td>0.013239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>-0.076703</td>\n",
       "      <td>-0.028680</td>\n",
       "      <td>-0.058344</td>\n",
       "      <td>-0.048134</td>\n",
       "      <td>-0.048257</td>\n",
       "      <td>-0.018683</td>\n",
       "      <td>-0.044502</td>\n",
       "      <td>-0.004150</td>\n",
       "      <td>0.003544</td>\n",
       "      <td>-0.009209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120499</td>\n",
       "      <td>0.074515</td>\n",
       "      <td>0.022469</td>\n",
       "      <td>-0.012830</td>\n",
       "      <td>0.029337</td>\n",
       "      <td>-0.059405</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.104349</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>-0.034064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>-0.065645</td>\n",
       "      <td>-0.018713</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>-0.010280</td>\n",
       "      <td>0.010404</td>\n",
       "      <td>-0.022496</td>\n",
       "      <td>-0.005357</td>\n",
       "      <td>-0.009244</td>\n",
       "      <td>0.034186</td>\n",
       "      <td>-0.019526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041775</td>\n",
       "      <td>-0.004044</td>\n",
       "      <td>0.053189</td>\n",
       "      <td>-0.057841</td>\n",
       "      <td>0.028182</td>\n",
       "      <td>-0.011910</td>\n",
       "      <td>0.006949</td>\n",
       "      <td>-0.006095</td>\n",
       "      <td>-0.042527</td>\n",
       "      <td>0.041970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>0.027367</td>\n",
       "      <td>0.063518</td>\n",
       "      <td>0.039084</td>\n",
       "      <td>-0.000963</td>\n",
       "      <td>0.047617</td>\n",
       "      <td>0.073557</td>\n",
       "      <td>0.016352</td>\n",
       "      <td>0.076654</td>\n",
       "      <td>0.046362</td>\n",
       "      <td>0.011457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062888</td>\n",
       "      <td>-0.030928</td>\n",
       "      <td>0.072676</td>\n",
       "      <td>-0.003460</td>\n",
       "      <td>0.053458</td>\n",
       "      <td>0.047244</td>\n",
       "      <td>0.068072</td>\n",
       "      <td>0.091003</td>\n",
       "      <td>0.006158</td>\n",
       "      <td>-0.034872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73082 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "word      </s>       the       NaN         .        of        to       and  \\\n",
       "V1    0.080156 -0.038091 -0.061148 -0.099335 -0.092714  0.019735 -0.015383   \n",
       "V2    0.088501 -0.049348 -0.000166  0.001326  0.016854  0.017912  0.014828   \n",
       "V3   -0.076703 -0.028680 -0.058344 -0.048134 -0.048257 -0.018683 -0.044502   \n",
       "V4   -0.065645 -0.018713  0.014657 -0.010280  0.010404 -0.022496 -0.005357   \n",
       "V5    0.027367  0.063518  0.039084 -0.000963  0.047617  0.073557  0.016352   \n",
       "\n",
       "word        in  [decimal]         a  ...     cop25  alistair  effectuation  \\\n",
       "V1    0.009759  -0.047645  0.060641  ... -0.078843 -0.023943      0.021798   \n",
       "V2   -0.050921  -0.077989 -0.000283  ... -0.026619 -0.013862      0.074990   \n",
       "V3   -0.004150   0.003544 -0.009209  ...  0.120499  0.074515      0.022469   \n",
       "V4   -0.009244   0.034186 -0.019526  ...  0.041775 -0.004044      0.053189   \n",
       "V5    0.076654   0.046362  0.011457  ...  0.062888 -0.030928      0.072676   \n",
       "\n",
       "word     fhfas   vaciago    just-i    ancona  1999–2001      ctos  altcoins  \n",
       "V1    0.034371 -0.039774  0.003213 -0.061320  -0.033173 -0.207396  0.019181  \n",
       "V2   -0.068248  0.046751  0.017442 -0.031018  -0.095737  0.106908  0.013239  \n",
       "V3   -0.012830  0.029337 -0.059405  0.003367   0.104349  0.015193 -0.034064  \n",
       "V4   -0.057841  0.028182 -0.011910  0.006949  -0.006095 -0.042527  0.041970  \n",
       "V5   -0.003460  0.053458  0.047244  0.068072   0.091003  0.006158 -0.034872  \n",
       "\n",
       "[5 rows x 73082 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zb_transposed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "nxkUhBxIND2K"
   },
   "outputs": [],
   "source": [
    "list_of_columns = zb.values.tolist() # was df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "2vNAz2WYND2L"
   },
   "outputs": [],
   "source": [
    "words=list(zb_transposed.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "7SrlSBrAND2X",
    "outputId": "13067689-3893-4dd5-c5fc-b5ae23a29fee"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V291</th>\n",
       "      <th>V292</th>\n",
       "      <th>V293</th>\n",
       "      <th>V294</th>\n",
       "      <th>V295</th>\n",
       "      <th>V296</th>\n",
       "      <th>V297</th>\n",
       "      <th>V298</th>\n",
       "      <th>V299</th>\n",
       "      <th>V300</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "      <td>0.080156</td>\n",
       "      <td>0.088501</td>\n",
       "      <td>-0.076703</td>\n",
       "      <td>-0.065645</td>\n",
       "      <td>0.027367</td>\n",
       "      <td>0.060499</td>\n",
       "      <td>0.018841</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>-0.072163</td>\n",
       "      <td>0.044426</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025759</td>\n",
       "      <td>0.030279</td>\n",
       "      <td>0.019642</td>\n",
       "      <td>-0.030535</td>\n",
       "      <td>0.058834</td>\n",
       "      <td>-0.092278</td>\n",
       "      <td>-0.028259</td>\n",
       "      <td>-0.026270</td>\n",
       "      <td>-0.033166</td>\n",
       "      <td>0.061495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>-0.038091</td>\n",
       "      <td>-0.049348</td>\n",
       "      <td>-0.028680</td>\n",
       "      <td>-0.018713</td>\n",
       "      <td>0.063518</td>\n",
       "      <td>0.057007</td>\n",
       "      <td>0.021474</td>\n",
       "      <td>0.084622</td>\n",
       "      <td>-0.108604</td>\n",
       "      <td>-0.092650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004401</td>\n",
       "      <td>0.030320</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>-0.081768</td>\n",
       "      <td>0.011895</td>\n",
       "      <td>0.025118</td>\n",
       "      <td>0.029903</td>\n",
       "      <td>0.029950</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>-0.065045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>-0.061148</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>-0.058344</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>0.039084</td>\n",
       "      <td>0.056894</td>\n",
       "      <td>-0.048181</td>\n",
       "      <td>0.049727</td>\n",
       "      <td>-0.075358</td>\n",
       "      <td>-0.038712</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038889</td>\n",
       "      <td>0.069039</td>\n",
       "      <td>0.018876</td>\n",
       "      <td>-0.050831</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>0.018375</td>\n",
       "      <td>0.052614</td>\n",
       "      <td>0.057787</td>\n",
       "      <td>-0.000694</td>\n",
       "      <td>-0.043442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>-0.099335</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>-0.048134</td>\n",
       "      <td>-0.010280</td>\n",
       "      <td>-0.000963</td>\n",
       "      <td>0.022920</td>\n",
       "      <td>-0.026348</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>-0.068051</td>\n",
       "      <td>-0.049312</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032482</td>\n",
       "      <td>0.063615</td>\n",
       "      <td>-0.020517</td>\n",
       "      <td>-0.017632</td>\n",
       "      <td>0.029572</td>\n",
       "      <td>0.061214</td>\n",
       "      <td>0.075277</td>\n",
       "      <td>0.135811</td>\n",
       "      <td>-0.011819</td>\n",
       "      <td>-0.106832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>-0.092714</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>-0.048257</td>\n",
       "      <td>0.010404</td>\n",
       "      <td>0.047617</td>\n",
       "      <td>0.060156</td>\n",
       "      <td>-0.019659</td>\n",
       "      <td>0.040367</td>\n",
       "      <td>-0.107395</td>\n",
       "      <td>-0.068698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036493</td>\n",
       "      <td>0.109343</td>\n",
       "      <td>-0.000342</td>\n",
       "      <td>-0.072286</td>\n",
       "      <td>0.045893</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.056748</td>\n",
       "      <td>0.037754</td>\n",
       "      <td>-0.022448</td>\n",
       "      <td>-0.029516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            V1        V2        V3        V4        V5        V6        V7  \\\n",
       "word                                                                         \n",
       "</s>  0.080156  0.088501 -0.076703 -0.065645  0.027367  0.060499  0.018841   \n",
       "the  -0.038091 -0.049348 -0.028680 -0.018713  0.063518  0.057007  0.021474   \n",
       "NaN  -0.061148 -0.000166 -0.058344  0.014657  0.039084  0.056894 -0.048181   \n",
       ".    -0.099335  0.001326 -0.048134 -0.010280 -0.000963  0.022920 -0.026348   \n",
       "of   -0.092714  0.016854 -0.048257  0.010404  0.047617  0.060156 -0.019659   \n",
       "\n",
       "            V8        V9       V10  ...      V291      V292      V293  \\\n",
       "word                                ...                                 \n",
       "</s>  0.004232 -0.072163  0.044426  ... -0.025759  0.030279  0.019642   \n",
       "the   0.084622 -0.108604 -0.092650  ...  0.004401  0.030320  0.001037   \n",
       "NaN   0.049727 -0.075358 -0.038712  ... -0.038889  0.069039  0.018876   \n",
       ".     0.010025 -0.068051 -0.049312  ... -0.032482  0.063615 -0.020517   \n",
       "of    0.040367 -0.107395 -0.068698  ... -0.036493  0.109343 -0.000342   \n",
       "\n",
       "          V294      V295      V296      V297      V298      V299      V300  \n",
       "word                                                                        \n",
       "</s> -0.030535  0.058834 -0.092278 -0.028259 -0.026270 -0.033166  0.061495  \n",
       "the  -0.081768  0.011895  0.025118  0.029903  0.029950  0.002812 -0.065045  \n",
       "NaN  -0.050831  0.029056  0.018375  0.052614  0.057787 -0.000694 -0.043442  \n",
       ".    -0.017632  0.029572  0.061214  0.075277  0.135811 -0.011819 -0.106832  \n",
       "of   -0.072286  0.045893  0.002628  0.056748  0.037754 -0.022448 -0.029516  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zb.head() #df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "QI_ecS6dND2X",
    "outputId": "ccd5b625-1066-4d1d-c050-39c81f348d98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inflation'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HhraL6JSND2X",
    "outputId": "fab23ba2-49ed-4acd-f8ad-a84f9401890e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 72096 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {} \n",
    "\n",
    "for i in range(len(words)):\n",
    "    embeddings_index[words[i]]=list_of_columns[i]\n",
    "    \n",
    "\n",
    "#word_column = df['word']\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0IejIYOIXGmo"
   },
   "source": [
    "# Prepare pretrained embeddings for the model and see how many words in our vocabulary are in the pre-trained model.\n",
    "\n",
    "Source:  https://keras.io/examples/nlp/pretrained_word_embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "_Be6537tND2c",
    "outputId": "e64ae5d5-f897-4ca9-a996-f703bf22b5b7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#vocab_size=2000\n",
    "num_tokens = len(range(vocab_size)) + 2\n",
    "embedding_dim = 300 #number of features per word in pre-trained model\n",
    "hits = 0 \n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "        #print(word, end =\"\")\n",
    "        #print(word)\n",
    "#print(\"Converted %d words (%d misses)\" % (hits, misses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "MrPgV4GcND2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "oQdKS4TmND2d"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "modela_zb = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], input_length = max_length, trainable=False),\n",
    "    #tf.keras.layers.Embedding(vocab_size+2,embedding_dim,embeddings_initializer=keras.initializers.Constant(embedding_matrix),input_length=max_length, trainable=False),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "]) # the two embedding statements here do exactly the same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "Hci2jJu8ND2d"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "modela_zb.compile(loss='binary_crossentropy', \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "L31FAi1-ND2e",
    "outputId": "a0416723-e27f-4a0f-fd24-3ef9ab73abf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1200, 300)         1500600   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 300)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 1806      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,502,413\n",
      "Trainable params: 1,813\n",
      "Non-trainable params: 1,500,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modela_zb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "eDWQkWpNND2e",
    "outputId": "e68d8dc3-fb1d-4a39-aa88-404464fb7558"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.6807 - precision: 0.0000e+00 - val_loss: 0.6742 - val_precision: 0.0000e+00\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.6648 - precision: 0.0000e+00 - val_loss: 0.6600 - val_precision: 0.0000e+00\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.6492 - precision: 0.0000e+00 - val_loss: 0.6458 - val_precision: 0.0000e+00\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6332 - precision: 0.0000e+00 - val_loss: 0.6318 - val_precision: 0.0000e+00\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6177 - precision: 0.0000e+00 - val_loss: 0.6181 - val_precision: 0.0000e+00\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.6028 - precision: 0.0000e+00 - val_loss: 0.6045 - val_precision: 0.0000e+00\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5878 - precision: 0.0000e+00 - val_loss: 0.5910 - val_precision: 0.0000e+00\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.5731 - precision: 0.0000e+00 - val_loss: 0.5780 - val_precision: 0.0000e+00\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5588 - precision: 0.0000e+00 - val_loss: 0.5653 - val_precision: 0.0000e+00\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.5451 - precision: 0.0000e+00 - val_loss: 0.5533 - val_precision: 0.0000e+00\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.5320 - precision: 0.0000e+00 - val_loss: 0.5407 - val_precision: 0.0000e+00\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.5185 - precision: 0.0000e+00 - val_loss: 0.5288 - val_precision: 0.0000e+00\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.5056 - precision: 0.0000e+00 - val_loss: 0.5171 - val_precision: 0.0000e+00\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4928 - precision: 0.0000e+00 - val_loss: 0.5056 - val_precision: 0.0000e+00\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.4805 - precision: 0.0000e+00 - val_loss: 0.4946 - val_precision: 0.0000e+00\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4687 - precision: 0.0000e+00 - val_loss: 0.4838 - val_precision: 0.0000e+00\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.4573 - precision: 0.0000e+00 - val_loss: 0.4734 - val_precision: 0.0000e+00\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.4464 - precision: 0.0000e+00 - val_loss: 0.4632 - val_precision: 0.0000e+00\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.4360 - precision: 0.0000e+00 - val_loss: 0.4536 - val_precision: 0.0000e+00\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4264 - precision: 0.0000e+00 - val_loss: 0.4450 - val_precision: 0.0000e+00\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.4171 - precision: 0.0000e+00 - val_loss: 0.4367 - val_precision: 0.0000e+00\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.4085 - precision: 0.0000e+00 - val_loss: 0.4284 - val_precision: 0.0000e+00\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.4002 - precision: 0.0000e+00 - val_loss: 0.4206 - val_precision: 0.0000e+00\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3925 - precision: 0.0000e+00 - val_loss: 0.4136 - val_precision: 0.0000e+00\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3856 - precision: 0.0000e+00 - val_loss: 0.4072 - val_precision: 0.0000e+00\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3790 - precision: 0.0000e+00 - val_loss: 0.4013 - val_precision: 0.0000e+00\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3728 - precision: 0.0000e+00 - val_loss: 0.3953 - val_precision: 0.0000e+00\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3670 - precision: 0.0000e+00 - val_loss: 0.3892 - val_precision: 0.0000e+00\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3609 - precision: 0.0000e+00 - val_loss: 0.3835 - val_precision: 0.0000e+00\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3553 - precision: 0.0000e+00 - val_loss: 0.3782 - val_precision: 0.0000e+00\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3500 - precision: 0.0000e+00 - val_loss: 0.3733 - val_precision: 0.0000e+00\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3451 - precision: 0.0000e+00 - val_loss: 0.3691 - val_precision: 0.0000e+00\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3411 - precision: 0.0000e+00 - val_loss: 0.3649 - val_precision: 0.0000e+00\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3369 - precision: 0.0000e+00 - val_loss: 0.3608 - val_precision: 0.0000e+00\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3330 - precision: 0.0000e+00 - val_loss: 0.3569 - val_precision: 0.0000e+00\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3291 - precision: 0.0000e+00 - val_loss: 0.3534 - val_precision: 0.0000e+00\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3261 - precision: 0.0000e+00 - val_loss: 0.3502 - val_precision: 0.0000e+00\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3229 - precision: 0.0000e+00 - val_loss: 0.3472 - val_precision: 0.0000e+00\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3203 - precision: 0.0000e+00 - val_loss: 0.3445 - val_precision: 0.0000e+00\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3180 - precision: 0.0000e+00 - val_loss: 0.3424 - val_precision: 0.0000e+00\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3158 - precision: 0.0000e+00 - val_loss: 0.3400 - val_precision: 0.0000e+00\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3140 - precision: 0.0000e+00 - val_loss: 0.3379 - val_precision: 0.0000e+00\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3116 - precision: 0.0000e+00 - val_loss: 0.3358 - val_precision: 0.0000e+00\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3097 - precision: 0.0000e+00 - val_loss: 0.3337 - val_precision: 0.0000e+00\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3079 - precision: 0.0000e+00 - val_loss: 0.3322 - val_precision: 0.0000e+00\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3063 - precision: 0.0000e+00 - val_loss: 0.3304 - val_precision: 0.0000e+00\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3046 - precision: 0.0000e+00 - val_loss: 0.3285 - val_precision: 0.0000e+00\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3029 - precision: 0.0000e+00 - val_loss: 0.3267 - val_precision: 0.0000e+00\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3014 - precision: 0.0000e+00 - val_loss: 0.3249 - val_precision: 0.0000e+00\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2999 - precision: 0.0000e+00 - val_loss: 0.3233 - val_precision: 0.0000e+00\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2985 - precision: 0.0000e+00 - val_loss: 0.3218 - val_precision: 0.0000e+00\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.2970 - precision: 0.0000e+00 - val_loss: 0.3206 - val_precision: 0.0000e+00\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2959 - precision: 0.0000e+00 - val_loss: 0.3194 - val_precision: 0.0000e+00\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.2950 - precision: 0.0000e+00 - val_loss: 0.3184 - val_precision: 0.0000e+00\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2942 - precision: 0.0000e+00 - val_loss: 0.3174 - val_precision: 0.0000e+00\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2932 - precision: 0.0000e+00 - val_loss: 0.3164 - val_precision: 0.0000e+00\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2925 - precision: 0.0000e+00 - val_loss: 0.3157 - val_precision: 0.0000e+00\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.2918 - precision: 0.0000e+00 - val_loss: 0.3149 - val_precision: 0.0000e+00\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2911 - precision: 0.0000e+00 - val_loss: 0.3142 - val_precision: 0.0000e+00\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2905 - precision: 0.0000e+00 - val_loss: 0.3134 - val_precision: 0.0000e+00\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.2899 - precision: 0.0000e+00 - val_loss: 0.3127 - val_precision: 0.0000e+00\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.2893 - precision: 0.0000e+00 - val_loss: 0.3122 - val_precision: 0.0000e+00\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2889 - precision: 0.0000e+00 - val_loss: 0.3117 - val_precision: 0.0000e+00\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2885 - precision: 0.0000e+00 - val_loss: 0.3113 - val_precision: 0.0000e+00\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2881 - precision: 0.0000e+00 - val_loss: 0.3108 - val_precision: 0.0000e+00\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2877 - precision: 0.0000e+00 - val_loss: 0.3103 - val_precision: 0.0000e+00\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2874 - precision: 0.0000e+00 - val_loss: 0.3100 - val_precision: 0.0000e+00\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2872 - precision: 0.0000e+00 - val_loss: 0.3097 - val_precision: 0.0000e+00\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2869 - precision: 0.0000e+00 - val_loss: 0.3094 - val_precision: 0.0000e+00\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.2867 - precision: 0.0000e+00 - val_loss: 0.3092 - val_precision: 0.0000e+00\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.2864 - precision: 0.0000e+00 - val_loss: 0.3088 - val_precision: 0.0000e+00\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.2861 - precision: 0.0000e+00 - val_loss: 0.3085 - val_precision: 0.0000e+00\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2859 - precision: 0.0000e+00 - val_loss: 0.3081 - val_precision: 0.0000e+00\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2856 - precision: 0.0000e+00 - val_loss: 0.3077 - val_precision: 0.0000e+00\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2853 - precision: 0.0000e+00 - val_loss: 0.3074 - val_precision: 0.0000e+00\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2851 - precision: 0.0000e+00 - val_loss: 0.3073 - val_precision: 0.0000e+00\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2851 - precision: 0.0000e+00 - val_loss: 0.3072 - val_precision: 0.0000e+00\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2849 - precision: 0.0000e+00 - val_loss: 0.3070 - val_precision: 0.0000e+00\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2847 - precision: 0.0000e+00 - val_loss: 0.3068 - val_precision: 0.0000e+00\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2846 - precision: 0.0000e+00 - val_loss: 0.3066 - val_precision: 0.0000e+00\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.2844 - precision: 0.0000e+00 - val_loss: 0.3064 - val_precision: 0.0000e+00\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.2844 - precision: 0.0000e+00 - val_loss: 0.3064 - val_precision: 0.0000e+00\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.2843 - precision: 0.0000e+00 - val_loss: 0.3063 - val_precision: 0.0000e+00\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2842 - precision: 0.0000e+00 - val_loss: 0.3062 - val_precision: 0.0000e+00\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2842 - precision: 0.0000e+00 - val_loss: 0.3062 - val_precision: 0.0000e+00\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2842 - precision: 0.0000e+00 - val_loss: 0.3061 - val_precision: 0.0000e+00\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.2840 - precision: 0.0000e+00 - val_loss: 0.3059 - val_precision: 0.0000e+00\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2839 - precision: 0.0000e+00 - val_loss: 0.3059 - val_precision: 0.0000e+00\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2839 - precision: 0.0000e+00 - val_loss: 0.3059 - val_precision: 0.0000e+00\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2838 - precision: 0.0000e+00 - val_loss: 0.3058 - val_precision: 0.0000e+00\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2838 - precision: 0.0000e+00 - val_loss: 0.3058 - val_precision: 0.0000e+00\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2838 - precision: 0.0000e+00 - val_loss: 0.3057 - val_precision: 0.0000e+00\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.2838 - precision: 0.0000e+00 - val_loss: 0.3057 - val_precision: 0.0000e+00\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2837 - precision: 0.0000e+00 - val_loss: 0.3057 - val_precision: 0.0000e+00\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2836 - precision: 0.0000e+00 - val_loss: 0.3055 - val_precision: 0.0000e+00\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2834 - precision: 0.0000e+00 - val_loss: 0.3053 - val_precision: 0.0000e+00\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2834 - precision: 0.0000e+00 - val_loss: 0.3052 - val_precision: 0.0000e+00\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2833 - precision: 0.0000e+00 - val_loss: 0.3051 - val_precision: 0.0000e+00\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2832 - precision: 0.0000e+00 - val_loss: 0.3050 - val_precision: 0.0000e+00\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2831 - precision: 0.0000e+00 - val_loss: 0.3048 - val_precision: 0.0000e+00\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2829 - precision: 0.0000e+00 - val_loss: 0.3047 - val_precision: 0.0000e+00\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2828 - precision: 0.0000e+00 - val_loss: 0.3045 - val_precision: 0.0000e+00\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2828 - precision: 0.0000e+00 - val_loss: 0.3043 - val_precision: 0.0000e+00\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2826 - precision: 0.0000e+00 - val_loss: 0.3042 - val_precision: 0.0000e+00\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2825 - precision: 0.0000e+00 - val_loss: 0.3040 - val_precision: 0.0000e+00\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2824 - precision: 0.0000e+00 - val_loss: 0.3039 - val_precision: 0.0000e+00\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2823 - precision: 0.0000e+00 - val_loss: 0.3039 - val_precision: 0.0000e+00\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2823 - precision: 0.0000e+00 - val_loss: 0.3038 - val_precision: 0.0000e+00\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2823 - precision: 0.0000e+00 - val_loss: 0.3037 - val_precision: 0.0000e+00\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2821 - precision: 0.0000e+00 - val_loss: 0.3036 - val_precision: 0.0000e+00\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2821 - precision: 0.0000e+00 - val_loss: 0.3035 - val_precision: 0.0000e+00\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2820 - precision: 0.0000e+00 - val_loss: 0.3034 - val_precision: 0.0000e+00\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2820 - precision: 0.0000e+00 - val_loss: 0.3034 - val_precision: 0.0000e+00\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2819 - precision: 0.0000e+00 - val_loss: 0.3034 - val_precision: 0.0000e+00\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2819 - precision: 0.0000e+00 - val_loss: 0.3034 - val_precision: 0.0000e+00\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2819 - precision: 0.0000e+00 - val_loss: 0.3034 - val_precision: 0.0000e+00\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2818 - precision: 0.0000e+00 - val_loss: 0.3033 - val_precision: 0.0000e+00\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2818 - precision: 0.0000e+00 - val_loss: 0.3032 - val_precision: 0.0000e+00\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2817 - precision: 0.0000e+00 - val_loss: 0.3032 - val_precision: 0.0000e+00\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2817 - precision: 0.0000e+00 - val_loss: 0.3031 - val_precision: 0.0000e+00\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2816 - precision: 0.0000e+00 - val_loss: 0.3031 - val_precision: 0.0000e+00\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2816 - precision: 0.0000e+00 - val_loss: 0.3031 - val_precision: 0.0000e+00\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2816 - precision: 0.0000e+00 - val_loss: 0.3031 - val_precision: 0.0000e+00\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2815 - precision: 0.0000e+00 - val_loss: 0.3030 - val_precision: 0.0000e+00\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2815 - precision: 0.0000e+00 - val_loss: 0.3030 - val_precision: 0.0000e+00\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2815 - precision: 0.0000e+00 - val_loss: 0.3029 - val_precision: 0.0000e+00\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2814 - precision: 0.0000e+00 - val_loss: 0.3029 - val_precision: 0.0000e+00\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2814 - precision: 0.0000e+00 - val_loss: 0.3028 - val_precision: 0.0000e+00\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2813 - precision: 0.0000e+00 - val_loss: 0.3028 - val_precision: 0.0000e+00\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2813 - precision: 0.0000e+00 - val_loss: 0.3028 - val_precision: 0.0000e+00\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2812 - precision: 0.0000e+00 - val_loss: 0.3027 - val_precision: 0.0000e+00\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2812 - precision: 0.0000e+00 - val_loss: 0.3026 - val_precision: 0.0000e+00\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2811 - precision: 0.0000e+00 - val_loss: 0.3025 - val_precision: 0.0000e+00\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2811 - precision: 0.0000e+00 - val_loss: 0.3024 - val_precision: 0.0000e+00\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2810 - precision: 0.0000e+00 - val_loss: 0.3023 - val_precision: 0.0000e+00\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2810 - precision: 0.0000e+00 - val_loss: 0.3022 - val_precision: 0.0000e+00\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2809 - precision: 0.0000e+00 - val_loss: 0.3022 - val_precision: 0.0000e+00\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2809 - precision: 0.0000e+00 - val_loss: 0.3022 - val_precision: 0.0000e+00\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2808 - precision: 0.0000e+00 - val_loss: 0.3021 - val_precision: 0.0000e+00\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2807 - precision: 0.0000e+00 - val_loss: 0.3021 - val_precision: 0.0000e+00\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.2806 - precision: 0.0000e+00 - val_loss: 0.3020 - val_precision: 0.0000e+00\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.2806 - precision: 0.0000e+00 - val_loss: 0.3019 - val_precision: 0.0000e+00\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.2806 - precision: 0.0000e+00 - val_loss: 0.3019 - val_precision: 0.0000e+00\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.2805 - precision: 0.0000e+00 - val_loss: 0.3019 - val_precision: 0.0000e+00\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2805 - precision: 0.0000e+00 - val_loss: 0.3018 - val_precision: 0.0000e+00\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2804 - precision: 0.0000e+00 - val_loss: 0.3017 - val_precision: 0.0000e+00\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2805 - precision: 0.0000e+00 - val_loss: 0.3017 - val_precision: 0.0000e+00\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2804 - precision: 0.0000e+00 - val_loss: 0.3016 - val_precision: 0.0000e+00\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2804 - precision: 0.0000e+00 - val_loss: 0.3016 - val_precision: 0.0000e+00\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2803 - precision: 0.0000e+00 - val_loss: 0.3016 - val_precision: 0.0000e+00\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2803 - precision: 0.0000e+00 - val_loss: 0.3015 - val_precision: 0.0000e+00\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2803 - precision: 0.0000e+00 - val_loss: 0.3015 - val_precision: 0.0000e+00\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2803 - precision: 0.0000e+00 - val_loss: 0.3014 - val_precision: 0.0000e+00\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2802 - precision: 0.0000e+00 - val_loss: 0.3014 - val_precision: 0.0000e+00\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2802 - precision: 0.0000e+00 - val_loss: 0.3013 - val_precision: 0.0000e+00\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2801 - precision: 0.0000e+00 - val_loss: 0.3013 - val_precision: 0.0000e+00\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2802 - precision: 0.0000e+00 - val_loss: 0.3012 - val_precision: 0.0000e+00\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.2801 - precision: 0.0000e+00 - val_loss: 0.3012 - val_precision: 0.0000e+00\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.2800 - precision: 0.0000e+00 - val_loss: 0.3012 - val_precision: 0.0000e+00\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2800 - precision: 0.0000e+00 - val_loss: 0.3012 - val_precision: 0.0000e+00\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2800 - precision: 0.0000e+00 - val_loss: 0.3011 - val_precision: 0.0000e+00\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2800 - precision: 0.0000e+00 - val_loss: 0.3011 - val_precision: 0.0000e+00\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2799 - precision: 0.0000e+00 - val_loss: 0.3011 - val_precision: 0.0000e+00\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2799 - precision: 0.0000e+00 - val_loss: 0.3010 - val_precision: 0.0000e+00\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2799 - precision: 0.0000e+00 - val_loss: 0.3010 - val_precision: 0.0000e+00\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2798 - precision: 0.0000e+00 - val_loss: 0.3010 - val_precision: 0.0000e+00\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2798 - precision: 0.0000e+00 - val_loss: 0.3009 - val_precision: 0.0000e+00\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.2799 - precision: 0.0000e+00 - val_loss: 0.3009 - val_precision: 0.0000e+00\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2798 - precision: 0.0000e+00 - val_loss: 0.3009 - val_precision: 0.0000e+00\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.2797 - precision: 0.0000e+00 - val_loss: 0.3008 - val_precision: 0.0000e+00\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2797 - precision: 0.0000e+00 - val_loss: 0.3008 - val_precision: 0.0000e+00\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2797 - precision: 0.0000e+00 - val_loss: 0.3008 - val_precision: 0.0000e+00\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2797 - precision: 0.0000e+00 - val_loss: 0.3007 - val_precision: 0.0000e+00\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2797 - precision: 0.0000e+00 - val_loss: 0.3007 - val_precision: 0.0000e+00\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2796 - precision: 0.0000e+00 - val_loss: 0.3007 - val_precision: 0.0000e+00\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2795 - precision: 0.0000e+00 - val_loss: 0.3007 - val_precision: 0.0000e+00\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2795 - precision: 0.0000e+00 - val_loss: 0.3007 - val_precision: 0.0000e+00\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2795 - precision: 0.0000e+00 - val_loss: 0.3006 - val_precision: 0.0000e+00\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2795 - precision: 0.0000e+00 - val_loss: 0.3006 - val_precision: 0.0000e+00\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2794 - precision: 0.0000e+00 - val_loss: 0.3006 - val_precision: 0.0000e+00\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2794 - precision: 0.0000e+00 - val_loss: 0.3006 - val_precision: 0.0000e+00\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2794 - precision: 0.0000e+00 - val_loss: 0.3005 - val_precision: 0.0000e+00\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2793 - precision: 0.0000e+00 - val_loss: 0.3005 - val_precision: 0.0000e+00\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2793 - precision: 0.0000e+00 - val_loss: 0.3005 - val_precision: 0.0000e+00\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2793 - precision: 0.0000e+00 - val_loss: 0.3004 - val_precision: 0.0000e+00\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2793 - precision: 0.0000e+00 - val_loss: 0.3004 - val_precision: 0.0000e+00\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2793 - precision: 0.0000e+00 - val_loss: 0.3004 - val_precision: 0.0000e+00\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2792 - precision: 0.0000e+00 - val_loss: 0.3004 - val_precision: 0.0000e+00\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2792 - precision: 0.0000e+00 - val_loss: 0.3003 - val_precision: 0.0000e+00\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2792 - precision: 0.0000e+00 - val_loss: 0.3003 - val_precision: 0.0000e+00\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.2791 - precision: 0.0000e+00 - val_loss: 0.3003 - val_precision: 0.0000e+00\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2790 - precision: 0.0000e+00 - val_loss: 0.3002 - val_precision: 0.0000e+00\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.2788 - precision: 0.0000e+00 - val_loss: 0.3002 - val_precision: 0.0000e+00\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2789 - precision: 0.0000e+00 - val_loss: 0.3002 - val_precision: 0.0000e+00\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.2789 - precision: 0.0000e+00 - val_loss: 0.3001 - val_precision: 0.0000e+00\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.2789 - precision: 0.0000e+00 - val_loss: 0.3001 - val_precision: 0.0000e+00\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2789 - precision: 0.0000e+00 - val_loss: 0.3001 - val_precision: 0.0000e+00\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2788 - precision: 0.0000e+00 - val_loss: 0.3001 - val_precision: 0.0000e+00\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.2788 - precision: 0.0000e+00 - val_loss: 0.3000 - val_precision: 0.0000e+00\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.2788 - precision: 0.0000e+00 - val_loss: 0.3000 - val_precision: 0.0000e+00\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2788 - precision: 0.0000e+00 - val_loss: 0.3000 - val_precision: 0.0000e+00\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2787 - precision: 0.0000e+00 - val_loss: 0.3000 - val_precision: 0.0000e+00\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2787 - precision: 0.0000e+00 - val_loss: 0.3000 - val_precision: 0.0000e+00\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2786 - precision: 0.0000e+00 - val_loss: 0.3000 - val_precision: 0.0000e+00\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2786 - precision: 0.0000e+00 - val_loss: 0.3000 - val_precision: 0.0000e+00\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.2786 - precision: 0.0000e+00 - val_loss: 0.2999 - val_precision: 0.0000e+00\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2786 - precision: 0.0000e+00 - val_loss: 0.2999 - val_precision: 0.0000e+00\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2785 - precision: 0.0000e+00 - val_loss: 0.2998 - val_precision: 0.0000e+00\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2785 - precision: 0.0000e+00 - val_loss: 0.2998 - val_precision: 0.0000e+00\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2785 - precision: 0.0000e+00 - val_loss: 0.2998 - val_precision: 0.0000e+00\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2784 - precision: 0.0000e+00 - val_loss: 0.2997 - val_precision: 0.0000e+00\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2785 - precision: 0.0000e+00 - val_loss: 0.2997 - val_precision: 0.0000e+00\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2784 - precision: 0.0000e+00 - val_loss: 0.2997 - val_precision: 0.0000e+00\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2785 - precision: 0.0000e+00 - val_loss: 0.2997 - val_precision: 0.0000e+00\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2783 - precision: 0.0000e+00 - val_loss: 0.2997 - val_precision: 0.0000e+00\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2783 - precision: 0.0000e+00 - val_loss: 0.2997 - val_precision: 0.0000e+00\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2783 - precision: 0.0000e+00 - val_loss: 0.2997 - val_precision: 0.0000e+00\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2783 - precision: 0.0000e+00 - val_loss: 0.2996 - val_precision: 0.0000e+00\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2782 - precision: 0.0000e+00 - val_loss: 0.2996 - val_precision: 0.0000e+00\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2783 - precision: 0.0000e+00 - val_loss: 0.2996 - val_precision: 0.0000e+00\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2782 - precision: 0.0000e+00 - val_loss: 0.2996 - val_precision: 0.0000e+00\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2782 - precision: 0.0000e+00 - val_loss: 0.2995 - val_precision: 0.0000e+00\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2782 - precision: 0.0000e+00 - val_loss: 0.2995 - val_precision: 0.0000e+00\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2781 - precision: 0.0000e+00 - val_loss: 0.2995 - val_precision: 0.0000e+00\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2781 - precision: 0.0000e+00 - val_loss: 0.2994 - val_precision: 0.0000e+00\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2781 - precision: 0.0000e+00 - val_loss: 0.2994 - val_precision: 0.0000e+00\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2781 - precision: 0.0000e+00 - val_loss: 0.2994 - val_precision: 0.0000e+00\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2781 - precision: 0.0000e+00 - val_loss: 0.2994 - val_precision: 0.0000e+00\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.2781 - precision: 0.0000e+00 - val_loss: 0.2994 - val_precision: 0.0000e+00\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2780 - precision: 0.0000e+00 - val_loss: 0.2993 - val_precision: 0.0000e+00\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2780 - precision: 0.0000e+00 - val_loss: 0.2993 - val_precision: 0.0000e+00\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2779 - precision: 0.0000e+00 - val_loss: 0.2993 - val_precision: 0.0000e+00\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2779 - precision: 0.0000e+00 - val_loss: 0.2993 - val_precision: 0.0000e+00\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2779 - precision: 0.0000e+00 - val_loss: 0.2993 - val_precision: 0.0000e+00\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2780 - precision: 0.0000e+00 - val_loss: 0.2993 - val_precision: 0.0000e+00\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2779 - precision: 0.0000e+00 - val_loss: 0.2993 - val_precision: 0.0000e+00\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2779 - precision: 0.0000e+00 - val_loss: 0.2992 - val_precision: 0.0000e+00\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2779 - precision: 0.0000e+00 - val_loss: 0.2992 - val_precision: 0.0000e+00\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2778 - precision: 0.0000e+00 - val_loss: 0.2992 - val_precision: 0.0000e+00\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2780 - precision: 0.0000e+00 - val_loss: 0.2992 - val_precision: 0.0000e+00\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2779 - precision: 0.0000e+00 - val_loss: 0.2992 - val_precision: 0.0000e+00\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2778 - precision: 0.0000e+00 - val_loss: 0.2992 - val_precision: 0.0000e+00\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2777 - precision: 0.0000e+00 - val_loss: 0.2992 - val_precision: 0.0000e+00\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2778 - precision: 0.0000e+00 - val_loss: 0.2992 - val_precision: 0.0000e+00\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2777 - precision: 0.0000e+00 - val_loss: 0.2991 - val_precision: 0.0000e+00\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2778 - precision: 0.0000e+00 - val_loss: 0.2992 - val_precision: 0.0000e+00\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2778 - precision: 0.0000e+00 - val_loss: 0.2992 - val_precision: 0.0000e+00\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2778 - precision: 0.0000e+00 - val_loss: 0.2991 - val_precision: 0.0000e+00\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2777 - precision: 0.0000e+00 - val_loss: 0.2991 - val_precision: 0.0000e+00\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2776 - precision: 0.0000e+00 - val_loss: 0.2991 - val_precision: 0.0000e+00\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2777 - precision: 0.0000e+00 - val_loss: 0.2990 - val_precision: 0.0000e+00\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2776 - precision: 0.0000e+00 - val_loss: 0.2990 - val_precision: 0.0000e+00\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2776 - precision: 0.0000e+00 - val_loss: 0.2990 - val_precision: 0.0000e+00\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2775 - precision: 0.0000e+00 - val_loss: 0.2990 - val_precision: 0.0000e+00\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2775 - precision: 0.0000e+00 - val_loss: 0.2990 - val_precision: 0.0000e+00\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2775 - precision: 0.0000e+00 - val_loss: 0.2990 - val_precision: 0.0000e+00\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2777 - precision: 0.0000e+00 - val_loss: 0.2989 - val_precision: 0.0000e+00\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2775 - precision: 0.0000e+00 - val_loss: 0.2989 - val_precision: 0.0000e+00\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2775 - precision: 0.0000e+00 - val_loss: 0.2989 - val_precision: 0.0000e+00\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2775 - precision: 0.0000e+00 - val_loss: 0.2989 - val_precision: 0.0000e+00\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2775 - precision: 0.0000e+00 - val_loss: 0.2989 - val_precision: 0.0000e+00\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2774 - precision: 0.0000e+00 - val_loss: 0.2989 - val_precision: 0.0000e+00\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2774 - precision: 0.0000e+00 - val_loss: 0.2988 - val_precision: 0.0000e+00\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2774 - precision: 0.0000e+00 - val_loss: 0.2988 - val_precision: 0.0000e+00\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2774 - precision: 0.0000e+00 - val_loss: 0.2988 - val_precision: 0.0000e+00\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2775 - precision: 0.0000e+00 - val_loss: 0.2988 - val_precision: 0.0000e+00\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2774 - precision: 0.0000e+00 - val_loss: 0.2988 - val_precision: 0.0000e+00\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2774 - precision: 0.0000e+00 - val_loss: 0.2988 - val_precision: 0.0000e+00\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2774 - precision: 0.0000e+00 - val_loss: 0.2988 - val_precision: 0.0000e+00\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2774 - precision: 0.0000e+00 - val_loss: 0.2988 - val_precision: 0.0000e+00\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2773 - precision: 0.0000e+00 - val_loss: 0.2987 - val_precision: 0.0000e+00\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2773 - precision: 0.0000e+00 - val_loss: 0.2987 - val_precision: 0.0000e+00\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2773 - precision: 0.0000e+00 - val_loss: 0.2987 - val_precision: 0.0000e+00\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2773 - precision: 0.0000e+00 - val_loss: 0.2987 - val_precision: 0.0000e+00\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2773 - precision: 0.0000e+00 - val_loss: 0.2987 - val_precision: 0.0000e+00\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2772 - precision: 0.0000e+00 - val_loss: 0.2987 - val_precision: 0.0000e+00\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2772 - precision: 0.0000e+00 - val_loss: 0.2986 - val_precision: 0.0000e+00\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2777 - precision: 0.0000e+00 - val_loss: 0.2986 - val_precision: 0.0000e+00\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2771 - precision: 0.0000e+00 - val_loss: 0.2986 - val_precision: 0.0000e+00\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2771 - precision: 0.0000e+00 - val_loss: 0.2986 - val_precision: 0.0000e+00\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2771 - precision: 0.0000e+00 - val_loss: 0.2986 - val_precision: 0.0000e+00\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.2771 - precision: 0.0000e+00 - val_loss: 0.2986 - val_precision: 0.0000e+00\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.2771 - precision: 0.0000e+00 - val_loss: 0.2985 - val_precision: 0.0000e+00\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2771 - precision: 0.0000e+00 - val_loss: 0.2985 - val_precision: 0.0000e+00\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2771 - precision: 0.0000e+00 - val_loss: 0.2985 - val_precision: 0.0000e+00\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2770 - precision: 0.0000e+00 - val_loss: 0.2985 - val_precision: 0.0000e+00\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.2770 - precision: 0.0000e+00 - val_loss: 0.2985 - val_precision: 0.0000e+00\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.2771 - precision: 0.0000e+00 - val_loss: 0.2985 - val_precision: 0.0000e+00\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.2771 - precision: 0.0000e+00 - val_loss: 0.2985 - val_precision: 0.0000e+00\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2771 - precision: 0.0000e+00 - val_loss: 0.2985 - val_precision: 0.0000e+00\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.2771 - precision: 0.0000e+00 - val_loss: 0.2985 - val_precision: 0.0000e+00\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2771 - precision: 0.0000e+00 - val_loss: 0.2985 - val_precision: 0.0000e+00\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2769 - precision: 0.0000e+00 - val_loss: 0.2984 - val_precision: 0.0000e+00\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.2769 - precision: 0.0000e+00 - val_loss: 0.2984 - val_precision: 0.0000e+00\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.2769 - precision: 0.0000e+00 - val_loss: 0.2984 - val_precision: 0.0000e+00\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.2770 - precision: 0.0000e+00 - val_loss: 0.2984 - val_precision: 0.0000e+00\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2769 - precision: 0.0000e+00 - val_loss: 0.2984 - val_precision: 0.0000e+00\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2769 - precision: 0.0000e+00 - val_loss: 0.2984 - val_precision: 0.0000e+00\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2769 - precision: 0.0000e+00 - val_loss: 0.2984 - val_precision: 0.0000e+00\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2769 - precision: 0.0000e+00 - val_loss: 0.2983 - val_precision: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300\n",
    "history = modela_zb.fit(padded, training_labels_final, \n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(val_padded, val_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "EcgW_tGkND2e",
    "outputId": "0a03b457-f792-4def-ecad-b7d5d30d0ab2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "precision = history.history['precision']\n",
    "val_precision = history.history['val_precision']\n",
    "epochs=range(len(precision))\n",
    "plt.plot(epochs, precision, 'r')\n",
    "plt.plot(epochs, val_precision, 'b')\n",
    "plt.title('Training and validation Precision')\n",
    "plt.ylim((0,1.5))\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "b4Wzq8OXND2h",
    "outputId": "9f67441b-f341-4d0d-ed1c-9b0acdd9cc3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3808 - precision: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38075533509254456, 0.0]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modela_zb.evaluate(test_padded, test_labels_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mymobnWsND2n"
   },
   "source": [
    "### Model B with the Z&B embeddings\n",
    "\n",
    "Adds a conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "LDCmEmpnND2n"
   },
   "outputs": [],
   "source": [
    "\n",
    "modelb_zb = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], input_length = max_length, trainable=False),\n",
    "    tf.keras.layers.Conv1D(128, 5, activation=\"relu\"),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "n99gc3pzND2o"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "modelb_zb.compile(loss='binary_crossentropy', \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "13YrvnoYND2o",
    "outputId": "e5c0778c-a58e-47b6-b0c7-9c94a5c43baa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1200, 300)         1500600   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 1196, 128)         192128    \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 774       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,693,509\n",
      "Trainable params: 192,909\n",
      "Non-trainable params: 1,500,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelb_zb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "avKnzHzRND2o",
    "outputId": "1c0de298-908e-4c08-99e4-36d0d3499873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 2s 212ms/step - loss: 0.6439 - precision: 0.0000e+00 - val_loss: 0.5931 - val_precision: 0.0000e+00\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 2s 187ms/step - loss: 0.5269 - precision: 0.0000e+00 - val_loss: 0.4964 - val_precision: 0.0000e+00\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 2s 214ms/step - loss: 0.4305 - precision: 0.0000e+00 - val_loss: 0.4243 - val_precision: 0.0000e+00\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 2s 250ms/step - loss: 0.3668 - precision: 0.0000e+00 - val_loss: 0.3811 - val_precision: 0.0000e+00\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 2s 218ms/step - loss: 0.3382 - precision: 0.0000e+00 - val_loss: 0.3579 - val_precision: 0.0000e+00\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 2s 178ms/step - loss: 0.3244 - precision: 0.0000e+00 - val_loss: 0.3483 - val_precision: 0.0000e+00\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 2s 190ms/step - loss: 0.3181 - precision: 0.0000e+00 - val_loss: 0.3428 - val_precision: 0.0000e+00\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 2s 196ms/step - loss: 0.3154 - precision: 0.0000e+00 - val_loss: 0.3397 - val_precision: 0.0000e+00\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 2s 201ms/step - loss: 0.3138 - precision: 0.0000e+00 - val_loss: 0.3374 - val_precision: 0.0000e+00\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.3135 - precision: 0.0000e+00 - val_loss: 0.3374 - val_precision: 0.0000e+00\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 2s 215ms/step - loss: 0.3100 - precision: 0.0000e+00 - val_loss: 0.3348 - val_precision: 0.0000e+00\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 2s 196ms/step - loss: 0.3082 - precision: 0.0000e+00 - val_loss: 0.3341 - val_precision: 0.0000e+00\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 2s 202ms/step - loss: 0.3063 - precision: 0.0000e+00 - val_loss: 0.3317 - val_precision: 0.0000e+00\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 2s 262ms/step - loss: 0.3038 - precision: 0.0000e+00 - val_loss: 0.3281 - val_precision: 0.0000e+00\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 2s 213ms/step - loss: 0.3015 - precision: 0.0000e+00 - val_loss: 0.3253 - val_precision: 0.0000e+00\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 2s 213ms/step - loss: 0.2992 - precision: 0.0000e+00 - val_loss: 0.3225 - val_precision: 0.0000e+00\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 2s 183ms/step - loss: 0.2972 - precision: 0.0000e+00 - val_loss: 0.3197 - val_precision: 0.0000e+00\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 2s 200ms/step - loss: 0.2958 - precision: 0.0000e+00 - val_loss: 0.3176 - val_precision: 0.0000e+00\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 2s 193ms/step - loss: 0.2940 - precision: 0.0000e+00 - val_loss: 0.3157 - val_precision: 0.0000e+00\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.2907 - precision: 0.0000e+00 - val_loss: 0.3140 - val_precision: 0.0000e+00\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 2s 203ms/step - loss: 0.2895 - precision: 0.0000e+00 - val_loss: 0.3125 - val_precision: 0.0000e+00\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 2s 211ms/step - loss: 0.2875 - precision: 0.0000e+00 - val_loss: 0.3103 - val_precision: 0.0000e+00\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 2s 208ms/step - loss: 0.2859 - precision: 0.0000e+00 - val_loss: 0.3084 - val_precision: 0.0000e+00\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 2s 189ms/step - loss: 0.2843 - precision: 0.0000e+00 - val_loss: 0.3074 - val_precision: 0.0000e+00\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 2s 192ms/step - loss: 0.2816 - precision: 0.0000e+00 - val_loss: 0.3075 - val_precision: 0.0000e+00\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 2s 192ms/step - loss: 0.2831 - precision: 0.0000e+00 - val_loss: 0.3076 - val_precision: 0.0000e+00\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 2s 187ms/step - loss: 0.2817 - precision: 0.0000e+00 - val_loss: 0.3050 - val_precision: 0.0000e+00\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 2s 198ms/step - loss: 0.2817 - precision: 0.0000e+00 - val_loss: 0.3027 - val_precision: 0.0000e+00\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.2795 - precision: 0.0000e+00 - val_loss: 0.3018 - val_precision: 0.0000e+00\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 2s 180ms/step - loss: 0.2786 - precision: 0.0000e+00 - val_loss: 0.3011 - val_precision: 0.0000e+00\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 2s 223ms/step - loss: 0.2776 - precision: 0.0000e+00 - val_loss: 0.3002 - val_precision: 0.0000e+00\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.2785 - precision: 0.0000e+00 - val_loss: 0.3001 - val_precision: 0.0000e+00\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 2s 212ms/step - loss: 0.2758 - precision: 0.0000e+00 - val_loss: 0.2995 - val_precision: 0.0000e+00\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 2s 214ms/step - loss: 0.2750 - precision: 0.0000e+00 - val_loss: 0.2987 - val_precision: 0.0000e+00\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 2s 187ms/step - loss: 0.2749 - precision: 0.0000e+00 - val_loss: 0.2983 - val_precision: 0.0000e+00\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 2s 178ms/step - loss: 0.2751 - precision: 0.0000e+00 - val_loss: 0.2976 - val_precision: 0.0000e+00\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 2s 197ms/step - loss: 0.2738 - precision: 0.0000e+00 - val_loss: 0.2973 - val_precision: 0.0000e+00\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 2s 194ms/step - loss: 0.2737 - precision: 0.0000e+00 - val_loss: 0.2970 - val_precision: 0.0000e+00\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.2729 - precision: 0.0000e+00 - val_loss: 0.2969 - val_precision: 0.0000e+00\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 2s 215ms/step - loss: 0.2731 - precision: 0.0000e+00 - val_loss: 0.2988 - val_precision: 0.0000e+00\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 2s 189ms/step - loss: 0.2736 - precision: 0.0000e+00 - val_loss: 0.2971 - val_precision: 0.0000e+00\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 2s 183ms/step - loss: 0.2729 - precision: 0.0000e+00 - val_loss: 0.2967 - val_precision: 0.0000e+00\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 2s 191ms/step - loss: 0.2716 - precision: 0.0000e+00 - val_loss: 0.2957 - val_precision: 0.0000e+00\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 2s 192ms/step - loss: 0.2712 - precision: 0.0000e+00 - val_loss: 0.2951 - val_precision: 0.0000e+00\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 2s 213ms/step - loss: 0.2711 - precision: 0.0000e+00 - val_loss: 0.2962 - val_precision: 0.0000e+00\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 2s 252ms/step - loss: 0.2720 - precision: 0.0000e+00 - val_loss: 0.2953 - val_precision: 0.0000e+00\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 3s 330ms/step - loss: 0.2695 - precision: 0.0000e+00 - val_loss: 0.2944 - val_precision: 0.0000e+00\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 2s 265ms/step - loss: 0.2692 - precision: 0.0000e+00 - val_loss: 0.2949 - val_precision: 0.0000e+00\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 2s 212ms/step - loss: 0.2709 - precision: 0.0000e+00 - val_loss: 0.2956 - val_precision: 0.0000e+00\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 2s 217ms/step - loss: 0.2708 - precision: 0.0000e+00 - val_loss: 0.2950 - val_precision: 0.0000e+00\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 2s 224ms/step - loss: 0.2697 - precision: 0.0000e+00 - val_loss: 0.2943 - val_precision: 0.0000e+00\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 2s 189ms/step - loss: 0.2691 - precision: 0.0000e+00 - val_loss: 0.2940 - val_precision: 0.0000e+00\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 2s 211ms/step - loss: 0.2683 - precision: 0.0000e+00 - val_loss: 0.2938 - val_precision: 0.0000e+00\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.2681 - precision: 0.0000e+00 - val_loss: 0.2936 - val_precision: 0.0000e+00\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 2s 216ms/step - loss: 0.2680 - precision: 0.0000e+00 - val_loss: 0.2936 - val_precision: 0.0000e+00\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 2s 225ms/step - loss: 0.2684 - precision: 0.0000e+00 - val_loss: 0.2934 - val_precision: 0.0000e+00\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 2s 193ms/step - loss: 0.2679 - precision: 0.0000e+00 - val_loss: 0.2933 - val_precision: 0.0000e+00\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 0.2673 - precision: 0.0000e+00 - val_loss: 0.2931 - val_precision: 0.0000e+00\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 2s 198ms/step - loss: 0.2676 - precision: 0.0000e+00 - val_loss: 0.2936 - val_precision: 0.0000e+00\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 2s 214ms/step - loss: 0.2672 - precision: 0.0000e+00 - val_loss: 0.2933 - val_precision: 0.0000e+00\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 2s 200ms/step - loss: 0.2669 - precision: 0.0000e+00 - val_loss: 0.2929 - val_precision: 0.0000e+00\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 2s 198ms/step - loss: 0.2666 - precision: 0.0000e+00 - val_loss: 0.2930 - val_precision: 0.0000e+00\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 2s 239ms/step - loss: 0.2654 - precision: 0.0000e+00 - val_loss: 0.2926 - val_precision: 0.0000e+00\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 2s 226ms/step - loss: 0.2652 - precision: 0.0000e+00 - val_loss: 0.2925 - val_precision: 0.0000e+00\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 2s 201ms/step - loss: 0.2651 - precision: 0.0000e+00 - val_loss: 0.2925 - val_precision: 0.0000e+00\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 2s 198ms/step - loss: 0.2655 - precision: 0.0000e+00 - val_loss: 0.2923 - val_precision: 0.0000e+00\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.2651 - precision: 0.0000e+00 - val_loss: 0.2924 - val_precision: 0.0000e+00\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 2s 192ms/step - loss: 0.2641 - precision: 0.0000e+00 - val_loss: 0.2924 - val_precision: 0.0000e+00\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 2s 215ms/step - loss: 0.2641 - precision: 0.0000e+00 - val_loss: 0.2921 - val_precision: 0.0000e+00\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 2s 180ms/step - loss: 0.2652 - precision: 0.0000e+00 - val_loss: 0.2934 - val_precision: 0.0000e+00\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 2s 226ms/step - loss: 0.2632 - precision: 0.0000e+00 - val_loss: 0.2916 - val_precision: 0.0000e+00\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 2s 213ms/step - loss: 0.2621 - precision: 0.0000e+00 - val_loss: 0.2917 - val_precision: 0.0000e+00\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 2s 223ms/step - loss: 0.2642 - precision: 0.0000e+00 - val_loss: 0.2922 - val_precision: 0.0000e+00\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 2s 199ms/step - loss: 0.2632 - precision: 0.0000e+00 - val_loss: 0.2911 - val_precision: 0.0000e+00\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 2s 205ms/step - loss: 0.2619 - precision: 0.0000e+00 - val_loss: 0.2910 - val_precision: 0.0000e+00\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 2s 192ms/step - loss: 0.2645 - precision: 0.0000e+00 - val_loss: 0.2944 - val_precision: 0.0000e+00\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 2s 188ms/step - loss: 0.2701 - precision: 0.0000e+00 - val_loss: 0.2961 - val_precision: 0.0000e+00\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 2s 193ms/step - loss: 0.2620 - precision: 0.0000e+00 - val_loss: 0.2908 - val_precision: 0.0000e+00\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 2s 204ms/step - loss: 0.2620 - precision: 0.0000e+00 - val_loss: 0.2922 - val_precision: 0.0000e+00\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 2s 220ms/step - loss: 0.2620 - precision: 0.0000e+00 - val_loss: 0.2906 - val_precision: 0.0000e+00\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 2s 211ms/step - loss: 0.2598 - precision: 0.0000e+00 - val_loss: 0.2905 - val_precision: 0.0000e+00\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.2595 - precision: 0.0000e+00 - val_loss: 0.2918 - val_precision: 0.0000e+00\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 2s 197ms/step - loss: 0.2601 - precision: 0.0000e+00 - val_loss: 0.2906 - val_precision: 0.0000e+00\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 2s 194ms/step - loss: 0.2594 - precision: 0.0000e+00 - val_loss: 0.2906 - val_precision: 0.0000e+00\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 2s 187ms/step - loss: 0.2595 - precision: 0.0000e+00 - val_loss: 0.2915 - val_precision: 0.0000e+00\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 2s 196ms/step - loss: 0.2591 - precision: 0.0000e+00 - val_loss: 0.2905 - val_precision: 0.0000e+00\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 2s 196ms/step - loss: 0.2591 - precision: 0.0000e+00 - val_loss: 0.2903 - val_precision: 0.0000e+00\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 2s 219ms/step - loss: 0.2591 - precision: 0.0000e+00 - val_loss: 0.2942 - val_precision: 0.0000e+00\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 2s 208ms/step - loss: 0.2624 - precision: 0.0000e+00 - val_loss: 0.2943 - val_precision: 0.0000e+00\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 2s 201ms/step - loss: 0.2596 - precision: 0.0000e+00 - val_loss: 0.2899 - val_precision: 0.0000e+00\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.2568 - precision: 0.0000e+00 - val_loss: 0.2898 - val_precision: 0.0000e+00\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 2s 202ms/step - loss: 0.2566 - precision: 0.0000e+00 - val_loss: 0.2901 - val_precision: 0.0000e+00\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 2s 188ms/step - loss: 0.2590 - precision: 0.0000e+00 - val_loss: 0.2930 - val_precision: 0.0000e+00\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 2s 190ms/step - loss: 0.2574 - precision: 0.0000e+00 - val_loss: 0.2901 - val_precision: 0.0000e+00\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 2s 180ms/step - loss: 0.2564 - precision: 0.0000e+00 - val_loss: 0.2895 - val_precision: 0.0000e+00\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 2s 193ms/step - loss: 0.2560 - precision: 0.0000e+00 - val_loss: 0.2890 - val_precision: 0.0000e+00\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 2s 214ms/step - loss: 0.2565 - precision: 0.0000e+00 - val_loss: 0.2913 - val_precision: 0.0000e+00\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 2s 215ms/step - loss: 0.2561 - precision: 0.0000e+00 - val_loss: 0.2887 - val_precision: 0.0000e+00\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 2s 217ms/step - loss: 0.2543 - precision: 0.0000e+00 - val_loss: 0.2882 - val_precision: 0.0000e+00\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 2s 211ms/step - loss: 0.2537 - precision: 0.0000e+00 - val_loss: 0.2882 - val_precision: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100 \n",
    "history = modelb_zb.fit(padded, training_labels_final, \n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(val_padded, val_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "B5Dqph9aND2p",
    "outputId": "9acfa2e2-868a-41f9-fa0a-b2ed4edd2ee1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "precision = history.history['precision']\n",
    "val_precision = history.history['val_precision']\n",
    "epochs=range(len(precision))\n",
    "plt.plot(epochs, precision, 'r')\n",
    "plt.plot(epochs, val_precision, 'b')\n",
    "plt.title('Training and validation Precision')\n",
    "plt.ylim((0,1.5))\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "Bo7PpA5jND2p",
    "outputId": "29b58a0f-1951-4227-a07f-69a3c1b2e720"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 57ms/step - loss: 0.3720 - precision: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3719780445098877, 0.0]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelb_zb.evaluate(test_padded, test_labels_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3mtKEPMA4o5"
   },
   "source": [
    "# Part III.  GloVE Embeddings\n",
    "\n",
    "After downloading Glove, we adapt our code to use it.  GloVE contains 400,000 tokens and comes with a variety of embedding dims.  We chose the smallest - 50 features per token.\n",
    "\n",
    "All but 45 words in our vocab were in GloVE.  The \"misses\" tended to be words with apostrophes, abbrevaitions and compound words (later we will clean our data to better match the pre-trained embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "cgdOOCOvA42C"
   },
   "outputs": [],
   "source": [
    "#file = pd.read_table('glove.6B.50d.txt') # okay this one may be too big - using 50 from now on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mk-BciFfgX9G",
    "outputId": "4eab497b-511c-4c1f-dfd6-d9a78d469616"
   },
   "outputs": [],
   "source": [
    "#!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "#!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xDgozhp9ND2q",
    "outputId": "512b9bad-67b0-4e1f-e0c3-924eb7735edf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('glove.6B.50d.txt', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g7j6F9IMND2q",
    "outputId": "26989fe0-e338-4fba-f767-528de175bf13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<OOV>\n",
      "today's\n",
      "committee's\n",
      "pepp\n",
      "tltro\n",
      "council's\n",
      "href\n",
      "reserve's\n",
      "covid\n",
      "pressconf\n",
      "eurosystem's\n",
      "ecb's\n",
      "regardingnon\n",
      "banks’\n",
      "peltros\n",
      "eurep\n",
      "households'\n",
      "bankofengland\n",
      "federalreserve\n",
      "optionality\n",
      "ltros\n",
      "tltros\n",
      "counterparties’\n",
      "10basis\n",
      "december2015\n",
      "4percent\n",
      "overbidding\n",
      "2818\n",
      "is000608\n",
      "tomaintain\n",
      " \n",
      "is010830\n",
      "is000302\n",
      "is001214\n",
      "is010201\n",
      "russia's\n",
      "board's\n",
      "summer's\n",
      "is020606\n",
      "actionsthe\n",
      "banksinformation\n",
      "is010510\n",
      "is000706\n",
      "peltro\n",
      "4½\n",
      "Converted 1878 words (45 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(range(vocab_size)) + 2 #vocab size was specified in Part I\n",
    "embedding_dim = 50 #we chose the 50-dim embedding of GloVE\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix. This matrix matches OUR vocabulary to the ELEMENTS in GloVE.\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "        #print(word, end =\"\")\n",
    "        print(word)\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "uTNAL0geND2r"
   },
   "outputs": [],
   "source": [
    "\n",
    "modela_glove = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], input_length = max_length, trainable=False),  \n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "ut_FfOsYND2r"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "modela_glove.compile(loss='binary_crossentropy', \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LlDbeiuoND2s",
    "outputId": "2738ffcb-7ced-4158-a43c-e76462195b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1200, 50)          250100    \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 50)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 306       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 250,413\n",
      "Trainable params: 313\n",
      "Non-trainable params: 250,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modela_glove.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IHSAeOJGND2s",
    "outputId": "e04b22e8-79de-4fcc-ccc1-184c8e349255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 1s 28ms/step - loss: 0.7109 - precision: 0.1061 - val_loss: 0.6929 - val_precision: 0.0741\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6822 - precision: 0.0444 - val_loss: 0.6691 - val_precision: 0.0000e+00\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6564 - precision: 0.0000e+00 - val_loss: 0.6477 - val_precision: 0.0000e+00\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6324 - precision: 0.0000e+00 - val_loss: 0.6286 - val_precision: 0.0000e+00\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6113 - precision: 0.0000e+00 - val_loss: 0.6111 - val_precision: 0.0000e+00\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5921 - precision: 0.0000e+00 - val_loss: 0.5945 - val_precision: 0.0000e+00\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5734 - precision: 0.0000e+00 - val_loss: 0.5785 - val_precision: 0.0000e+00\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5559 - precision: 0.0000e+00 - val_loss: 0.5637 - val_precision: 0.0000e+00\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5397 - precision: 0.0000e+00 - val_loss: 0.5500 - val_precision: 0.0000e+00\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5251 - precision: 0.0000e+00 - val_loss: 0.5375 - val_precision: 0.0000e+00\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5115 - precision: 0.0000e+00 - val_loss: 0.5246 - val_precision: 0.0000e+00\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4977 - precision: 0.0000e+00 - val_loss: 0.5125 - val_precision: 0.0000e+00\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4846 - precision: 0.0000e+00 - val_loss: 0.5007 - val_precision: 0.0000e+00\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4718 - precision: 0.0000e+00 - val_loss: 0.4891 - val_precision: 0.0000e+00\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4595 - precision: 0.0000e+00 - val_loss: 0.4782 - val_precision: 0.0000e+00\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4478 - precision: 0.0000e+00 - val_loss: 0.4675 - val_precision: 0.0000e+00\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4366 - precision: 0.0000e+00 - val_loss: 0.4573 - val_precision: 0.0000e+00\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4261 - precision: 0.0000e+00 - val_loss: 0.4475 - val_precision: 0.0000e+00\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4161 - precision: 0.0000e+00 - val_loss: 0.4382 - val_precision: 0.0000e+00\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4069 - precision: 0.0000e+00 - val_loss: 0.4300 - val_precision: 0.0000e+00\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3982 - precision: 0.0000e+00 - val_loss: 0.4221 - val_precision: 0.0000e+00\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3902 - precision: 0.0000e+00 - val_loss: 0.4144 - val_precision: 0.0000e+00\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3824 - precision: 0.0000e+00 - val_loss: 0.4071 - val_precision: 0.0000e+00\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3754 - precision: 0.0000e+00 - val_loss: 0.4007 - val_precision: 0.0000e+00\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3693 - precision: 0.0000e+00 - val_loss: 0.3950 - val_precision: 0.0000e+00\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3634 - precision: 0.0000e+00 - val_loss: 0.3897 - val_precision: 0.0000e+00\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3579 - precision: 0.0000e+00 - val_loss: 0.3843 - val_precision: 0.0000e+00\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3528 - precision: 0.0000e+00 - val_loss: 0.3788 - val_precision: 0.0000e+00\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3473 - precision: 0.0000e+00 - val_loss: 0.3738 - val_precision: 0.0000e+00\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3425 - precision: 0.0000e+00 - val_loss: 0.3690 - val_precision: 0.0000e+00\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3378 - precision: 0.0000e+00 - val_loss: 0.3646 - val_precision: 0.0000e+00\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3335 - precision: 0.0000e+00 - val_loss: 0.3610 - val_precision: 0.0000e+00\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3301 - precision: 0.0000e+00 - val_loss: 0.3574 - val_precision: 0.0000e+00\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3266 - precision: 0.0000e+00 - val_loss: 0.3538 - val_precision: 0.0000e+00\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3233 - precision: 0.0000e+00 - val_loss: 0.3504 - val_precision: 0.0000e+00\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3199 - precision: 0.0000e+00 - val_loss: 0.3474 - val_precision: 0.0000e+00\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3175 - precision: 0.0000e+00 - val_loss: 0.3447 - val_precision: 0.0000e+00\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3147 - precision: 0.0000e+00 - val_loss: 0.3422 - val_precision: 0.0000e+00\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3127 - precision: 0.0000e+00 - val_loss: 0.3399 - val_precision: 0.0000e+00\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3107 - precision: 0.0000e+00 - val_loss: 0.3382 - val_precision: 0.0000e+00\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3090 - precision: 0.0000e+00 - val_loss: 0.3362 - val_precision: 0.0000e+00\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3076 - precision: 0.0000e+00 - val_loss: 0.3345 - val_precision: 0.0000e+00\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3057 - precision: 0.0000e+00 - val_loss: 0.3328 - val_precision: 0.0000e+00\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3041 - precision: 0.0000e+00 - val_loss: 0.3310 - val_precision: 0.0000e+00\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3027 - precision: 0.0000e+00 - val_loss: 0.3298 - val_precision: 0.0000e+00\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3013 - precision: 0.0000e+00 - val_loss: 0.3283 - val_precision: 0.0000e+00\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2999 - precision: 0.0000e+00 - val_loss: 0.3267 - val_precision: 0.0000e+00\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2985 - precision: 0.0000e+00 - val_loss: 0.3251 - val_precision: 0.0000e+00\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2973 - precision: 0.0000e+00 - val_loss: 0.3236 - val_precision: 0.0000e+00\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2960 - precision: 0.0000e+00 - val_loss: 0.3222 - val_precision: 0.0000e+00\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2949 - precision: 0.0000e+00 - val_loss: 0.3210 - val_precision: 0.0000e+00\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2936 - precision: 0.0000e+00 - val_loss: 0.3199 - val_precision: 0.0000e+00\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2927 - precision: 0.0000e+00 - val_loss: 0.3189 - val_precision: 0.0000e+00\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2919 - precision: 0.0000e+00 - val_loss: 0.3180 - val_precision: 0.0000e+00\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2913 - precision: 0.0000e+00 - val_loss: 0.3172 - val_precision: 0.0000e+00\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2905 - precision: 0.0000e+00 - val_loss: 0.3164 - val_precision: 0.0000e+00\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2899 - precision: 0.0000e+00 - val_loss: 0.3159 - val_precision: 0.0000e+00\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2893 - precision: 0.0000e+00 - val_loss: 0.3152 - val_precision: 0.0000e+00\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2888 - precision: 0.0000e+00 - val_loss: 0.3146 - val_precision: 0.0000e+00\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2882 - precision: 0.0000e+00 - val_loss: 0.3140 - val_precision: 0.0000e+00\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2878 - precision: 0.0000e+00 - val_loss: 0.3133 - val_precision: 0.0000e+00\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2873 - precision: 0.0000e+00 - val_loss: 0.3129 - val_precision: 0.0000e+00\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2870 - precision: 0.0000e+00 - val_loss: 0.3125 - val_precision: 0.0000e+00\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2867 - precision: 0.0000e+00 - val_loss: 0.3121 - val_precision: 0.0000e+00\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2863 - precision: 0.0000e+00 - val_loss: 0.3118 - val_precision: 0.0000e+00\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2860 - precision: 0.0000e+00 - val_loss: 0.3113 - val_precision: 0.0000e+00\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2857 - precision: 0.0000e+00 - val_loss: 0.3111 - val_precision: 0.0000e+00\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2855 - precision: 0.0000e+00 - val_loss: 0.3108 - val_precision: 0.0000e+00\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2853 - precision: 0.0000e+00 - val_loss: 0.3105 - val_precision: 0.0000e+00\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2851 - precision: 0.0000e+00 - val_loss: 0.3103 - val_precision: 0.0000e+00\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2849 - precision: 0.0000e+00 - val_loss: 0.3100 - val_precision: 0.0000e+00\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2845 - precision: 0.0000e+00 - val_loss: 0.3097 - val_precision: 0.0000e+00\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2844 - precision: 0.0000e+00 - val_loss: 0.3094 - val_precision: 0.0000e+00\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2841 - precision: 0.0000e+00 - val_loss: 0.3090 - val_precision: 0.0000e+00\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2838 - precision: 0.0000e+00 - val_loss: 0.3087 - val_precision: 0.0000e+00\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2836 - precision: 0.0000e+00 - val_loss: 0.3086 - val_precision: 0.0000e+00\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2836 - precision: 0.0000e+00 - val_loss: 0.3085 - val_precision: 0.0000e+00\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2834 - precision: 0.0000e+00 - val_loss: 0.3083 - val_precision: 0.0000e+00\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2832 - precision: 0.0000e+00 - val_loss: 0.3081 - val_precision: 0.0000e+00\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2831 - precision: 0.0000e+00 - val_loss: 0.3079 - val_precision: 0.0000e+00\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2829 - precision: 0.0000e+00 - val_loss: 0.3078 - val_precision: 0.0000e+00\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2828 - precision: 0.0000e+00 - val_loss: 0.3077 - val_precision: 0.0000e+00\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2827 - precision: 0.0000e+00 - val_loss: 0.3076 - val_precision: 0.0000e+00\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2826 - precision: 0.0000e+00 - val_loss: 0.3075 - val_precision: 0.0000e+00\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2826 - precision: 0.0000e+00 - val_loss: 0.3075 - val_precision: 0.0000e+00\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2825 - precision: 0.0000e+00 - val_loss: 0.3074 - val_precision: 0.0000e+00\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2824 - precision: 0.0000e+00 - val_loss: 0.3072 - val_precision: 0.0000e+00\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2822 - precision: 0.0000e+00 - val_loss: 0.3071 - val_precision: 0.0000e+00\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2822 - precision: 0.0000e+00 - val_loss: 0.3071 - val_precision: 0.0000e+00\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2821 - precision: 0.0000e+00 - val_loss: 0.3070 - val_precision: 0.0000e+00\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2820 - precision: 0.0000e+00 - val_loss: 0.3069 - val_precision: 0.0000e+00\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2819 - precision: 0.0000e+00 - val_loss: 0.3069 - val_precision: 0.0000e+00\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2819 - precision: 0.0000e+00 - val_loss: 0.3068 - val_precision: 0.0000e+00\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2818 - precision: 0.0000e+00 - val_loss: 0.3068 - val_precision: 0.0000e+00\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2817 - precision: 0.0000e+00 - val_loss: 0.3066 - val_precision: 0.0000e+00\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2815 - precision: 0.0000e+00 - val_loss: 0.3063 - val_precision: 0.0000e+00\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2814 - precision: 0.0000e+00 - val_loss: 0.3062 - val_precision: 0.0000e+00\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2813 - precision: 0.0000e+00 - val_loss: 0.3061 - val_precision: 0.0000e+00\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2812 - precision: 0.0000e+00 - val_loss: 0.3059 - val_precision: 0.0000e+00\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2810 - precision: 0.0000e+00 - val_loss: 0.3057 - val_precision: 0.0000e+00\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2808 - precision: 0.0000e+00 - val_loss: 0.3056 - val_precision: 0.0000e+00\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2807 - precision: 0.0000e+00 - val_loss: 0.3054 - val_precision: 0.0000e+00\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2806 - precision: 0.0000e+00 - val_loss: 0.3052 - val_precision: 0.0000e+00\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2804 - precision: 0.0000e+00 - val_loss: 0.3050 - val_precision: 0.0000e+00\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2803 - precision: 0.0000e+00 - val_loss: 0.3048 - val_precision: 0.0000e+00\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2801 - precision: 0.0000e+00 - val_loss: 0.3047 - val_precision: 0.0000e+00\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2801 - precision: 0.0000e+00 - val_loss: 0.3047 - val_precision: 0.0000e+00\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2800 - precision: 0.0000e+00 - val_loss: 0.3045 - val_precision: 0.0000e+00\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2799 - precision: 0.0000e+00 - val_loss: 0.3044 - val_precision: 0.0000e+00\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2798 - precision: 0.0000e+00 - val_loss: 0.3043 - val_precision: 0.0000e+00\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2797 - precision: 0.0000e+00 - val_loss: 0.3042 - val_precision: 0.0000e+00\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2796 - precision: 0.0000e+00 - val_loss: 0.3041 - val_precision: 0.0000e+00\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2795 - precision: 0.0000e+00 - val_loss: 0.3040 - val_precision: 0.0000e+00\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2794 - precision: 0.0000e+00 - val_loss: 0.3040 - val_precision: 0.0000e+00\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2793 - precision: 0.0000e+00 - val_loss: 0.3039 - val_precision: 0.0000e+00\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2793 - precision: 0.0000e+00 - val_loss: 0.3039 - val_precision: 0.0000e+00\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2792 - precision: 0.0000e+00 - val_loss: 0.3038 - val_precision: 0.0000e+00\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2791 - precision: 0.0000e+00 - val_loss: 0.3037 - val_precision: 0.0000e+00\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2790 - precision: 0.0000e+00 - val_loss: 0.3036 - val_precision: 0.0000e+00\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2789 - precision: 0.0000e+00 - val_loss: 0.3035 - val_precision: 0.0000e+00\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2788 - precision: 0.0000e+00 - val_loss: 0.3035 - val_precision: 0.0000e+00\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2788 - precision: 0.0000e+00 - val_loss: 0.3034 - val_precision: 0.0000e+00\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2787 - precision: 0.0000e+00 - val_loss: 0.3034 - val_precision: 0.0000e+00\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2786 - precision: 0.0000e+00 - val_loss: 0.3033 - val_precision: 0.0000e+00\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2786 - precision: 0.0000e+00 - val_loss: 0.3032 - val_precision: 0.0000e+00\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2785 - precision: 0.0000e+00 - val_loss: 0.3031 - val_precision: 0.0000e+00\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2784 - precision: 0.0000e+00 - val_loss: 0.3031 - val_precision: 0.0000e+00\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2785 - precision: 0.0000e+00 - val_loss: 0.3030 - val_precision: 0.0000e+00\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2782 - precision: 0.0000e+00 - val_loss: 0.3029 - val_precision: 0.0000e+00\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2782 - precision: 0.0000e+00 - val_loss: 0.3029 - val_precision: 0.0000e+00\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2781 - precision: 0.0000e+00 - val_loss: 0.3028 - val_precision: 0.0000e+00\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2781 - precision: 0.0000e+00 - val_loss: 0.3027 - val_precision: 0.0000e+00\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2780 - precision: 0.0000e+00 - val_loss: 0.3026 - val_precision: 0.0000e+00\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2779 - precision: 0.0000e+00 - val_loss: 0.3025 - val_precision: 0.0000e+00\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2778 - precision: 0.0000e+00 - val_loss: 0.3024 - val_precision: 0.0000e+00\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2777 - precision: 0.0000e+00 - val_loss: 0.3023 - val_precision: 0.0000e+00\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2776 - precision: 0.0000e+00 - val_loss: 0.3022 - val_precision: 0.0000e+00\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2776 - precision: 0.0000e+00 - val_loss: 0.3021 - val_precision: 0.0000e+00\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2774 - precision: 0.0000e+00 - val_loss: 0.3021 - val_precision: 0.0000e+00\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2774 - precision: 0.0000e+00 - val_loss: 0.3020 - val_precision: 0.0000e+00\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2772 - precision: 0.0000e+00 - val_loss: 0.3019 - val_precision: 0.0000e+00\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2772 - precision: 0.0000e+00 - val_loss: 0.3018 - val_precision: 0.0000e+00\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2772 - precision: 0.0000e+00 - val_loss: 0.3017 - val_precision: 0.0000e+00\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2771 - precision: 0.0000e+00 - val_loss: 0.3017 - val_precision: 0.0000e+00\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2770 - precision: 0.0000e+00 - val_loss: 0.3016 - val_precision: 0.0000e+00\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2769 - precision: 0.0000e+00 - val_loss: 0.3015 - val_precision: 0.0000e+00\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2770 - precision: 0.0000e+00 - val_loss: 0.3014 - val_precision: 0.0000e+00\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2768 - precision: 0.0000e+00 - val_loss: 0.3014 - val_precision: 0.0000e+00\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2768 - precision: 0.0000e+00 - val_loss: 0.3013 - val_precision: 0.0000e+00\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2767 - precision: 0.0000e+00 - val_loss: 0.3013 - val_precision: 0.0000e+00\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2767 - precision: 0.0000e+00 - val_loss: 0.3012 - val_precision: 0.0000e+00\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2767 - precision: 0.0000e+00 - val_loss: 0.3012 - val_precision: 0.0000e+00\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2767 - precision: 0.0000e+00 - val_loss: 0.3011 - val_precision: 0.0000e+00\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2766 - precision: 0.0000e+00 - val_loss: 0.3011 - val_precision: 0.0000e+00\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2765 - precision: 0.0000e+00 - val_loss: 0.3010 - val_precision: 0.0000e+00\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2764 - precision: 0.0000e+00 - val_loss: 0.3009 - val_precision: 0.0000e+00\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2764 - precision: 0.0000e+00 - val_loss: 0.3009 - val_precision: 0.0000e+00\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2763 - precision: 0.0000e+00 - val_loss: 0.3009 - val_precision: 0.0000e+00\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2763 - precision: 0.0000e+00 - val_loss: 0.3008 - val_precision: 0.0000e+00\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2762 - precision: 0.0000e+00 - val_loss: 0.3008 - val_precision: 0.0000e+00\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2762 - precision: 0.0000e+00 - val_loss: 0.3007 - val_precision: 0.0000e+00\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2761 - precision: 0.0000e+00 - val_loss: 0.3007 - val_precision: 0.0000e+00\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2761 - precision: 0.0000e+00 - val_loss: 0.3006 - val_precision: 0.0000e+00\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2760 - precision: 0.0000e+00 - val_loss: 0.3006 - val_precision: 0.0000e+00\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2760 - precision: 0.0000e+00 - val_loss: 0.3005 - val_precision: 0.0000e+00\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2759 - precision: 0.0000e+00 - val_loss: 0.3005 - val_precision: 0.0000e+00\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2759 - precision: 0.0000e+00 - val_loss: 0.3004 - val_precision: 0.0000e+00\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2760 - precision: 0.0000e+00 - val_loss: 0.3004 - val_precision: 0.0000e+00\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2759 - precision: 0.0000e+00 - val_loss: 0.3003 - val_precision: 0.0000e+00\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2757 - precision: 0.0000e+00 - val_loss: 0.3003 - val_precision: 0.0000e+00\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2757 - precision: 0.0000e+00 - val_loss: 0.3003 - val_precision: 0.0000e+00\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2757 - precision: 0.0000e+00 - val_loss: 0.3002 - val_precision: 0.0000e+00\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2757 - precision: 0.0000e+00 - val_loss: 0.3002 - val_precision: 0.0000e+00\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2756 - precision: 0.0000e+00 - val_loss: 0.3002 - val_precision: 0.0000e+00\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2755 - precision: 0.0000e+00 - val_loss: 0.3001 - val_precision: 0.0000e+00\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2754 - precision: 0.0000e+00 - val_loss: 0.3001 - val_precision: 0.0000e+00\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2754 - precision: 0.0000e+00 - val_loss: 0.3000 - val_precision: 0.0000e+00\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2753 - precision: 0.0000e+00 - val_loss: 0.3000 - val_precision: 0.0000e+00\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2754 - precision: 0.0000e+00 - val_loss: 0.3000 - val_precision: 0.0000e+00\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2752 - precision: 0.0000e+00 - val_loss: 0.2999 - val_precision: 0.0000e+00\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2752 - precision: 0.0000e+00 - val_loss: 0.2999 - val_precision: 0.0000e+00\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2752 - precision: 0.0000e+00 - val_loss: 0.2999 - val_precision: 0.0000e+00\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2751 - precision: 0.0000e+00 - val_loss: 0.2998 - val_precision: 0.0000e+00\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2751 - precision: 0.0000e+00 - val_loss: 0.2998 - val_precision: 0.0000e+00\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2751 - precision: 0.0000e+00 - val_loss: 0.2997 - val_precision: 0.0000e+00\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2750 - precision: 0.0000e+00 - val_loss: 0.2997 - val_precision: 0.0000e+00\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2750 - precision: 0.0000e+00 - val_loss: 0.2997 - val_precision: 0.0000e+00\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2749 - precision: 0.0000e+00 - val_loss: 0.2996 - val_precision: 0.0000e+00\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2749 - precision: 0.0000e+00 - val_loss: 0.2996 - val_precision: 0.0000e+00\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2749 - precision: 0.0000e+00 - val_loss: 0.2996 - val_precision: 0.0000e+00\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2748 - precision: 0.0000e+00 - val_loss: 0.2995 - val_precision: 0.0000e+00\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2747 - precision: 0.0000e+00 - val_loss: 0.2995 - val_precision: 0.0000e+00\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2744 - precision: 0.0000e+00 - val_loss: 0.2994 - val_precision: 0.0000e+00\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2745 - precision: 0.0000e+00 - val_loss: 0.2993 - val_precision: 0.0000e+00\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2745 - precision: 0.0000e+00 - val_loss: 0.2993 - val_precision: 0.0000e+00\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2744 - precision: 0.0000e+00 - val_loss: 0.2993 - val_precision: 0.0000e+00\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2745 - precision: 0.0000e+00 - val_loss: 0.2992 - val_precision: 0.0000e+00\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2743 - precision: 0.0000e+00 - val_loss: 0.2992 - val_precision: 0.0000e+00\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2743 - precision: 0.0000e+00 - val_loss: 0.2992 - val_precision: 0.0000e+00\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2743 - precision: 0.0000e+00 - val_loss: 0.2992 - val_precision: 0.0000e+00\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2743 - precision: 0.0000e+00 - val_loss: 0.2991 - val_precision: 0.0000e+00\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2742 - precision: 0.0000e+00 - val_loss: 0.2991 - val_precision: 0.0000e+00\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2742 - precision: 0.0000e+00 - val_loss: 0.2991 - val_precision: 0.0000e+00\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2741 - precision: 0.0000e+00 - val_loss: 0.2991 - val_precision: 0.0000e+00\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2741 - precision: 0.0000e+00 - val_loss: 0.2991 - val_precision: 0.0000e+00\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2740 - precision: 0.0000e+00 - val_loss: 0.2990 - val_precision: 0.0000e+00\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2740 - precision: 0.0000e+00 - val_loss: 0.2990 - val_precision: 0.0000e+00\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2739 - precision: 0.0000e+00 - val_loss: 0.2989 - val_precision: 0.0000e+00\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2739 - precision: 0.0000e+00 - val_loss: 0.2989 - val_precision: 0.0000e+00\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2739 - precision: 0.0000e+00 - val_loss: 0.2988 - val_precision: 0.0000e+00\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2738 - precision: 0.0000e+00 - val_loss: 0.2988 - val_precision: 0.0000e+00\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2738 - precision: 0.0000e+00 - val_loss: 0.2988 - val_precision: 0.0000e+00\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2738 - precision: 0.0000e+00 - val_loss: 0.2987 - val_precision: 0.0000e+00\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2739 - precision: 0.0000e+00 - val_loss: 0.2988 - val_precision: 0.0000e+00\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2737 - precision: 0.0000e+00 - val_loss: 0.2987 - val_precision: 0.0000e+00\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2736 - precision: 0.0000e+00 - val_loss: 0.2987 - val_precision: 0.0000e+00\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2736 - precision: 0.0000e+00 - val_loss: 0.2987 - val_precision: 0.0000e+00\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2736 - precision: 0.0000e+00 - val_loss: 0.2986 - val_precision: 0.0000e+00\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2735 - precision: 0.0000e+00 - val_loss: 0.2986 - val_precision: 0.0000e+00\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2736 - precision: 0.0000e+00 - val_loss: 0.2986 - val_precision: 0.0000e+00\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2734 - precision: 0.0000e+00 - val_loss: 0.2986 - val_precision: 0.0000e+00\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2734 - precision: 0.0000e+00 - val_loss: 0.2985 - val_precision: 0.0000e+00\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2734 - precision: 0.0000e+00 - val_loss: 0.2985 - val_precision: 0.0000e+00\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2733 - precision: 0.0000e+00 - val_loss: 0.2984 - val_precision: 0.0000e+00\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2733 - precision: 0.0000e+00 - val_loss: 0.2984 - val_precision: 0.0000e+00\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2733 - precision: 0.0000e+00 - val_loss: 0.2984 - val_precision: 0.0000e+00\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2733 - precision: 0.0000e+00 - val_loss: 0.2984 - val_precision: 0.0000e+00\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2732 - precision: 0.0000e+00 - val_loss: 0.2983 - val_precision: 0.0000e+00\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2733 - precision: 0.0000e+00 - val_loss: 0.2983 - val_precision: 0.0000e+00\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2731 - precision: 0.0000e+00 - val_loss: 0.2983 - val_precision: 0.0000e+00\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2731 - precision: 0.0000e+00 - val_loss: 0.2983 - val_precision: 0.0000e+00\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2731 - precision: 0.0000e+00 - val_loss: 0.2982 - val_precision: 0.0000e+00\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2730 - precision: 0.0000e+00 - val_loss: 0.2982 - val_precision: 0.0000e+00\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2730 - precision: 0.0000e+00 - val_loss: 0.2982 - val_precision: 0.0000e+00\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2731 - precision: 0.0000e+00 - val_loss: 0.2982 - val_precision: 0.0000e+00\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2730 - precision: 0.0000e+00 - val_loss: 0.2982 - val_precision: 0.0000e+00\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2729 - precision: 0.0000e+00 - val_loss: 0.2982 - val_precision: 0.0000e+00\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2729 - precision: 0.0000e+00 - val_loss: 0.2982 - val_precision: 0.0000e+00\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2729 - precision: 0.0000e+00 - val_loss: 0.2981 - val_precision: 0.0000e+00\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2731 - precision: 0.0000e+00 - val_loss: 0.2981 - val_precision: 0.0000e+00\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2729 - precision: 0.0000e+00 - val_loss: 0.2981 - val_precision: 0.0000e+00\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2728 - precision: 0.0000e+00 - val_loss: 0.2981 - val_precision: 0.0000e+00\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2727 - precision: 0.0000e+00 - val_loss: 0.2981 - val_precision: 0.0000e+00\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2728 - precision: 0.0000e+00 - val_loss: 0.2980 - val_precision: 0.0000e+00\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2726 - precision: 0.0000e+00 - val_loss: 0.2980 - val_precision: 0.0000e+00\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2728 - precision: 0.0000e+00 - val_loss: 0.2980 - val_precision: 0.0000e+00\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2728 - precision: 0.0000e+00 - val_loss: 0.2981 - val_precision: 0.0000e+00\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2727 - precision: 0.0000e+00 - val_loss: 0.2980 - val_precision: 0.0000e+00\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2726 - precision: 0.0000e+00 - val_loss: 0.2980 - val_precision: 0.0000e+00\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2725 - precision: 0.0000e+00 - val_loss: 0.2979 - val_precision: 0.0000e+00\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2726 - precision: 0.0000e+00 - val_loss: 0.2979 - val_precision: 0.0000e+00\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2725 - precision: 0.0000e+00 - val_loss: 0.2978 - val_precision: 0.0000e+00\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2725 - precision: 0.0000e+00 - val_loss: 0.2978 - val_precision: 0.0000e+00\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2724 - precision: 0.0000e+00 - val_loss: 0.2978 - val_precision: 0.0000e+00\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2724 - precision: 0.0000e+00 - val_loss: 0.2978 - val_precision: 0.0000e+00\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2724 - precision: 0.0000e+00 - val_loss: 0.2978 - val_precision: 0.0000e+00\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2725 - precision: 0.0000e+00 - val_loss: 0.2978 - val_precision: 0.0000e+00\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2723 - precision: 0.0000e+00 - val_loss: 0.2977 - val_precision: 0.0000e+00\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2723 - precision: 0.0000e+00 - val_loss: 0.2977 - val_precision: 0.0000e+00\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2723 - precision: 0.0000e+00 - val_loss: 0.2977 - val_precision: 0.0000e+00\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2723 - precision: 0.0000e+00 - val_loss: 0.2977 - val_precision: 0.0000e+00\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2722 - precision: 0.0000e+00 - val_loss: 0.2977 - val_precision: 0.0000e+00\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2722 - precision: 0.0000e+00 - val_loss: 0.2977 - val_precision: 0.0000e+00\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2722 - precision: 0.0000e+00 - val_loss: 0.2977 - val_precision: 0.0000e+00\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2722 - precision: 0.0000e+00 - val_loss: 0.2976 - val_precision: 0.0000e+00\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2723 - precision: 0.0000e+00 - val_loss: 0.2976 - val_precision: 0.0000e+00\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2722 - precision: 0.0000e+00 - val_loss: 0.2976 - val_precision: 0.0000e+00\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2722 - precision: 0.0000e+00 - val_loss: 0.2976 - val_precision: 0.0000e+00\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2721 - precision: 0.0000e+00 - val_loss: 0.2976 - val_precision: 0.0000e+00\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2721 - precision: 0.0000e+00 - val_loss: 0.2976 - val_precision: 0.0000e+00\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2720 - precision: 0.0000e+00 - val_loss: 0.2976 - val_precision: 0.0000e+00\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2720 - precision: 0.0000e+00 - val_loss: 0.2975 - val_precision: 0.0000e+00\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2720 - precision: 0.0000e+00 - val_loss: 0.2975 - val_precision: 0.0000e+00\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2720 - precision: 0.0000e+00 - val_loss: 0.2975 - val_precision: 0.0000e+00\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2720 - precision: 0.0000e+00 - val_loss: 0.2975 - val_precision: 0.0000e+00\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2719 - precision: 0.0000e+00 - val_loss: 0.2974 - val_precision: 0.0000e+00\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2718 - precision: 0.0000e+00 - val_loss: 0.2974 - val_precision: 0.0000e+00\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2724 - precision: 0.0000e+00 - val_loss: 0.2974 - val_precision: 0.0000e+00\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2718 - precision: 0.0000e+00 - val_loss: 0.2973 - val_precision: 0.0000e+00\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2717 - precision: 0.0000e+00 - val_loss: 0.2973 - val_precision: 0.0000e+00\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2717 - precision: 0.0000e+00 - val_loss: 0.2973 - val_precision: 0.0000e+00\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2717 - precision: 0.0000e+00 - val_loss: 0.2973 - val_precision: 0.0000e+00\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2716 - precision: 0.0000e+00 - val_loss: 0.2973 - val_precision: 0.0000e+00\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2716 - precision: 0.0000e+00 - val_loss: 0.2973 - val_precision: 0.0000e+00\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2717 - precision: 0.0000e+00 - val_loss: 0.2973 - val_precision: 0.0000e+00\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2716 - precision: 0.0000e+00 - val_loss: 0.2972 - val_precision: 0.0000e+00\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2716 - precision: 0.0000e+00 - val_loss: 0.2972 - val_precision: 0.0000e+00\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2716 - precision: 0.0000e+00 - val_loss: 0.2972 - val_precision: 0.0000e+00\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2716 - precision: 0.0000e+00 - val_loss: 0.2972 - val_precision: 0.0000e+00\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2716 - precision: 0.0000e+00 - val_loss: 0.2972 - val_precision: 0.0000e+00\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2716 - precision: 0.0000e+00 - val_loss: 0.2972 - val_precision: 0.0000e+00\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2716 - precision: 0.0000e+00 - val_loss: 0.2972 - val_precision: 0.0000e+00\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2713 - precision: 0.0000e+00 - val_loss: 0.2971 - val_precision: 0.0000e+00\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2714 - precision: 0.0000e+00 - val_loss: 0.2971 - val_precision: 0.0000e+00\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2714 - precision: 0.0000e+00 - val_loss: 0.2971 - val_precision: 0.0000e+00\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2715 - precision: 0.0000e+00 - val_loss: 0.2971 - val_precision: 0.0000e+00\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2713 - precision: 0.0000e+00 - val_loss: 0.2971 - val_precision: 0.0000e+00\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2713 - precision: 0.0000e+00 - val_loss: 0.2970 - val_precision: 0.0000e+00\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2713 - precision: 0.0000e+00 - val_loss: 0.2970 - val_precision: 0.0000e+00\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2713 - precision: 0.0000e+00 - val_loss: 0.2970 - val_precision: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300\n",
    "history = modela_glove.fit(padded, training_labels_final, \n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(val_padded, val_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "-_ctJiO4ND2t",
    "outputId": "357ac8d3-9a35-4db6-d584-578399043c71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "precision = history.history['precision']\n",
    "val_precision = history.history['val_precision']\n",
    "epochs=range(len(precision))\n",
    "plt.plot(epochs, precision, 'r')\n",
    "plt.plot(epochs, val_precision, 'b')\n",
    "plt.title('Training and validation Precision')\n",
    "plt.ylim((0,1.5))\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "f8srp5_wND2t",
    "outputId": "df4be3fb-168e-46a3-a552-4613bf0d63d6",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3771 - precision: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3771357834339142, 0.0]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modela_glove.evaluate(test_padded, test_labels_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model B with GloVe 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelb_glove50 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], input_length = max_length, trainable=False),  \n",
    "    tf.keras.layers.Conv1D(128, 5, activation=\"relu\"),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "modelb_glove50.compile(loss='binary_crossentropy', \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1200, 50)          250100    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 1196, 128)         32128     \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 774       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 283,009\n",
      "Trainable params: 32,909\n",
      "Non-trainable params: 250,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelb_glove50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 0.6074 - precision: 0.0000e+00 - val_loss: 0.5457 - val_precision: 0.0000e+00\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.4685 - precision: 0.0000e+00 - val_loss: 0.4457 - val_precision: 0.0000e+00\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.3807 - precision: 0.0000e+00 - val_loss: 0.3870 - val_precision: 0.0000e+00\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.3362 - precision: 0.0000e+00 - val_loss: 0.3601 - val_precision: 0.0000e+00\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.3244 - precision: 0.0000e+00 - val_loss: 0.3487 - val_precision: 0.0000e+00\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.3179 - precision: 0.0000e+00 - val_loss: 0.3435 - val_precision: 0.0000e+00\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.3134 - precision: 0.0000e+00 - val_loss: 0.3393 - val_precision: 0.0000e+00\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.3102 - precision: 0.0000e+00 - val_loss: 0.3359 - val_precision: 0.0000e+00\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.3062 - precision: 0.0000e+00 - val_loss: 0.3330 - val_precision: 0.0000e+00\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.3057 - precision: 0.0000e+00 - val_loss: 0.3329 - val_precision: 0.0000e+00\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.3006 - precision: 0.0000e+00 - val_loss: 0.3292 - val_precision: 0.0000e+00\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.2979 - precision: 0.0000e+00 - val_loss: 0.3276 - val_precision: 0.0000e+00\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2948 - precision: 0.0000e+00 - val_loss: 0.3237 - val_precision: 0.0000e+00\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.2910 - precision: 0.0000e+00 - val_loss: 0.3191 - val_precision: 0.0000e+00\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2881 - precision: 0.0000e+00 - val_loss: 0.3160 - val_precision: 0.0000e+00\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2853 - precision: 0.0000e+00 - val_loss: 0.3133 - val_precision: 0.0000e+00\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2832 - precision: 0.0000e+00 - val_loss: 0.3106 - val_precision: 0.0000e+00\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.2818 - precision: 0.0000e+00 - val_loss: 0.3089 - val_precision: 0.0000e+00\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.2797 - precision: 0.0000e+00 - val_loss: 0.3071 - val_precision: 0.0000e+00\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2761 - precision: 0.0000e+00 - val_loss: 0.3056 - val_precision: 0.0000e+00\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.2751 - precision: 0.0000e+00 - val_loss: 0.3045 - val_precision: 0.0000e+00\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.2733 - precision: 0.0000e+00 - val_loss: 0.3028 - val_precision: 0.0000e+00\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2720 - precision: 0.0000e+00 - val_loss: 0.3015 - val_precision: 0.0000e+00\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2710 - precision: 0.0000e+00 - val_loss: 0.3011 - val_precision: 0.0000e+00\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.2684 - precision: 0.0000e+00 - val_loss: 0.3019 - val_precision: 0.0000e+00\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2711 - precision: 0.0000e+00 - val_loss: 0.3025 - val_precision: 0.0000e+00\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2696 - precision: 0.0000e+00 - val_loss: 0.2999 - val_precision: 0.0000e+00\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.2701 - precision: 0.0000e+00 - val_loss: 0.2987 - val_precision: 0.0000e+00\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.2682 - precision: 0.0000e+00 - val_loss: 0.2986 - val_precision: 0.0000e+00\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.2676 - precision: 0.0000e+00 - val_loss: 0.2984 - val_precision: 0.0000e+00\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2665 - precision: 0.0000e+00 - val_loss: 0.2978 - val_precision: 0.0000e+00\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2682 - precision: 0.0000e+00 - val_loss: 0.2980 - val_precision: 0.0000e+00\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.2652 - precision: 0.0000e+00 - val_loss: 0.2976 - val_precision: 0.0000e+00\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 0.2642 - precision: 0.0000e+00 - val_loss: 0.2971 - val_precision: 0.0000e+00\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 0.2646 - precision: 0.0000e+00 - val_loss: 0.2973 - val_precision: 0.0000e+00\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.2648 - precision: 0.0000e+00 - val_loss: 0.2967 - val_precision: 0.0000e+00\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.2631 - precision: 0.0000e+00 - val_loss: 0.2966 - val_precision: 0.0000e+00\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 0.2632 - precision: 0.0000e+00 - val_loss: 0.2965 - val_precision: 0.0000e+00\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.2621 - precision: 0.0000e+00 - val_loss: 0.2963 - val_precision: 0.0000e+00\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.2622 - precision: 0.0000e+00 - val_loss: 0.2983 - val_precision: 0.0000e+00\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.2622 - precision: 0.0000e+00 - val_loss: 0.2962 - val_precision: 0.0000e+00\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.2610 - precision: 0.0000e+00 - val_loss: 0.2961 - val_precision: 0.0000e+00\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2601 - precision: 0.0000e+00 - val_loss: 0.2954 - val_precision: 0.0000e+00\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2597 - precision: 0.0000e+00 - val_loss: 0.2949 - val_precision: 0.0000e+00\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.2591 - precision: 0.0000e+00 - val_loss: 0.2965 - val_precision: 0.0000e+00\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.2605 - precision: 0.0000e+00 - val_loss: 0.2949 - val_precision: 0.0000e+00\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2568 - precision: 0.0000e+00 - val_loss: 0.2943 - val_precision: 0.0000e+00\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2569 - precision: 0.0000e+00 - val_loss: 0.2950 - val_precision: 0.0000e+00\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2578 - precision: 0.0000e+00 - val_loss: 0.2955 - val_precision: 0.0000e+00\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2571 - precision: 0.0000e+00 - val_loss: 0.2946 - val_precision: 0.0000e+00\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.2559 - precision: 0.0000e+00 - val_loss: 0.2940 - val_precision: 0.0000e+00\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.2549 - precision: 0.0000e+00 - val_loss: 0.2936 - val_precision: 0.0000e+00\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.2540 - precision: 0.0000e+00 - val_loss: 0.2933 - val_precision: 0.0000e+00\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.2536 - precision: 0.0000e+00 - val_loss: 0.2930 - val_precision: 0.0000e+00\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2529 - precision: 0.0000e+00 - val_loss: 0.2928 - val_precision: 0.0000e+00\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 0.2537 - precision: 0.0000e+00 - val_loss: 0.2924 - val_precision: 0.0000e+00\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.2529 - precision: 0.0000e+00 - val_loss: 0.2921 - val_precision: 0.0000e+00\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.2517 - precision: 0.0000e+00 - val_loss: 0.2919 - val_precision: 0.0000e+00\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.2520 - precision: 0.0000e+00 - val_loss: 0.2925 - val_precision: 0.0000e+00\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.2512 - precision: 0.0000e+00 - val_loss: 0.2921 - val_precision: 0.0000e+00\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.2506 - precision: 0.0000e+00 - val_loss: 0.2911 - val_precision: 0.0000e+00\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2510 - precision: 0.0000e+00 - val_loss: 0.2909 - val_precision: 0.0000e+00\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.2489 - precision: 0.0000e+00 - val_loss: 0.2910 - val_precision: 0.0000e+00\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 0.2489 - precision: 0.0000e+00 - val_loss: 0.2905 - val_precision: 0.0000e+00\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 0.2488 - precision: 0.0000e+00 - val_loss: 0.2901 - val_precision: 0.0000e+00\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 0.2489 - precision: 0.0000e+00 - val_loss: 0.2897 - val_precision: 0.0000e+00\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 0.2486 - precision: 0.0000e+00 - val_loss: 0.2895 - val_precision: 0.0000e+00\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 0.2469 - precision: 0.0000e+00 - val_loss: 0.2892 - val_precision: 0.0000e+00\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 0.2463 - precision: 0.0000e+00 - val_loss: 0.2887 - val_precision: 0.0000e+00\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.2496 - precision: 0.0000e+00 - val_loss: 0.2902 - val_precision: 0.0000e+00\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.2445 - precision: 0.0000e+00 - val_loss: 0.2884 - val_precision: 0.0000e+00\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2453 - precision: 0.0000e+00 - val_loss: 0.2899 - val_precision: 0.0000e+00\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.2462 - precision: 0.0000e+00 - val_loss: 0.2884 - val_precision: 0.0000e+00\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.2443 - precision: 0.0000e+00 - val_loss: 0.2870 - val_precision: 0.0000e+00\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.2428 - precision: 0.0000e+00 - val_loss: 0.2868 - val_precision: 0.0000e+00\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2478 - precision: 0.0000e+00 - val_loss: 0.2896 - val_precision: 0.0000e+00\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.2509 - precision: 0.0000e+00 - val_loss: 0.2869 - val_precision: 0.0000e+00\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.2410 - precision: 0.0000e+00 - val_loss: 0.2900 - val_precision: 0.0000e+00\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.2463 - precision: 0.0000e+00 - val_loss: 0.2884 - val_precision: 0.0000e+00\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.2418 - precision: 0.0000e+00 - val_loss: 0.2854 - val_precision: 0.0000e+00\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.2402 - precision: 0.0000e+00 - val_loss: 0.2856 - val_precision: 0.0000e+00\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2404 - precision: 0.0000e+00 - val_loss: 0.2861 - val_precision: 0.0000e+00\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.2406 - precision: 0.0000e+00 - val_loss: 0.2848 - val_precision: 0.0000e+00\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.2396 - precision: 0.0000e+00 - val_loss: 0.2848 - val_precision: 0.0000e+00\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 0.2404 - precision: 0.0000e+00 - val_loss: 0.2858 - val_precision: 0.0000e+00\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.2387 - precision: 0.0000e+00 - val_loss: 0.2848 - val_precision: 0.0000e+00\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2392 - precision: 0.0000e+00 - val_loss: 0.2838 - val_precision: 0.0000e+00\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.2403 - precision: 0.0000e+00 - val_loss: 0.2884 - val_precision: 0.0000e+00\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 0.2383 - precision: 0.0000e+00 - val_loss: 0.2833 - val_precision: 0.0000e+00\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.2384 - precision: 0.0000e+00 - val_loss: 0.2837 - val_precision: 0.0000e+00\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.2367 - precision: 0.0000e+00 - val_loss: 0.2835 - val_precision: 0.0000e+00\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2361 - precision: 0.0000e+00 - val_loss: 0.2836 - val_precision: 0.0000e+00\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.2411 - precision: 0.0000e+00 - val_loss: 0.2852 - val_precision: 0.0000e+00\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.2343 - precision: 0.0000e+00 - val_loss: 0.2822 - val_precision: 0.0000e+00\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.2360 - precision: 0.0000e+00 - val_loss: 0.2831 - val_precision: 0.0000e+00\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 0.2341 - precision: 0.0000e+00 - val_loss: 0.2807 - val_precision: 0.0000e+00\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.2381 - precision: 0.0000e+00 - val_loss: 0.2857 - val_precision: 0.0000e+00\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 0.2364 - precision: 0.0000e+00 - val_loss: 0.2817 - val_precision: 0.0000e+00\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.2334 - precision: 0.0000e+00 - val_loss: 0.2807 - val_precision: 0.0000e+00\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.2315 - precision: 0.0000e+00 - val_loss: 0.2798 - val_precision: 0.0000e+00\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2306 - precision: 0.0000e+00 - val_loss: 0.2797 - val_precision: 0.0000e+00\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.2298 - precision: 0.0000e+00 - val_loss: 0.2797 - val_precision: 0.0000e+00\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2305 - precision: 0.0000e+00 - val_loss: 0.2790 - val_precision: 0.0000e+00\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.2286 - precision: 0.0000e+00 - val_loss: 0.2787 - val_precision: 0.0000e+00\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.2286 - precision: 0.0000e+00 - val_loss: 0.2787 - val_precision: 0.0000e+00\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2276 - precision: 0.0000e+00 - val_loss: 0.2782 - val_precision: 0.0000e+00\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 0.2288 - precision: 0.0000e+00 - val_loss: 0.2782 - val_precision: 0.0000e+00\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 0.2294 - precision: 0.0000e+00 - val_loss: 0.2793 - val_precision: 0.0000e+00\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.2286 - precision: 0.0000e+00 - val_loss: 0.2779 - val_precision: 0.0000e+00\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 0.2268 - precision: 0.0000e+00 - val_loss: 0.2775 - val_precision: 0.0000e+00\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.2248 - precision: 0.0000e+00 - val_loss: 0.2777 - val_precision: 0.0000e+00\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.2273 - precision: 0.0000e+00 - val_loss: 0.2783 - val_precision: 0.0000e+00\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 0.2269 - precision: 0.0000e+00 - val_loss: 0.2786 - val_precision: 0.0000e+00\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 0.2252 - precision: 0.0000e+00 - val_loss: 0.2766 - val_precision: 0.0000e+00\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 0.2237 - precision: 0.0000e+00 - val_loss: 0.2761 - val_precision: 0.0000e+00\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 0.2229 - precision: 0.0000e+00 - val_loss: 0.2768 - val_precision: 0.0000e+00\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 0.2215 - precision: 0.0000e+00 - val_loss: 0.2771 - val_precision: 0.0000e+00\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.2258 - precision: 0.0000e+00 - val_loss: 0.2760 - val_precision: 0.0000e+00\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 0.2233 - precision: 0.0000e+00 - val_loss: 0.2854 - val_precision: 0.0000e+00\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 0.2243 - precision: 0.0000e+00 - val_loss: 0.2769 - val_precision: 0.0000e+00\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.2214 - precision: 0.0000e+00 - val_loss: 0.2752 - val_precision: 0.0000e+00\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2191 - precision: 0.0000e+00 - val_loss: 0.2751 - val_precision: 0.0000e+00\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2193 - precision: 0.0000e+00 - val_loss: 0.2749 - val_precision: 0.0000e+00\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.2186 - precision: 0.0000e+00 - val_loss: 0.2746 - val_precision: 0.0000e+00\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.2177 - precision: 0.0000e+00 - val_loss: 0.2743 - val_precision: 0.0000e+00\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2186 - precision: 0.0000e+00 - val_loss: 0.2742 - val_precision: 0.0000e+00\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.2209 - precision: 0.0000e+00 - val_loss: 0.2749 - val_precision: 0.0000e+00\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.2229 - precision: 0.0000e+00 - val_loss: 0.2746 - val_precision: 0.0000e+00\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2183 - precision: 0.0000e+00 - val_loss: 0.2867 - val_precision: 0.0000e+00\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.2237 - precision: 0.0000e+00 - val_loss: 0.2742 - val_precision: 0.0000e+00\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.2172 - precision: 0.0000e+00 - val_loss: 0.2758 - val_precision: 0.0000e+00\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2169 - precision: 0.0000e+00 - val_loss: 0.2729 - val_precision: 0.0000e+00\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2143 - precision: 0.0000e+00 - val_loss: 0.2727 - val_precision: 0.0000e+00\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2140 - precision: 0.0000e+00 - val_loss: 0.2731 - val_precision: 0.0000e+00\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2166 - precision: 0.0000e+00 - val_loss: 0.2750 - val_precision: 0.0000e+00\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.2138 - precision: 0.0000e+00 - val_loss: 0.2723 - val_precision: 0.0000e+00\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.2153 - precision: 0.0000e+00 - val_loss: 0.2726 - val_precision: 0.0000e+00\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 0.2179 - precision: 0.0000e+00 - val_loss: 0.2741 - val_precision: 0.0000e+00\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.2129 - precision: 0.0000e+00 - val_loss: 0.2758 - val_precision: 0.0000e+00\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.2159 - precision: 0.0000e+00 - val_loss: 0.2722 - val_precision: 0.0000e+00\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 0.2147 - precision: 0.0000e+00 - val_loss: 0.2719 - val_precision: 0.0000e+00\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.2112 - precision: 0.0000e+00 - val_loss: 0.2750 - val_precision: 0.0000e+00\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.2123 - precision: 0.0000e+00 - val_loss: 0.2767 - val_precision: 0.0000e+00\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 0.2122 - precision: 0.0000e+00 - val_loss: 0.2714 - val_precision: 0.0000e+00\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 0.2072 - precision: 0.0000e+00 - val_loss: 0.2745 - val_precision: 0.0000e+00\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 0.2132 - precision: 0.0000e+00 - val_loss: 0.2738 - val_precision: 0.0000e+00\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 0.2136 - precision: 0.0000e+00 - val_loss: 0.2725 - val_precision: 0.0000e+00\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 0.2086 - precision: 0.0000e+00 - val_loss: 0.2724 - val_precision: 0.0000e+00\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.2111 - precision: 0.0000e+00 - val_loss: 0.2722 - val_precision: 0.0000e+00\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.2064 - precision: 0.0000e+00 - val_loss: 0.2713 - val_precision: 0.0000e+00\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.2064 - precision: 0.0000e+00 - val_loss: 0.2712 - val_precision: 0.0000e+00\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.2079 - precision: 0.0000e+00 - val_loss: 0.2736 - val_precision: 0.0000e+00\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2081 - precision: 0.0000e+00 - val_loss: 0.2717 - val_precision: 0.0000e+00\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2055 - precision: 0.0000e+00 - val_loss: 0.2712 - val_precision: 0.0000e+00\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2044 - precision: 0.0000e+00 - val_loss: 0.2714 - val_precision: 0.0000e+00\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2054 - precision: 0.0000e+00 - val_loss: 0.2719 - val_precision: 0.0000e+00\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.2046 - precision: 0.0000e+00 - val_loss: 0.2712 - val_precision: 0.0000e+00\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.2046 - precision: 0.0000e+00 - val_loss: 0.2716 - val_precision: 0.0000e+00\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.2015 - precision: 0.0000e+00 - val_loss: 0.2723 - val_precision: 0.0000e+00\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.2055 - precision: 0.0000e+00 - val_loss: 0.2719 - val_precision: 0.0000e+00\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2025 - precision: 0.0000e+00 - val_loss: 0.2715 - val_precision: 0.0000e+00\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2037 - precision: 0.0000e+00 - val_loss: 0.2727 - val_precision: 0.0000e+00\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.2017 - precision: 0.0000e+00 - val_loss: 0.2715 - val_precision: 0.0000e+00\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.2001 - precision: 0.0000e+00 - val_loss: 0.2718 - val_precision: 0.0000e+00\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.2004 - precision: 0.0000e+00 - val_loss: 0.2715 - val_precision: 0.0000e+00\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.1991 - precision: 0.0000e+00 - val_loss: 0.2724 - val_precision: 0.0000e+00\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.1993 - precision: 0.0000e+00 - val_loss: 0.2717 - val_precision: 0.0000e+00\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.2015 - precision: 0.0000e+00 - val_loss: 0.2721 - val_precision: 0.0000e+00\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.2037 - precision: 0.0000e+00 - val_loss: 0.2717 - val_precision: 0.0000e+00\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.1989 - precision: 0.0000e+00 - val_loss: 0.2762 - val_precision: 0.0000e+00\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.2009 - precision: 0.0000e+00 - val_loss: 0.2712 - val_precision: 0.0000e+00\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.2018 - precision: 0.0000e+00 - val_loss: 0.2728 - val_precision: 0.0000e+00\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 0.1978 - precision: 0.0000e+00 - val_loss: 0.2723 - val_precision: 0.0000e+00\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.2064 - precision: 0.0000e+00 - val_loss: 0.2746 - val_precision: 0.0000e+00\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.1956 - precision: 0.0000e+00 - val_loss: 0.2751 - val_precision: 0.0000e+00\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.1978 - precision: 0.0000e+00 - val_loss: 0.2726 - val_precision: 0.0000e+00\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.1965 - precision: 0.0000e+00 - val_loss: 0.2734 - val_precision: 0.0000e+00\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.1973 - precision: 0.0000e+00 - val_loss: 0.2744 - val_precision: 0.0000e+00\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2052 - precision: 0.0000e+00 - val_loss: 0.2734 - val_precision: 0.0000e+00\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.1933 - precision: 0.0000e+00 - val_loss: 0.2750 - val_precision: 0.0000e+00\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.1956 - precision: 0.0000e+00 - val_loss: 0.2719 - val_precision: 0.0000e+00\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 0.1942 - precision: 0.0000e+00 - val_loss: 0.2722 - val_precision: 0.0000e+00\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 0.1931 - precision: 0.0000e+00 - val_loss: 0.2721 - val_precision: 0.0000e+00\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.1920 - precision: 0.0000e+00 - val_loss: 0.2744 - val_precision: 0.0000e+00\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 0.1941 - precision: 0.0000e+00 - val_loss: 0.2726 - val_precision: 0.0000e+00\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.1925 - precision: 0.0000e+00 - val_loss: 0.2734 - val_precision: 0.0000e+00\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.1918 - precision: 0.0000e+00 - val_loss: 0.2760 - val_precision: 0.0000e+00\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.1951 - precision: 1.0000 - val_loss: 0.2727 - val_precision: 0.0000e+00\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.1908 - precision: 1.0000 - val_loss: 0.2746 - val_precision: 0.0000e+00\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.1903 - precision: 1.0000 - val_loss: 0.2727 - val_precision: 0.0000e+00\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.1950 - precision: 0.8571 - val_loss: 0.2736 - val_precision: 0.0000e+00\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.1954 - precision: 1.0000 - val_loss: 0.2732 - val_precision: 0.0000e+00\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.1893 - precision: 1.0000 - val_loss: 0.2735 - val_precision: 0.0000e+00\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.1919 - precision: 1.0000 - val_loss: 0.2738 - val_precision: 0.0000e+00\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.1944 - precision: 1.0000 - val_loss: 0.2811 - val_precision: 0.0000e+00\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.1903 - precision: 1.0000 - val_loss: 0.2756 - val_precision: 1.0000\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 0.1921 - precision: 0.8333 - val_loss: 0.2742 - val_precision: 0.0000e+00\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.1868 - precision: 1.0000 - val_loss: 0.2760 - val_precision: 0.0000e+00\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.1886 - precision: 1.0000 - val_loss: 0.2736 - val_precision: 0.0000e+00\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.1966 - precision: 0.7500 - val_loss: 0.2762 - val_precision: 1.0000\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.1848 - precision: 1.0000 - val_loss: 0.2752 - val_precision: 0.0000e+00\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 0.1862 - precision: 1.0000 - val_loss: 0.2755 - val_precision: 0.0000e+00\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.1848 - precision: 1.0000 - val_loss: 0.2757 - val_precision: 0.0000e+00\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.1847 - precision: 1.0000 - val_loss: 0.2764 - val_precision: 0.0000e+00\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.1835 - precision: 1.0000 - val_loss: 0.2776 - val_precision: 0.0000e+00\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.1849 - precision: 1.0000 - val_loss: 0.2765 - val_precision: 0.0000e+00\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.1844 - precision: 1.0000 - val_loss: 0.2767 - val_precision: 0.0000e+00\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.1832 - precision: 1.0000 - val_loss: 0.2762 - val_precision: 0.0000e+00\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.1824 - precision: 1.0000 - val_loss: 0.2769 - val_precision: 0.0000e+00\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.1821 - precision: 1.0000 - val_loss: 0.2780 - val_precision: 0.0000e+00\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.1822 - precision: 1.0000 - val_loss: 0.2765 - val_precision: 0.0000e+00\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.1808 - precision: 1.0000 - val_loss: 0.2804 - val_precision: 1.0000\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.2101 - precision: 0.5333 - val_loss: 0.3002 - val_precision: 0.6667\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.1871 - precision: 0.7500 - val_loss: 0.2884 - val_precision: 0.0000e+00\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.1893 - precision: 1.0000 - val_loss: 0.2759 - val_precision: 1.0000\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.1826 - precision: 0.7143 - val_loss: 0.2793 - val_precision: 1.0000\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.1801 - precision: 0.8571 - val_loss: 0.2753 - val_precision: 0.0000e+00\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.1801 - precision: 1.0000 - val_loss: 0.2757 - val_precision: 0.0000e+00\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.1793 - precision: 1.0000 - val_loss: 0.2759 - val_precision: 0.0000e+00\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.1788 - precision: 1.0000 - val_loss: 0.2762 - val_precision: 0.0000e+00\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.1775 - precision: 1.0000 - val_loss: 0.2772 - val_precision: 0.0000e+00\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.1773 - precision: 1.0000 - val_loss: 0.2784 - val_precision: 0.0000e+00\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.1842 - precision: 1.0000 - val_loss: 0.2798 - val_precision: 0.0000e+00\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.1809 - precision: 0.8333 - val_loss: 0.2825 - val_precision: 1.0000\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.1785 - precision: 0.8000 - val_loss: 0.2773 - val_precision: 0.0000e+00\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 0.1764 - precision: 1.0000 - val_loss: 0.2774 - val_precision: 1.0000\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 0.1758 - precision: 1.0000 - val_loss: 0.2779 - val_precision: 1.0000\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.1744 - precision: 1.0000 - val_loss: 0.2792 - val_precision: 1.0000\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.1749 - precision: 0.8333 - val_loss: 0.2786 - val_precision: 0.0000e+00\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.1744 - precision: 1.0000 - val_loss: 0.2793 - val_precision: 0.0000e+00\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.1737 - precision: 1.0000 - val_loss: 0.2794 - val_precision: 1.0000\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.1732 - precision: 1.0000 - val_loss: 0.2795 - val_precision: 1.0000\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.1744 - precision: 0.8333 - val_loss: 0.2809 - val_precision: 0.0000e+00\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.1761 - precision: 1.0000 - val_loss: 0.2809 - val_precision: 0.0000e+00\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.1780 - precision: 0.8571 - val_loss: 0.2849 - val_precision: 1.0000\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 0.1709 - precision: 1.0000 - val_loss: 0.2822 - val_precision: 0.0000e+00\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 0.1720 - precision: 1.0000 - val_loss: 0.2806 - val_precision: 0.0000e+00\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.1737 - precision: 0.8333 - val_loss: 0.2810 - val_precision: 0.0000e+00\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.1819 - precision: 1.0000 - val_loss: 0.2907 - val_precision: 0.0000e+00\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.1695 - precision: 1.0000 - val_loss: 0.2912 - val_precision: 0.6667\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.1881 - precision: 0.6923 - val_loss: 0.2901 - val_precision: 0.6667\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.1716 - precision: 0.8571 - val_loss: 0.2801 - val_precision: 0.0000e+00\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.1708 - precision: 1.0000 - val_loss: 0.2807 - val_precision: 0.0000e+00\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 0.1716 - precision: 1.0000 - val_loss: 0.2798 - val_precision: 0.0000e+00\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.1688 - precision: 1.0000 - val_loss: 0.2819 - val_precision: 1.0000\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.1709 - precision: 0.8889 - val_loss: 0.2792 - val_precision: 1.0000\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.1683 - precision: 1.0000 - val_loss: 0.2806 - val_precision: 0.0000e+00\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.1761 - precision: 1.0000 - val_loss: 0.2797 - val_precision: 1.0000\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.1713 - precision: 0.8000 - val_loss: 0.2802 - val_precision: 1.0000\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.1683 - precision: 0.8000 - val_loss: 0.2793 - val_precision: 1.0000\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.1686 - precision: 1.0000 - val_loss: 0.2799 - val_precision: 1.0000\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.1666 - precision: 1.0000 - val_loss: 0.2810 - val_precision: 1.0000\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 0.1678 - precision: 1.0000 - val_loss: 0.2825 - val_precision: 1.0000\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 0.1660 - precision: 0.8889 - val_loss: 0.2814 - val_precision: 1.0000\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.1662 - precision: 1.0000 - val_loss: 0.2825 - val_precision: 0.0000e+00\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 0.1652 - precision: 1.0000 - val_loss: 0.2823 - val_precision: 1.0000\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 0.1758 - precision: 1.0000 - val_loss: 0.2817 - val_precision: 1.0000\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 0.1649 - precision: 0.8889 - val_loss: 0.2829 - val_precision: 1.0000\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 0.1688 - precision: 0.8000 - val_loss: 0.2825 - val_precision: 0.0000e+00\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.1652 - precision: 0.8571 - val_loss: 0.2828 - val_precision: 1.0000\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.1646 - precision: 1.0000 - val_loss: 0.2829 - val_precision: 1.0000\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 0.1667 - precision: 0.8889 - val_loss: 0.2822 - val_precision: 1.0000\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 0.1640 - precision: 1.0000 - val_loss: 0.2850 - val_precision: 0.0000e+00\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 0.1655 - precision: 1.0000 - val_loss: 0.2828 - val_precision: 1.0000\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 0.1618 - precision: 1.0000 - val_loss: 0.2819 - val_precision: 1.0000\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.1693 - precision: 1.0000 - val_loss: 0.2824 - val_precision: 1.0000\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.1630 - precision: 1.0000 - val_loss: 0.2877 - val_precision: 1.0000\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.1656 - precision: 0.7778 - val_loss: 0.2824 - val_precision: 1.0000\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.1617 - precision: 1.0000 - val_loss: 0.2824 - val_precision: 1.0000\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.1604 - precision: 1.0000 - val_loss: 0.2823 - val_precision: 1.0000\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.1604 - precision: 1.0000 - val_loss: 0.2825 - val_precision: 1.0000\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.1612 - precision: 1.0000 - val_loss: 0.2822 - val_precision: 1.0000\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 0.1653 - precision: 1.0000 - val_loss: 0.2832 - val_precision: 0.0000e+00\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 0.1590 - precision: 0.8333 - val_loss: 0.2863 - val_precision: 1.0000\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 0.1614 - precision: 1.0000 - val_loss: 0.2818 - val_precision: 1.0000\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.1641 - precision: 0.8182 - val_loss: 0.2875 - val_precision: 1.0000\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 0.1612 - precision: 0.8750 - val_loss: 0.2832 - val_precision: 1.0000\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.1878 - precision: 0.7500 - val_loss: 0.2866 - val_precision: 1.0000\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.1767 - precision: 0.8571 - val_loss: 0.3167 - val_precision: 0.0000e+00\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.1690 - precision: 1.0000 - val_loss: 0.2990 - val_precision: 0.5000\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.1668 - precision: 0.8333 - val_loss: 0.2825 - val_precision: 0.0000e+00\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.1652 - precision: 1.0000 - val_loss: 0.2817 - val_precision: 1.0000\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.1588 - precision: 0.8750 - val_loss: 0.2835 - val_precision: 1.0000\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.1574 - precision: 0.8889 - val_loss: 0.2830 - val_precision: 1.0000\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.1658 - precision: 1.0000 - val_loss: 0.2818 - val_precision: 1.0000\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.1585 - precision: 0.9000 - val_loss: 0.2828 - val_precision: 1.0000\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.1560 - precision: 1.0000 - val_loss: 0.2851 - val_precision: 0.0000e+00\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.1603 - precision: 0.8571 - val_loss: 0.2847 - val_precision: 1.0000\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.1561 - precision: 1.0000 - val_loss: 0.2857 - val_precision: 0.0000e+00\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.1627 - precision: 1.0000 - val_loss: 0.2833 - val_precision: 1.0000\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.1563 - precision: 0.9000 - val_loss: 0.2836 - val_precision: 1.0000\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.1562 - precision: 0.8889 - val_loss: 0.2836 - val_precision: 1.0000\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 0.1563 - precision: 0.9000 - val_loss: 0.2847 - val_precision: 1.0000\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 0.1565 - precision: 0.8571 - val_loss: 0.2873 - val_precision: 0.0000e+00\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 0.1627 - precision: 0.7778 - val_loss: 0.2869 - val_precision: 1.0000\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.1539 - precision: 0.8889 - val_loss: 0.2921 - val_precision: 0.0000e+00\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.1675 - precision: 1.0000 - val_loss: 0.2860 - val_precision: 1.0000\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.1551 - precision: 0.9091 - val_loss: 0.2856 - val_precision: 1.0000\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.1562 - precision: 1.0000 - val_loss: 0.2856 - val_precision: 1.0000\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 0.1542 - precision: 0.9000 - val_loss: 0.2859 - val_precision: 1.0000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300\n",
    "history = modelb_glove50.fit(padded, training_labels_final, \n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(val_padded, val_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "precision = history.history['precision']\n",
    "val_precision = history.history['val_precision']\n",
    "epochs=range(len(precision))\n",
    "plt.plot(epochs, precision, 'r')\n",
    "plt.plot(epochs, val_precision, 'b')\n",
    "plt.title('Training and validation Precision')\n",
    "plt.ylim((0,1.5))\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4008 - precision: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4008418023586273, 1.0]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelb_glove50.evaluate(test_padded, test_labels_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRKZWN0GND20"
   },
   "source": [
    "### Model A with bigger GloVe set predicting next interest rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "KIRtRDhbND22",
    "outputId": "d8e6d641-9a20-42a4-b214-600d97c5ab4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('glove.6B.200d.txt', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "qBqmIavPND23"
   },
   "outputs": [],
   "source": [
    "num_tokens = len(range(vocab_size)) + 2\n",
    "embedding_dim = 200\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "        #print(word, end =\"\")\n",
    "        #print(word)\n",
    "#print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "oJsiueUCND24"
   },
   "outputs": [],
   "source": [
    "modela_glove_next_rate = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(embedding_matrix.shape[0], embedding_dim, weights=[embedding_matrix], input_length = max_length, trainable=False),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "BEJaEHrQND24"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "modela_glove_next_rate.compile(loss='binary_crossentropy', \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "dq_i5ChnND25",
    "outputId": "a2b6b88b-3899-46a0-a9e4-b77049f1d57b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1200, 200)         1000400   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 200)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 1206      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,001,613\n",
      "Trainable params: 1,213\n",
      "Non-trainable params: 1,000,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modela_glove_next_rate.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "v0CnyfiOND25",
    "outputId": "e57d71eb-b0a6-47dc-91af-e196ce945fb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 1s 44ms/step - loss: 0.6476 - precision: 0.5000 - val_loss: 0.6311 - val_precision: 0.0000e+00\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.6012 - precision: 0.0000e+00 - val_loss: 0.5965 - val_precision: 0.0000e+00\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.5658 - precision: 0.0000e+00 - val_loss: 0.5692 - val_precision: 0.0000e+00\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.5353 - precision: 0.0000e+00 - val_loss: 0.5446 - val_precision: 0.0000e+00\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.5089 - precision: 0.0000e+00 - val_loss: 0.5226 - val_precision: 0.0000e+00\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.4857 - precision: 0.0000e+00 - val_loss: 0.5028 - val_precision: 0.0000e+00\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.4646 - precision: 0.0000e+00 - val_loss: 0.4844 - val_precision: 0.0000e+00\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.4457 - precision: 0.0000e+00 - val_loss: 0.4682 - val_precision: 0.0000e+00\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.4292 - precision: 0.0000e+00 - val_loss: 0.4537 - val_precision: 0.0000e+00\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.4150 - precision: 0.0000e+00 - val_loss: 0.4419 - val_precision: 0.0000e+00\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.4033 - precision: 0.0000e+00 - val_loss: 0.4297 - val_precision: 0.0000e+00\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3914 - precision: 0.0000e+00 - val_loss: 0.4196 - val_precision: 0.0000e+00\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3815 - precision: 0.0000e+00 - val_loss: 0.4099 - val_precision: 0.0000e+00\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3719 - precision: 0.0000e+00 - val_loss: 0.4005 - val_precision: 0.0000e+00\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.3632 - precision: 0.0000e+00 - val_loss: 0.3923 - val_precision: 0.0000e+00\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.3551 - precision: 0.0000e+00 - val_loss: 0.3846 - val_precision: 0.0000e+00\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3480 - precision: 0.0000e+00 - val_loss: 0.3775 - val_precision: 0.0000e+00\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3421 - precision: 0.0000e+00 - val_loss: 0.3709 - val_precision: 0.0000e+00\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3364 - precision: 0.0000e+00 - val_loss: 0.3653 - val_precision: 0.0000e+00\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3321 - precision: 0.0000e+00 - val_loss: 0.3611 - val_precision: 0.0000e+00\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3281 - precision: 0.0000e+00 - val_loss: 0.3572 - val_precision: 0.0000e+00\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3247 - precision: 0.0000e+00 - val_loss: 0.3532 - val_precision: 0.0000e+00\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3214 - precision: 0.0000e+00 - val_loss: 0.3497 - val_precision: 0.0000e+00\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3188 - precision: 0.0000e+00 - val_loss: 0.3469 - val_precision: 0.0000e+00\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.3169 - precision: 0.0000e+00 - val_loss: 0.3452 - val_precision: 0.0000e+00\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3152 - precision: 0.0000e+00 - val_loss: 0.3434 - val_precision: 0.0000e+00\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3136 - precision: 0.0000e+00 - val_loss: 0.3413 - val_precision: 0.0000e+00\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.3123 - precision: 0.0000e+00 - val_loss: 0.3390 - val_precision: 0.0000e+00\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3102 - precision: 0.0000e+00 - val_loss: 0.3370 - val_precision: 0.0000e+00\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3087 - precision: 0.0000e+00 - val_loss: 0.3351 - val_precision: 0.0000e+00\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3072 - precision: 0.0000e+00 - val_loss: 0.3334 - val_precision: 0.0000e+00\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3059 - precision: 0.0000e+00 - val_loss: 0.3325 - val_precision: 0.0000e+00\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3050 - precision: 0.0000e+00 - val_loss: 0.3313 - val_precision: 0.0000e+00\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.3041 - precision: 0.0000e+00 - val_loss: 0.3300 - val_precision: 0.0000e+00\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.3032 - precision: 0.0000e+00 - val_loss: 0.3288 - val_precision: 0.0000e+00\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.3021 - precision: 0.0000e+00 - val_loss: 0.3278 - val_precision: 0.0000e+00\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3016 - precision: 0.0000e+00 - val_loss: 0.3269 - val_precision: 0.0000e+00\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3008 - precision: 0.0000e+00 - val_loss: 0.3261 - val_precision: 0.0000e+00\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3002 - precision: 0.0000e+00 - val_loss: 0.3254 - val_precision: 0.0000e+00\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2995 - precision: 0.0000e+00 - val_loss: 0.3249 - val_precision: 0.0000e+00\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2990 - precision: 0.0000e+00 - val_loss: 0.3242 - val_precision: 0.0000e+00\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2983 - precision: 0.0000e+00 - val_loss: 0.3237 - val_precision: 0.0000e+00\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2978 - precision: 0.0000e+00 - val_loss: 0.3231 - val_precision: 0.0000e+00\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2972 - precision: 0.0000e+00 - val_loss: 0.3223 - val_precision: 0.0000e+00\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2965 - precision: 0.0000e+00 - val_loss: 0.3218 - val_precision: 0.0000e+00\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.2960 - precision: 0.0000e+00 - val_loss: 0.3211 - val_precision: 0.0000e+00\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2952 - precision: 0.0000e+00 - val_loss: 0.3202 - val_precision: 0.0000e+00\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2944 - precision: 0.0000e+00 - val_loss: 0.3193 - val_precision: 0.0000e+00\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2939 - precision: 0.0000e+00 - val_loss: 0.3184 - val_precision: 0.0000e+00\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2933 - precision: 0.0000e+00 - val_loss: 0.3177 - val_precision: 0.0000e+00\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2928 - precision: 0.0000e+00 - val_loss: 0.3170 - val_precision: 0.0000e+00\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2921 - precision: 0.0000e+00 - val_loss: 0.3164 - val_precision: 0.0000e+00\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2916 - precision: 0.0000e+00 - val_loss: 0.3159 - val_precision: 0.0000e+00\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2912 - precision: 0.0000e+00 - val_loss: 0.3154 - val_precision: 0.0000e+00\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2908 - precision: 0.0000e+00 - val_loss: 0.3150 - val_precision: 0.0000e+00\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2905 - precision: 0.0000e+00 - val_loss: 0.3145 - val_precision: 0.0000e+00\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2899 - precision: 0.0000e+00 - val_loss: 0.3142 - val_precision: 0.0000e+00\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2896 - precision: 0.0000e+00 - val_loss: 0.3137 - val_precision: 0.0000e+00\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2891 - precision: 0.0000e+00 - val_loss: 0.3133 - val_precision: 0.0000e+00\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2888 - precision: 0.0000e+00 - val_loss: 0.3129 - val_precision: 0.0000e+00\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2884 - precision: 0.0000e+00 - val_loss: 0.3125 - val_precision: 0.0000e+00\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2881 - precision: 0.0000e+00 - val_loss: 0.3121 - val_precision: 0.0000e+00\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2876 - precision: 0.0000e+00 - val_loss: 0.3118 - val_precision: 0.0000e+00\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2873 - precision: 0.0000e+00 - val_loss: 0.3115 - val_precision: 0.0000e+00\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2869 - precision: 0.0000e+00 - val_loss: 0.3112 - val_precision: 0.0000e+00\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2867 - precision: 0.0000e+00 - val_loss: 0.3107 - val_precision: 0.0000e+00\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2863 - precision: 0.0000e+00 - val_loss: 0.3105 - val_precision: 0.0000e+00\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2859 - precision: 0.0000e+00 - val_loss: 0.3103 - val_precision: 0.0000e+00\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2856 - precision: 0.0000e+00 - val_loss: 0.3099 - val_precision: 0.0000e+00\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2853 - precision: 0.0000e+00 - val_loss: 0.3096 - val_precision: 0.0000e+00\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2847 - precision: 0.0000e+00 - val_loss: 0.3092 - val_precision: 0.0000e+00\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2843 - precision: 0.0000e+00 - val_loss: 0.3088 - val_precision: 0.0000e+00\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2840 - precision: 0.0000e+00 - val_loss: 0.3084 - val_precision: 0.0000e+00\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2836 - precision: 0.0000e+00 - val_loss: 0.3080 - val_precision: 0.0000e+00\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2832 - precision: 0.0000e+00 - val_loss: 0.3076 - val_precision: 0.0000e+00\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2829 - precision: 0.0000e+00 - val_loss: 0.3072 - val_precision: 0.0000e+00\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2828 - precision: 0.0000e+00 - val_loss: 0.3071 - val_precision: 0.0000e+00\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.2819 - precision: 0.0000e+00 - val_loss: 0.3068 - val_precision: 0.0000e+00\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2816 - precision: 0.0000e+00 - val_loss: 0.3065 - val_precision: 0.0000e+00\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2814 - precision: 0.0000e+00 - val_loss: 0.3062 - val_precision: 0.0000e+00\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2810 - precision: 0.0000e+00 - val_loss: 0.3060 - val_precision: 0.0000e+00\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2809 - precision: 0.0000e+00 - val_loss: 0.3059 - val_precision: 0.0000e+00\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2807 - precision: 0.0000e+00 - val_loss: 0.3056 - val_precision: 0.0000e+00\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2805 - precision: 0.0000e+00 - val_loss: 0.3055 - val_precision: 0.0000e+00\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2803 - precision: 0.0000e+00 - val_loss: 0.3055 - val_precision: 0.0000e+00\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2802 - precision: 0.0000e+00 - val_loss: 0.3053 - val_precision: 0.0000e+00\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2799 - precision: 0.0000e+00 - val_loss: 0.3050 - val_precision: 0.0000e+00\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2796 - precision: 0.0000e+00 - val_loss: 0.3048 - val_precision: 0.0000e+00\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2795 - precision: 0.0000e+00 - val_loss: 0.3048 - val_precision: 0.0000e+00\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2792 - precision: 0.0000e+00 - val_loss: 0.3047 - val_precision: 0.0000e+00\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2791 - precision: 0.0000e+00 - val_loss: 0.3046 - val_precision: 0.0000e+00\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2788 - precision: 0.0000e+00 - val_loss: 0.3044 - val_precision: 0.0000e+00\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2788 - precision: 0.0000e+00 - val_loss: 0.3044 - val_precision: 0.0000e+00\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2785 - precision: 0.0000e+00 - val_loss: 0.3042 - val_precision: 0.0000e+00\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2782 - precision: 0.0000e+00 - val_loss: 0.3037 - val_precision: 0.0000e+00\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2778 - precision: 0.0000e+00 - val_loss: 0.3033 - val_precision: 0.0000e+00\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2776 - precision: 0.0000e+00 - val_loss: 0.3031 - val_precision: 0.0000e+00\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2773 - precision: 0.0000e+00 - val_loss: 0.3028 - val_precision: 0.0000e+00\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2770 - precision: 0.0000e+00 - val_loss: 0.3025 - val_precision: 0.0000e+00\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2767 - precision: 0.0000e+00 - val_loss: 0.3021 - val_precision: 0.0000e+00\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2764 - precision: 0.0000e+00 - val_loss: 0.3018 - val_precision: 0.0000e+00\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2761 - precision: 0.0000e+00 - val_loss: 0.3015 - val_precision: 0.0000e+00\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2761 - precision: 0.0000e+00 - val_loss: 0.3012 - val_precision: 0.0000e+00\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2757 - precision: 0.0000e+00 - val_loss: 0.3010 - val_precision: 0.0000e+00\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2756 - precision: 0.0000e+00 - val_loss: 0.3007 - val_precision: 0.0000e+00\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2753 - precision: 0.0000e+00 - val_loss: 0.3005 - val_precision: 0.0000e+00\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2751 - precision: 0.0000e+00 - val_loss: 0.3005 - val_precision: 0.0000e+00\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2750 - precision: 0.0000e+00 - val_loss: 0.3003 - val_precision: 0.0000e+00\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2749 - precision: 0.0000e+00 - val_loss: 0.3001 - val_precision: 0.0000e+00\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2746 - precision: 0.0000e+00 - val_loss: 0.3000 - val_precision: 0.0000e+00\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2745 - precision: 0.0000e+00 - val_loss: 0.2998 - val_precision: 0.0000e+00\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2743 - precision: 0.0000e+00 - val_loss: 0.2996 - val_precision: 0.0000e+00\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2742 - precision: 0.0000e+00 - val_loss: 0.2995 - val_precision: 0.0000e+00\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2738 - precision: 0.0000e+00 - val_loss: 0.2994 - val_precision: 0.0000e+00\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2737 - precision: 0.0000e+00 - val_loss: 0.2994 - val_precision: 0.0000e+00\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2735 - precision: 0.0000e+00 - val_loss: 0.2993 - val_precision: 0.0000e+00\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2734 - precision: 0.0000e+00 - val_loss: 0.2992 - val_precision: 0.0000e+00\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2734 - precision: 0.0000e+00 - val_loss: 0.2990 - val_precision: 0.0000e+00\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2729 - precision: 0.0000e+00 - val_loss: 0.2989 - val_precision: 0.0000e+00\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2728 - precision: 0.0000e+00 - val_loss: 0.2988 - val_precision: 0.0000e+00\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2727 - precision: 0.0000e+00 - val_loss: 0.2988 - val_precision: 0.0000e+00\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2725 - precision: 0.0000e+00 - val_loss: 0.2986 - val_precision: 0.0000e+00\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.2725 - precision: 0.0000e+00 - val_loss: 0.2985 - val_precision: 0.0000e+00\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2723 - precision: 0.0000e+00 - val_loss: 0.2984 - val_precision: 0.0000e+00\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2722 - precision: 0.0000e+00 - val_loss: 0.2983 - val_precision: 0.0000e+00\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2721 - precision: 0.0000e+00 - val_loss: 0.2981 - val_precision: 0.0000e+00\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2720 - precision: 0.0000e+00 - val_loss: 0.2981 - val_precision: 0.0000e+00\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2721 - precision: 0.0000e+00 - val_loss: 0.2979 - val_precision: 0.0000e+00\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2716 - precision: 0.0000e+00 - val_loss: 0.2979 - val_precision: 0.0000e+00\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2717 - precision: 0.0000e+00 - val_loss: 0.2980 - val_precision: 0.0000e+00\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2715 - precision: 0.0000e+00 - val_loss: 0.2978 - val_precision: 0.0000e+00\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2714 - precision: 0.0000e+00 - val_loss: 0.2976 - val_precision: 0.0000e+00\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2712 - precision: 0.0000e+00 - val_loss: 0.2974 - val_precision: 0.0000e+00\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2712 - precision: 0.0000e+00 - val_loss: 0.2972 - val_precision: 0.0000e+00\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2710 - precision: 0.0000e+00 - val_loss: 0.2971 - val_precision: 0.0000e+00\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2709 - precision: 0.0000e+00 - val_loss: 0.2970 - val_precision: 0.0000e+00\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2708 - precision: 0.0000e+00 - val_loss: 0.2969 - val_precision: 0.0000e+00\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2709 - precision: 0.0000e+00 - val_loss: 0.2969 - val_precision: 0.0000e+00\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2704 - precision: 0.0000e+00 - val_loss: 0.2968 - val_precision: 0.0000e+00\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2703 - precision: 0.0000e+00 - val_loss: 0.2967 - val_precision: 0.0000e+00\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2701 - precision: 0.0000e+00 - val_loss: 0.2966 - val_precision: 0.0000e+00\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2699 - precision: 0.0000e+00 - val_loss: 0.2964 - val_precision: 0.0000e+00\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2700 - precision: 0.0000e+00 - val_loss: 0.2964 - val_precision: 0.0000e+00\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2698 - precision: 0.0000e+00 - val_loss: 0.2963 - val_precision: 0.0000e+00\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2697 - precision: 0.0000e+00 - val_loss: 0.2962 - val_precision: 0.0000e+00\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2695 - precision: 0.0000e+00 - val_loss: 0.2961 - val_precision: 0.0000e+00\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2698 - precision: 0.0000e+00 - val_loss: 0.2961 - val_precision: 0.0000e+00\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2695 - precision: 0.0000e+00 - val_loss: 0.2960 - val_precision: 0.0000e+00\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2695 - precision: 0.0000e+00 - val_loss: 0.2960 - val_precision: 0.0000e+00\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2694 - precision: 0.0000e+00 - val_loss: 0.2960 - val_precision: 0.0000e+00\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2693 - precision: 0.0000e+00 - val_loss: 0.2959 - val_precision: 0.0000e+00\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2693 - precision: 0.0000e+00 - val_loss: 0.2959 - val_precision: 0.0000e+00\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2695 - precision: 0.0000e+00 - val_loss: 0.2959 - val_precision: 0.0000e+00\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2692 - precision: 0.0000e+00 - val_loss: 0.2958 - val_precision: 0.0000e+00\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2692 - precision: 0.0000e+00 - val_loss: 0.2957 - val_precision: 0.0000e+00\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2689 - precision: 0.0000e+00 - val_loss: 0.2956 - val_precision: 0.0000e+00\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2689 - precision: 0.0000e+00 - val_loss: 0.2956 - val_precision: 0.0000e+00\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2688 - precision: 0.0000e+00 - val_loss: 0.2955 - val_precision: 0.0000e+00\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2686 - precision: 0.0000e+00 - val_loss: 0.2955 - val_precision: 0.0000e+00\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2685 - precision: 0.0000e+00 - val_loss: 0.2954 - val_precision: 0.0000e+00\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2685 - precision: 0.0000e+00 - val_loss: 0.2954 - val_precision: 0.0000e+00\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2684 - precision: 0.0000e+00 - val_loss: 0.2954 - val_precision: 0.0000e+00\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2683 - precision: 0.0000e+00 - val_loss: 0.2953 - val_precision: 0.0000e+00\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2682 - precision: 0.0000e+00 - val_loss: 0.2953 - val_precision: 0.0000e+00\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2683 - precision: 0.0000e+00 - val_loss: 0.2952 - val_precision: 0.0000e+00\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2680 - precision: 0.0000e+00 - val_loss: 0.2952 - val_precision: 0.0000e+00\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2680 - precision: 0.0000e+00 - val_loss: 0.2951 - val_precision: 0.0000e+00\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2682 - precision: 0.0000e+00 - val_loss: 0.2951 - val_precision: 0.0000e+00\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2681 - precision: 0.0000e+00 - val_loss: 0.2950 - val_precision: 0.0000e+00\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2677 - precision: 0.0000e+00 - val_loss: 0.2950 - val_precision: 0.0000e+00\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2676 - precision: 0.0000e+00 - val_loss: 0.2950 - val_precision: 0.0000e+00\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2676 - precision: 0.0000e+00 - val_loss: 0.2949 - val_precision: 0.0000e+00\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2677 - precision: 0.0000e+00 - val_loss: 0.2948 - val_precision: 0.0000e+00\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2676 - precision: 0.0000e+00 - val_loss: 0.2948 - val_precision: 0.0000e+00\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2673 - precision: 0.0000e+00 - val_loss: 0.2948 - val_precision: 0.0000e+00\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2672 - precision: 0.0000e+00 - val_loss: 0.2947 - val_precision: 0.0000e+00\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2671 - precision: 0.0000e+00 - val_loss: 0.2947 - val_precision: 0.0000e+00\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2670 - precision: 0.0000e+00 - val_loss: 0.2946 - val_precision: 0.0000e+00\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2672 - precision: 0.0000e+00 - val_loss: 0.2946 - val_precision: 0.0000e+00\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2669 - precision: 0.0000e+00 - val_loss: 0.2945 - val_precision: 0.0000e+00\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2668 - precision: 0.0000e+00 - val_loss: 0.2945 - val_precision: 0.0000e+00\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2669 - precision: 0.0000e+00 - val_loss: 0.2945 - val_precision: 0.0000e+00\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2667 - precision: 0.0000e+00 - val_loss: 0.2945 - val_precision: 0.0000e+00\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2667 - precision: 0.0000e+00 - val_loss: 0.2944 - val_precision: 0.0000e+00\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2666 - precision: 0.0000e+00 - val_loss: 0.2944 - val_precision: 0.0000e+00\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2666 - precision: 0.0000e+00 - val_loss: 0.2944 - val_precision: 0.0000e+00\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2665 - precision: 0.0000e+00 - val_loss: 0.2943 - val_precision: 0.0000e+00\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2664 - precision: 0.0000e+00 - val_loss: 0.2943 - val_precision: 0.0000e+00\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2663 - precision: 0.0000e+00 - val_loss: 0.2943 - val_precision: 0.0000e+00\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2663 - precision: 0.0000e+00 - val_loss: 0.2943 - val_precision: 0.0000e+00\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2661 - precision: 0.0000e+00 - val_loss: 0.2942 - val_precision: 0.0000e+00\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2658 - precision: 0.0000e+00 - val_loss: 0.2941 - val_precision: 0.0000e+00\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2654 - precision: 0.0000e+00 - val_loss: 0.2941 - val_precision: 0.0000e+00\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2657 - precision: 0.0000e+00 - val_loss: 0.2941 - val_precision: 0.0000e+00\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2657 - precision: 0.0000e+00 - val_loss: 0.2940 - val_precision: 0.0000e+00\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2656 - precision: 0.0000e+00 - val_loss: 0.2939 - val_precision: 0.0000e+00\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2656 - precision: 0.0000e+00 - val_loss: 0.2939 - val_precision: 0.0000e+00\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2655 - precision: 0.0000e+00 - val_loss: 0.2938 - val_precision: 0.0000e+00\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2654 - precision: 0.0000e+00 - val_loss: 0.2938 - val_precision: 0.0000e+00\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2654 - precision: 0.0000e+00 - val_loss: 0.2938 - val_precision: 0.0000e+00\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2654 - precision: 0.0000e+00 - val_loss: 0.2937 - val_precision: 0.0000e+00\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2652 - precision: 0.0000e+00 - val_loss: 0.2937 - val_precision: 0.0000e+00\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2652 - precision: 0.0000e+00 - val_loss: 0.2939 - val_precision: 0.0000e+00\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2651 - precision: 0.0000e+00 - val_loss: 0.2939 - val_precision: 0.0000e+00\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2650 - precision: 0.0000e+00 - val_loss: 0.2937 - val_precision: 0.0000e+00\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2649 - precision: 0.0000e+00 - val_loss: 0.2936 - val_precision: 0.0000e+00\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2648 - precision: 0.0000e+00 - val_loss: 0.2935 - val_precision: 0.0000e+00\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2646 - precision: 0.0000e+00 - val_loss: 0.2934 - val_precision: 0.0000e+00\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2646 - precision: 0.0000e+00 - val_loss: 0.2934 - val_precision: 0.0000e+00\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2645 - precision: 0.0000e+00 - val_loss: 0.2934 - val_precision: 0.0000e+00\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2645 - precision: 0.0000e+00 - val_loss: 0.2934 - val_precision: 0.0000e+00\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2645 - precision: 0.0000e+00 - val_loss: 0.2933 - val_precision: 0.0000e+00\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2644 - precision: 0.0000e+00 - val_loss: 0.2932 - val_precision: 0.0000e+00\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2648 - precision: 0.0000e+00 - val_loss: 0.2936 - val_precision: 0.0000e+00\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2645 - precision: 0.0000e+00 - val_loss: 0.2936 - val_precision: 0.0000e+00\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2643 - precision: 0.0000e+00 - val_loss: 0.2934 - val_precision: 0.0000e+00\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2641 - precision: 0.0000e+00 - val_loss: 0.2933 - val_precision: 0.0000e+00\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2640 - precision: 0.0000e+00 - val_loss: 0.2931 - val_precision: 0.0000e+00\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2638 - precision: 0.0000e+00 - val_loss: 0.2930 - val_precision: 0.0000e+00\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2640 - precision: 0.0000e+00 - val_loss: 0.2929 - val_precision: 0.0000e+00\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2637 - precision: 0.0000e+00 - val_loss: 0.2929 - val_precision: 0.0000e+00\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2636 - precision: 0.0000e+00 - val_loss: 0.2929 - val_precision: 0.0000e+00\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2637 - precision: 0.0000e+00 - val_loss: 0.2928 - val_precision: 0.0000e+00\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2635 - precision: 0.0000e+00 - val_loss: 0.2928 - val_precision: 0.0000e+00\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2634 - precision: 0.0000e+00 - val_loss: 0.2928 - val_precision: 0.0000e+00\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2634 - precision: 0.0000e+00 - val_loss: 0.2928 - val_precision: 0.0000e+00\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2634 - precision: 0.0000e+00 - val_loss: 0.2928 - val_precision: 0.0000e+00\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2634 - precision: 0.0000e+00 - val_loss: 0.2928 - val_precision: 0.0000e+00\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2633 - precision: 0.0000e+00 - val_loss: 0.2926 - val_precision: 0.0000e+00\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2630 - precision: 0.0000e+00 - val_loss: 0.2926 - val_precision: 0.0000e+00\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2629 - precision: 0.0000e+00 - val_loss: 0.2925 - val_precision: 0.0000e+00\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2628 - precision: 0.0000e+00 - val_loss: 0.2925 - val_precision: 0.0000e+00\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2627 - precision: 0.0000e+00 - val_loss: 0.2925 - val_precision: 0.0000e+00\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2627 - precision: 0.0000e+00 - val_loss: 0.2924 - val_precision: 0.0000e+00\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2627 - precision: 0.0000e+00 - val_loss: 0.2924 - val_precision: 0.0000e+00\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2625 - precision: 0.0000e+00 - val_loss: 0.2923 - val_precision: 0.0000e+00\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2624 - precision: 0.0000e+00 - val_loss: 0.2923 - val_precision: 0.0000e+00\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2624 - precision: 0.0000e+00 - val_loss: 0.2923 - val_precision: 0.0000e+00\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2624 - precision: 0.0000e+00 - val_loss: 0.2923 - val_precision: 0.0000e+00\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2627 - precision: 0.0000e+00 - val_loss: 0.2923 - val_precision: 0.0000e+00\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2624 - precision: 0.0000e+00 - val_loss: 0.2922 - val_precision: 0.0000e+00\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2620 - precision: 0.0000e+00 - val_loss: 0.2921 - val_precision: 0.0000e+00\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2619 - precision: 0.0000e+00 - val_loss: 0.2921 - val_precision: 0.0000e+00\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2621 - precision: 0.0000e+00 - val_loss: 0.2921 - val_precision: 0.0000e+00\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2617 - precision: 0.0000e+00 - val_loss: 0.2923 - val_precision: 0.0000e+00\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2623 - precision: 0.0000e+00 - val_loss: 0.2926 - val_precision: 0.0000e+00\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2626 - precision: 0.0000e+00 - val_loss: 0.2929 - val_precision: 0.0000e+00\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2624 - precision: 0.0000e+00 - val_loss: 0.2925 - val_precision: 0.0000e+00\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2617 - precision: 0.0000e+00 - val_loss: 0.2922 - val_precision: 0.0000e+00\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2615 - precision: 0.0000e+00 - val_loss: 0.2919 - val_precision: 0.0000e+00\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2614 - precision: 0.0000e+00 - val_loss: 0.2917 - val_precision: 0.0000e+00\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2614 - precision: 0.0000e+00 - val_loss: 0.2917 - val_precision: 0.0000e+00\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2614 - precision: 0.0000e+00 - val_loss: 0.2917 - val_precision: 0.0000e+00\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2612 - precision: 0.0000e+00 - val_loss: 0.2916 - val_precision: 0.0000e+00\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2610 - precision: 0.0000e+00 - val_loss: 0.2916 - val_precision: 0.0000e+00\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2610 - precision: 0.0000e+00 - val_loss: 0.2915 - val_precision: 0.0000e+00\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2613 - precision: 0.0000e+00 - val_loss: 0.2915 - val_precision: 0.0000e+00\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2609 - precision: 0.0000e+00 - val_loss: 0.2915 - val_precision: 0.0000e+00\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2610 - precision: 0.0000e+00 - val_loss: 0.2915 - val_precision: 0.0000e+00\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2609 - precision: 0.0000e+00 - val_loss: 0.2915 - val_precision: 0.0000e+00\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2609 - precision: 0.0000e+00 - val_loss: 0.2915 - val_precision: 0.0000e+00\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2607 - precision: 0.0000e+00 - val_loss: 0.2914 - val_precision: 0.0000e+00\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2606 - precision: 0.0000e+00 - val_loss: 0.2914 - val_precision: 0.0000e+00\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2605 - precision: 0.0000e+00 - val_loss: 0.2913 - val_precision: 0.0000e+00\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2604 - precision: 0.0000e+00 - val_loss: 0.2913 - val_precision: 0.0000e+00\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2606 - precision: 0.0000e+00 - val_loss: 0.2913 - val_precision: 0.0000e+00\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2604 - precision: 0.0000e+00 - val_loss: 0.2913 - val_precision: 0.0000e+00\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2603 - precision: 0.0000e+00 - val_loss: 0.2912 - val_precision: 0.0000e+00\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2602 - precision: 0.0000e+00 - val_loss: 0.2912 - val_precision: 0.0000e+00\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2601 - precision: 0.0000e+00 - val_loss: 0.2911 - val_precision: 0.0000e+00\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2600 - precision: 0.0000e+00 - val_loss: 0.2911 - val_precision: 0.0000e+00\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2599 - precision: 0.0000e+00 - val_loss: 0.2910 - val_precision: 0.0000e+00\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2599 - precision: 0.0000e+00 - val_loss: 0.2910 - val_precision: 0.0000e+00\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2598 - precision: 0.0000e+00 - val_loss: 0.2910 - val_precision: 0.0000e+00\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2598 - precision: 0.0000e+00 - val_loss: 0.2909 - val_precision: 0.0000e+00\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2596 - precision: 0.0000e+00 - val_loss: 0.2909 - val_precision: 0.0000e+00\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2594 - precision: 0.0000e+00 - val_loss: 0.2908 - val_precision: 0.0000e+00\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2609 - precision: 0.0000e+00 - val_loss: 0.2911 - val_precision: 0.0000e+00\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2595 - precision: 0.0000e+00 - val_loss: 0.2910 - val_precision: 0.0000e+00\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2594 - precision: 0.0000e+00 - val_loss: 0.2909 - val_precision: 0.0000e+00\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2592 - precision: 0.0000e+00 - val_loss: 0.2908 - val_precision: 0.0000e+00\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2591 - precision: 0.0000e+00 - val_loss: 0.2907 - val_precision: 0.0000e+00\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2590 - precision: 0.0000e+00 - val_loss: 0.2906 - val_precision: 0.0000e+00\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2590 - precision: 0.0000e+00 - val_loss: 0.2906 - val_precision: 0.0000e+00\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2590 - precision: 0.0000e+00 - val_loss: 0.2906 - val_precision: 0.0000e+00\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2589 - precision: 0.0000e+00 - val_loss: 0.2905 - val_precision: 0.0000e+00\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2588 - precision: 0.0000e+00 - val_loss: 0.2905 - val_precision: 0.0000e+00\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2589 - precision: 0.0000e+00 - val_loss: 0.2905 - val_precision: 0.0000e+00\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2588 - precision: 0.0000e+00 - val_loss: 0.2905 - val_precision: 0.0000e+00\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2588 - precision: 0.0000e+00 - val_loss: 0.2905 - val_precision: 0.0000e+00\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2587 - precision: 0.0000e+00 - val_loss: 0.2905 - val_precision: 0.0000e+00\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2586 - precision: 0.0000e+00 - val_loss: 0.2904 - val_precision: 0.0000e+00\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2580 - precision: 0.0000e+00 - val_loss: 0.2902 - val_precision: 0.0000e+00\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2582 - precision: 0.0000e+00 - val_loss: 0.2902 - val_precision: 0.0000e+00\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2580 - precision: 0.0000e+00 - val_loss: 0.2902 - val_precision: 0.0000e+00\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2581 - precision: 0.0000e+00 - val_loss: 0.2901 - val_precision: 0.0000e+00\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2578 - precision: 0.0000e+00 - val_loss: 0.2901 - val_precision: 0.0000e+00\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2578 - precision: 0.0000e+00 - val_loss: 0.2900 - val_precision: 0.0000e+00\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2578 - precision: 0.0000e+00 - val_loss: 0.2900 - val_precision: 0.0000e+00\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2578 - precision: 0.0000e+00 - val_loss: 0.2900 - val_precision: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300\n",
    "history = modela_glove_next_rate.fit(padded, training_labels_final, \n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(val_padded, val_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "J6cOVKfVND25",
    "outputId": "412b54a0-e97a-48b8-f4c5-32097e44328a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "precision = history.history['precision']\n",
    "val_precision = history.history['val_precision']\n",
    "epochs=range(len(precision))\n",
    "plt.plot(epochs, precision, 'r')\n",
    "plt.plot(epochs, val_precision, 'b')\n",
    "plt.title('Training and validation Precision')\n",
    "plt.ylim((0,1.5))\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "pNWiLctvND26",
    "outputId": "49befbd2-e0d0-437e-fc11-4026b5874610",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3638 - precision: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36378490924835205, 0.0]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modela_glove_next_rate.evaluate(test_padded, test_labels_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model B, GloVE 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelb_glove200 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], input_length = max_length, trainable=False),  \n",
    "    tf.keras.layers.Conv1D(128, 5, activation=\"relu\"),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "modelb_glove200.compile(loss='binary_crossentropy', \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1200, 200)         1000400   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 1196, 128)         128128    \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 774       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,129,309\n",
      "Trainable params: 128,909\n",
      "Non-trainable params: 1,000,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelb_glove200.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 2s 158ms/step - loss: 0.5896 - precision: 0.0000e+00 - val_loss: 0.5188 - val_precision: 0.0000e+00\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 141ms/step - loss: 0.4398 - precision: 0.0000e+00 - val_loss: 0.4280 - val_precision: 0.0000e+00\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 0.3700 - precision: 0.0000e+00 - val_loss: 0.3857 - val_precision: 0.0000e+00\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 0.3403 - precision: 0.0000e+00 - val_loss: 0.3672 - val_precision: 0.0000e+00\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 0.3344 - precision: 0.0000e+00 - val_loss: 0.3588 - val_precision: 0.0000e+00\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 128ms/step - loss: 0.3291 - precision: 0.0000e+00 - val_loss: 0.3537 - val_precision: 0.0000e+00\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 0.3244 - precision: 0.0000e+00 - val_loss: 0.3491 - val_precision: 0.0000e+00\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.3205 - precision: 0.0000e+00 - val_loss: 0.3454 - val_precision: 0.0000e+00\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.3155 - precision: 0.0000e+00 - val_loss: 0.3418 - val_precision: 0.0000e+00\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.3152 - precision: 0.0000e+00 - val_loss: 0.3434 - val_precision: 0.0000e+00\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.3096 - precision: 0.0000e+00 - val_loss: 0.3375 - val_precision: 0.0000e+00\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 129ms/step - loss: 0.3043 - precision: 0.0000e+00 - val_loss: 0.3334 - val_precision: 0.0000e+00\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 143ms/step - loss: 0.2992 - precision: 0.0000e+00 - val_loss: 0.3275 - val_precision: 0.0000e+00\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.2938 - precision: 0.0000e+00 - val_loss: 0.3220 - val_precision: 0.0000e+00\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.2900 - precision: 0.0000e+00 - val_loss: 0.3181 - val_precision: 0.0000e+00\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.2859 - precision: 0.0000e+00 - val_loss: 0.3143 - val_precision: 0.0000e+00\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.2819 - precision: 0.0000e+00 - val_loss: 0.3103 - val_precision: 0.0000e+00\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 0.2792 - precision: 0.0000e+00 - val_loss: 0.3075 - val_precision: 0.0000e+00\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.2749 - precision: 0.0000e+00 - val_loss: 0.3046 - val_precision: 0.0000e+00\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 2s 198ms/step - loss: 0.2688 - precision: 0.0000e+00 - val_loss: 0.3040 - val_precision: 0.0000e+00\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 2s 199ms/step - loss: 0.2681 - precision: 0.0000e+00 - val_loss: 0.3012 - val_precision: 0.0000e+00\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 0.2647 - precision: 0.0000e+00 - val_loss: 0.2988 - val_precision: 0.0000e+00\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.2630 - precision: 0.0000e+00 - val_loss: 0.2976 - val_precision: 0.0000e+00\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.2610 - precision: 0.0000e+00 - val_loss: 0.2967 - val_precision: 0.0000e+00\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 2s 170ms/step - loss: 0.2588 - precision: 0.0000e+00 - val_loss: 0.3024 - val_precision: 0.0000e+00\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 160ms/step - loss: 0.2651 - precision: 0.0000e+00 - val_loss: 0.3007 - val_precision: 0.0000e+00\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 143ms/step - loss: 0.2600 - precision: 0.0000e+00 - val_loss: 0.2957 - val_precision: 0.0000e+00\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 142ms/step - loss: 0.2605 - precision: 0.0000e+00 - val_loss: 0.2958 - val_precision: 0.0000e+00\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 142ms/step - loss: 0.2584 - precision: 0.0000e+00 - val_loss: 0.2954 - val_precision: 0.0000e+00\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.2572 - precision: 0.0000e+00 - val_loss: 0.2950 - val_precision: 0.0000e+00\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 165ms/step - loss: 0.2550 - precision: 0.0000e+00 - val_loss: 0.2942 - val_precision: 0.0000e+00\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 162ms/step - loss: 0.2583 - precision: 0.0000e+00 - val_loss: 0.2962 - val_precision: 0.0000e+00\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 1s 164ms/step - loss: 0.2545 - precision: 0.0000e+00 - val_loss: 0.2938 - val_precision: 0.0000e+00\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 165ms/step - loss: 0.2526 - precision: 0.0000e+00 - val_loss: 0.2938 - val_precision: 0.0000e+00\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 0.2530 - precision: 0.0000e+00 - val_loss: 0.2944 - val_precision: 0.0000e+00\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 2s 191ms/step - loss: 0.2532 - precision: 0.0000e+00 - val_loss: 0.2937 - val_precision: 0.0000e+00\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.2508 - precision: 0.0000e+00 - val_loss: 0.2936 - val_precision: 0.0000e+00\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.2515 - precision: 0.0000e+00 - val_loss: 0.2932 - val_precision: 0.0000e+00\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.2497 - precision: 0.0000e+00 - val_loss: 0.2930 - val_precision: 0.0000e+00\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 1s 124ms/step - loss: 0.2496 - precision: 0.0000e+00 - val_loss: 0.2963 - val_precision: 0.0000e+00\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.2501 - precision: 0.0000e+00 - val_loss: 0.2937 - val_precision: 0.0000e+00\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.2460 - precision: 0.0000e+00 - val_loss: 0.2965 - val_precision: 0.0000e+00\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.2492 - precision: 0.0000e+00 - val_loss: 0.2937 - val_precision: 0.0000e+00\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.2474 - precision: 0.0000e+00 - val_loss: 0.2937 - val_precision: 0.0000e+00\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 1s 160ms/step - loss: 0.2451 - precision: 0.0000e+00 - val_loss: 0.2950 - val_precision: 0.0000e+00\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 1s 141ms/step - loss: 0.2470 - precision: 0.0000e+00 - val_loss: 0.2937 - val_precision: 0.0000e+00\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 1s 169ms/step - loss: 0.2436 - precision: 0.0000e+00 - val_loss: 0.2939 - val_precision: 0.0000e+00\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.2427 - precision: 0.0000e+00 - val_loss: 0.2945 - val_precision: 0.0000e+00\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 1s 167ms/step - loss: 0.2431 - precision: 0.0000e+00 - val_loss: 0.2940 - val_precision: 0.0000e+00\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.2400 - precision: 0.0000e+00 - val_loss: 0.2926 - val_precision: 0.0000e+00\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 0.2401 - precision: 0.0000e+00 - val_loss: 0.2922 - val_precision: 0.0000e+00\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.2382 - precision: 0.0000e+00 - val_loss: 0.2915 - val_precision: 0.0000e+00\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.2363 - precision: 0.0000e+00 - val_loss: 0.2916 - val_precision: 0.0000e+00\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 1s 162ms/step - loss: 0.2346 - precision: 0.0000e+00 - val_loss: 0.2901 - val_precision: 0.0000e+00\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 0.2333 - precision: 0.0000e+00 - val_loss: 0.2884 - val_precision: 0.0000e+00\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 2s 171ms/step - loss: 0.2351 - precision: 0.0000e+00 - val_loss: 0.2874 - val_precision: 0.0000e+00\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 0.2317 - precision: 0.0000e+00 - val_loss: 0.2875 - val_precision: 0.0000e+00\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 2s 165ms/step - loss: 0.2321 - precision: 0.0000e+00 - val_loss: 0.2865 - val_precision: 0.0000e+00\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 1s 142ms/step - loss: 0.2298 - precision: 0.0000e+00 - val_loss: 0.2859 - val_precision: 0.0000e+00\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 1s 143ms/step - loss: 0.2249 - precision: 0.0000e+00 - val_loss: 0.2852 - val_precision: 0.0000e+00\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.2261 - precision: 0.0000e+00 - val_loss: 0.2850 - val_precision: 0.0000e+00\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 1s 141ms/step - loss: 0.2251 - precision: 0.0000e+00 - val_loss: 0.2868 - val_precision: 0.0000e+00\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 1s 137ms/step - loss: 0.2289 - precision: 0.0000e+00 - val_loss: 0.2865 - val_precision: 0.0000e+00\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 0.2228 - precision: 0.0000e+00 - val_loss: 0.2843 - val_precision: 0.0000e+00\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 1s 163ms/step - loss: 0.2216 - precision: 0.0000e+00 - val_loss: 0.2880 - val_precision: 0.0000e+00\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 1s 165ms/step - loss: 0.2269 - precision: 0.0000e+00 - val_loss: 0.2840 - val_precision: 0.0000e+00\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 0.2214 - precision: 0.0000e+00 - val_loss: 0.2844 - val_precision: 0.0000e+00\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.2185 - precision: 0.0000e+00 - val_loss: 0.2837 - val_precision: 0.0000e+00\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.2159 - precision: 0.0000e+00 - val_loss: 0.2845 - val_precision: 0.0000e+00\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.2210 - precision: 0.0000e+00 - val_loss: 0.2845 - val_precision: 0.0000e+00\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.2218 - precision: 0.0000e+00 - val_loss: 0.2881 - val_precision: 0.0000e+00\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.2150 - precision: 0.0000e+00 - val_loss: 0.2847 - val_precision: 0.0000e+00\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.2104 - precision: 0.0000e+00 - val_loss: 0.2838 - val_precision: 0.0000e+00\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.2098 - precision: 0.0000e+00 - val_loss: 0.2837 - val_precision: 0.0000e+00\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 0.2072 - precision: 0.0000e+00 - val_loss: 0.2838 - val_precision: 0.0000e+00\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 1s 156ms/step - loss: 0.2215 - precision: 0.0000e+00 - val_loss: 0.2862 - val_precision: 0.0000e+00\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 1s 137ms/step - loss: 0.2200 - precision: 0.0000e+00 - val_loss: 0.2846 - val_precision: 0.0000e+00\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.2100 - precision: 0.0000e+00 - val_loss: 0.2944 - val_precision: 0.0000e+00\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 1s 143ms/step - loss: 0.2120 - precision: 0.0000e+00 - val_loss: 0.2860 - val_precision: 0.0000e+00\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 0.2053 - precision: 0.0000e+00 - val_loss: 0.2832 - val_precision: 0.0000e+00\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 0.2027 - precision: 0.0000e+00 - val_loss: 0.2835 - val_precision: 0.0000e+00\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.2003 - precision: 0.0000e+00 - val_loss: 0.2860 - val_precision: 0.0000e+00\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 1s 160ms/step - loss: 0.2012 - precision: 0.0000e+00 - val_loss: 0.2839 - val_precision: 0.0000e+00\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 1s 162ms/step - loss: 0.2032 - precision: 0.0000e+00 - val_loss: 0.2842 - val_precision: 0.0000e+00\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.2039 - precision: 0.0000e+00 - val_loss: 0.2847 - val_precision: 0.0000e+00\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.2026 - precision: 0.0000e+00 - val_loss: 0.2879 - val_precision: 0.0000e+00\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 1s 156ms/step - loss: 0.2029 - precision: 0.0000e+00 - val_loss: 0.2941 - val_precision: 0.0000e+00\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 1s 160ms/step - loss: 0.2185 - precision: 0.0000e+00 - val_loss: 0.2839 - val_precision: 0.0000e+00\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 0.2046 - precision: 0.0000e+00 - val_loss: 0.2888 - val_precision: 0.0000e+00\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 0.1935 - precision: 0.0000e+00 - val_loss: 0.2899 - val_precision: 0.0000e+00\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.2005 - precision: 0.0000e+00 - val_loss: 0.2846 - val_precision: 0.0000e+00\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.1957 - precision: 0.0000e+00 - val_loss: 0.2851 - val_precision: 0.0000e+00\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.2130 - precision: 0.0000e+00 - val_loss: 0.2845 - val_precision: 0.0000e+00\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.1989 - precision: 0.0000e+00 - val_loss: 0.2945 - val_precision: 0.0000e+00\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.1986 - precision: 0.0000e+00 - val_loss: 0.2831 - val_precision: 0.0000e+00\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 1s 160ms/step - loss: 0.1918 - precision: 0.0000e+00 - val_loss: 0.2873 - val_precision: 0.0000e+00\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.1959 - precision: 0.0000e+00 - val_loss: 0.2847 - val_precision: 0.0000e+00\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 0.1927 - precision: 0.0000e+00 - val_loss: 0.2859 - val_precision: 0.0000e+00\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.1884 - precision: 0.0000e+00 - val_loss: 0.2877 - val_precision: 0.0000e+00\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.1869 - precision: 0.0000e+00 - val_loss: 0.2868 - val_precision: 0.0000e+00\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.1880 - precision: 0.0000e+00 - val_loss: 0.2892 - val_precision: 0.0000e+00\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.1860 - precision: 0.0000e+00 - val_loss: 0.2870 - val_precision: 0.0000e+00\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.1853 - precision: 0.0000e+00 - val_loss: 0.2891 - val_precision: 0.0000e+00\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 1s 160ms/step - loss: 0.1849 - precision: 0.0000e+00 - val_loss: 0.2882 - val_precision: 0.0000e+00\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 0.1849 - precision: 0.0000e+00 - val_loss: 0.2900 - val_precision: 0.0000e+00\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.1839 - precision: 0.0000e+00 - val_loss: 0.2910 - val_precision: 0.0000e+00\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 1s 140ms/step - loss: 0.1909 - precision: 0.0000e+00 - val_loss: 0.2885 - val_precision: 0.0000e+00\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 0.2006 - precision: 0.0000e+00 - val_loss: 0.2942 - val_precision: 0.0000e+00\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.1786 - precision: 0.0000e+00 - val_loss: 0.2930 - val_precision: 0.0000e+00\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 0.1844 - precision: 0.0000e+00 - val_loss: 0.2887 - val_precision: 0.0000e+00\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.1934 - precision: 0.0000e+00 - val_loss: 0.2913 - val_precision: 0.0000e+00\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 1s 164ms/step - loss: 0.1800 - precision: 0.0000e+00 - val_loss: 0.2924 - val_precision: 0.0000e+00\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 1s 156ms/step - loss: 0.1822 - precision: 0.0000e+00 - val_loss: 0.2884 - val_precision: 0.0000e+00\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 1s 130ms/step - loss: 0.1831 - precision: 0.0000e+00 - val_loss: 0.2894 - val_precision: 0.0000e+00\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.1791 - precision: 0.0000e+00 - val_loss: 0.2951 - val_precision: 0.0000e+00\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 1s 142ms/step - loss: 0.1840 - precision: 0.0000e+00 - val_loss: 0.2917 - val_precision: 0.0000e+00\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 1s 142ms/step - loss: 0.1838 - precision: 0.0000e+00 - val_loss: 0.2945 - val_precision: 0.0000e+00\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 2s 169ms/step - loss: 0.1747 - precision: 0.0000e+00 - val_loss: 0.2966 - val_precision: 0.0000e+00\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 0.1854 - precision: 0.0000e+00 - val_loss: 0.2928 - val_precision: 0.0000e+00\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 0.1774 - precision: 0.0000e+00 - val_loss: 0.2952 - val_precision: 0.0000e+00\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 2s 169ms/step - loss: 0.1788 - precision: 0.0000e+00 - val_loss: 0.2944 - val_precision: 0.0000e+00\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 1s 166ms/step - loss: 0.1744 - precision: 0.0000e+00 - val_loss: 0.2993 - val_precision: 0.0000e+00\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.1752 - precision: 0.0000e+00 - val_loss: 0.2945 - val_precision: 0.0000e+00\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 0.1737 - precision: 0.0000e+00 - val_loss: 0.2920 - val_precision: 0.0000e+00\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.1724 - precision: 0.0000e+00 - val_loss: 0.2939 - val_precision: 0.0000e+00\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 0.1746 - precision: 0.0000e+00 - val_loss: 0.2919 - val_precision: 0.0000e+00\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 0.1735 - precision: 0.0000e+00 - val_loss: 0.2917 - val_precision: 0.0000e+00\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 1s 153ms/step - loss: 0.1808 - precision: 0.0000e+00 - val_loss: 0.2922 - val_precision: 0.0000e+00\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 1s 141ms/step - loss: 0.1702 - precision: 0.0000e+00 - val_loss: 0.2951 - val_precision: 0.0000e+00\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 1s 136ms/step - loss: 0.1753 - precision: 0.6667 - val_loss: 0.2927 - val_precision: 0.0000e+00\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.1693 - precision: 1.0000 - val_loss: 0.2936 - val_precision: 0.0000e+00\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 1s 126ms/step - loss: 0.1699 - precision: 1.0000 - val_loss: 0.2943 - val_precision: 0.0000e+00\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 1s 142ms/step - loss: 0.1692 - precision: 1.0000 - val_loss: 0.2956 - val_precision: 0.0000e+00\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 1s 153ms/step - loss: 0.1677 - precision: 1.0000 - val_loss: 0.2974 - val_precision: 0.0000e+00\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 0.1690 - precision: 1.0000 - val_loss: 0.2996 - val_precision: 0.0000e+00\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.1696 - precision: 1.0000 - val_loss: 0.2993 - val_precision: 0.0000e+00\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 1s 163ms/step - loss: 0.1667 - precision: 1.0000 - val_loss: 0.3006 - val_precision: 0.0000e+00\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 0.1704 - precision: 1.0000 - val_loss: 0.2975 - val_precision: 1.0000\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.1688 - precision: 1.0000 - val_loss: 0.2975 - val_precision: 0.0000e+00\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 1s 138ms/step - loss: 0.1650 - precision: 1.0000 - val_loss: 0.2978 - val_precision: 0.0000e+00\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 1s 163ms/step - loss: 0.1654 - precision: 1.0000 - val_loss: 0.2985 - val_precision: 0.0000e+00\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 2s 170ms/step - loss: 0.1667 - precision: 1.0000 - val_loss: 0.2990 - val_precision: 0.0000e+00\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.1728 - precision: 0.9000 - val_loss: 0.2995 - val_precision: 0.0000e+00\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.1681 - precision: 1.0000 - val_loss: 0.3003 - val_precision: 0.0000e+00\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 1s 167ms/step - loss: 0.1640 - precision: 1.0000 - val_loss: 0.2994 - val_precision: 0.0000e+00\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.1632 - precision: 1.0000 - val_loss: 0.3005 - val_precision: 0.0000e+00\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 2s 170ms/step - loss: 0.1676 - precision: 1.0000 - val_loss: 0.3006 - val_precision: 1.0000\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 1s 168ms/step - loss: 0.1657 - precision: 0.9000 - val_loss: 0.3005 - val_precision: 0.0000e+00\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 0.1656 - precision: 1.0000 - val_loss: 0.3009 - val_precision: 0.0000e+00\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 1s 162ms/step - loss: 0.1620 - precision: 0.8571 - val_loss: 0.3007 - val_precision: 1.0000\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.1632 - precision: 1.0000 - val_loss: 0.3016 - val_precision: 1.0000\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 1s 124ms/step - loss: 0.1625 - precision: 1.0000 - val_loss: 0.3037 - val_precision: 0.0000e+00\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 1s 126ms/step - loss: 0.1598 - precision: 1.0000 - val_loss: 0.3033 - val_precision: 0.0000e+00\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 1s 135ms/step - loss: 0.1593 - precision: 1.0000 - val_loss: 0.3035 - val_precision: 0.0000e+00\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 1s 140ms/step - loss: 0.1578 - precision: 1.0000 - val_loss: 0.3052 - val_precision: 0.0000e+00\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.1605 - precision: 1.0000 - val_loss: 0.3039 - val_precision: 1.0000\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.1600 - precision: 0.8333 - val_loss: 0.3039 - val_precision: 1.0000\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.1627 - precision: 0.9091 - val_loss: 0.3047 - val_precision: 0.0000e+00\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 0.1572 - precision: 1.0000 - val_loss: 0.3062 - val_precision: 0.0000e+00\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 0.1589 - precision: 1.0000 - val_loss: 0.3050 - val_precision: 0.0000e+00\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.1582 - precision: 1.0000 - val_loss: 0.3053 - val_precision: 0.0000e+00\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.1600 - precision: 1.0000 - val_loss: 0.3066 - val_precision: 0.0000e+00\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.1607 - precision: 0.8750 - val_loss: 0.3065 - val_precision: 0.0000e+00\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 0.1554 - precision: 1.0000 - val_loss: 0.3078 - val_precision: 0.0000e+00\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.1556 - precision: 1.0000 - val_loss: 0.3060 - val_precision: 0.0000e+00\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.1542 - precision: 1.0000 - val_loss: 0.3078 - val_precision: 0.0000e+00\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 1s 140ms/step - loss: 0.1539 - precision: 1.0000 - val_loss: 0.3080 - val_precision: 0.0000e+00\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 1s 162ms/step - loss: 0.1560 - precision: 1.0000 - val_loss: 0.3070 - val_precision: 0.5000\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 1s 160ms/step - loss: 0.1541 - precision: 0.8889 - val_loss: 0.3096 - val_precision: 1.0000\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.1576 - precision: 1.0000 - val_loss: 0.3052 - val_precision: 1.0000\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.1562 - precision: 0.8750 - val_loss: 0.3068 - val_precision: 1.0000\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.1537 - precision: 0.8571 - val_loss: 0.3059 - val_precision: 0.5000\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 0.1578 - precision: 0.8000 - val_loss: 0.3068 - val_precision: 0.0000e+00\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 0.1654 - precision: 1.0000 - val_loss: 0.3049 - val_precision: 0.0000e+00\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 0.1620 - precision: 0.9167 - val_loss: 0.3034 - val_precision: 0.5000\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 0.1567 - precision: 1.0000 - val_loss: 0.3045 - val_precision: 0.5000\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 1s 153ms/step - loss: 0.1624 - precision: 0.8000 - val_loss: 0.3040 - val_precision: 0.5000\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 1s 166ms/step - loss: 0.1595 - precision: 1.0000 - val_loss: 0.3069 - val_precision: 0.0000e+00\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.1576 - precision: 0.8182 - val_loss: 0.3041 - val_precision: 0.5000\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.1514 - precision: 0.8333 - val_loss: 0.3069 - val_precision: 1.0000\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 0.1506 - precision: 0.8333 - val_loss: 0.3072 - val_precision: 0.5000\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 2s 169ms/step - loss: 0.1516 - precision: 1.0000 - val_loss: 0.3083 - val_precision: 0.5000\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.1500 - precision: 0.9000 - val_loss: 0.3110 - val_precision: 1.0000\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 1s 160ms/step - loss: 0.1512 - precision: 0.8750 - val_loss: 0.3093 - val_precision: 1.0000\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 1s 167ms/step - loss: 0.1506 - precision: 0.8571 - val_loss: 0.3093 - val_precision: 0.5000\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 0.1549 - precision: 1.0000 - val_loss: 0.3087 - val_precision: 0.5000\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 1s 165ms/step - loss: 0.1489 - precision: 0.8889 - val_loss: 0.3146 - val_precision: 0.0000e+00\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.1530 - precision: 0.8750 - val_loss: 0.3072 - val_precision: 0.5000\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 2s 170ms/step - loss: 0.1483 - precision: 0.8750 - val_loss: 0.3159 - val_precision: 0.0000e+00\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.1495 - precision: 0.8889 - val_loss: 0.3080 - val_precision: 0.5000\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.1557 - precision: 0.8571 - val_loss: 0.3083 - val_precision: 0.5000\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 1s 165ms/step - loss: 0.1519 - precision: 1.0000 - val_loss: 0.3063 - val_precision: 0.5000\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.1520 - precision: 0.8462 - val_loss: 0.3078 - val_precision: 1.0000\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 1s 124ms/step - loss: 0.1481 - precision: 0.8750 - val_loss: 0.3115 - val_precision: 0.0000e+00\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.1476 - precision: 0.8889 - val_loss: 0.3092 - val_precision: 0.5000\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.1471 - precision: 0.8571 - val_loss: 0.3069 - val_precision: 0.5000\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 1s 138ms/step - loss: 0.1546 - precision: 0.8571 - val_loss: 0.3060 - val_precision: 0.5000\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.1456 - precision: 1.0000 - val_loss: 0.3196 - val_precision: 0.0000e+00\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 0.1484 - precision: 1.0000 - val_loss: 0.3060 - val_precision: 0.5000\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.1512 - precision: 0.8462 - val_loss: 0.3117 - val_precision: 0.5000\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.1481 - precision: 0.8000 - val_loss: 0.3133 - val_precision: 0.0000e+00\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.1466 - precision: 1.0000 - val_loss: 0.3125 - val_precision: 0.0000e+00\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 1s 142ms/step - loss: 0.1449 - precision: 0.8889 - val_loss: 0.3121 - val_precision: 0.5000\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 1s 162ms/step - loss: 0.1446 - precision: 0.8889 - val_loss: 0.3086 - val_precision: 0.5000\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 1s 165ms/step - loss: 0.1442 - precision: 0.8571 - val_loss: 0.3178 - val_precision: 0.0000e+00\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 2s 191ms/step - loss: 0.1525 - precision: 0.8571 - val_loss: 0.3089 - val_precision: 0.5000\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 1s 156ms/step - loss: 0.1492 - precision: 1.0000 - val_loss: 0.3163 - val_precision: 0.5000\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.1436 - precision: 0.8889 - val_loss: 0.3116 - val_precision: 0.5000\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 1s 153ms/step - loss: 0.1446 - precision: 0.8462 - val_loss: 0.3206 - val_precision: 0.0000e+00\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 2s 180ms/step - loss: 0.1454 - precision: 0.7500 - val_loss: 0.3113 - val_precision: 0.5000\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 2s 170ms/step - loss: 0.1458 - precision: 0.9000 - val_loss: 0.3153 - val_precision: 0.5000\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 2s 166ms/step - loss: 0.1426 - precision: 0.8333 - val_loss: 0.3133 - val_precision: 0.5000\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 1s 153ms/step - loss: 0.1470 - precision: 0.8333 - val_loss: 0.3119 - val_precision: 0.5000\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 1s 153ms/step - loss: 0.1474 - precision: 0.7857 - val_loss: 0.3132 - val_precision: 0.5000\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 1s 127ms/step - loss: 0.1454 - precision: 0.8750 - val_loss: 0.3165 - val_precision: 0.5000\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.1439 - precision: 0.9091 - val_loss: 0.3147 - val_precision: 0.5000\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.1457 - precision: 0.8125 - val_loss: 0.3115 - val_precision: 0.5000\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 0.1442 - precision: 0.8182 - val_loss: 0.3148 - val_precision: 0.5000\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 1s 133ms/step - loss: 0.1415 - precision: 0.8571 - val_loss: 0.3155 - val_precision: 0.5000\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 1s 133ms/step - loss: 0.1451 - precision: 0.8571 - val_loss: 0.3123 - val_precision: 0.5000\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 1s 134ms/step - loss: 0.1501 - precision: 0.8125 - val_loss: 0.3179 - val_precision: 0.5000\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 0.1424 - precision: 1.0000 - val_loss: 0.3280 - val_precision: 0.0000e+00\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.1527 - precision: 1.0000 - val_loss: 0.3142 - val_precision: 0.5000\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.1479 - precision: 0.8125 - val_loss: 0.3110 - val_precision: 0.5000\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 0.1411 - precision: 0.9000 - val_loss: 0.3193 - val_precision: 0.5000\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 2s 163ms/step - loss: 0.1410 - precision: 0.9000 - val_loss: 0.3117 - val_precision: 0.5000\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 1s 156ms/step - loss: 0.1441 - precision: 0.8462 - val_loss: 0.3181 - val_precision: 0.5000\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 1s 163ms/step - loss: 0.1403 - precision: 0.9091 - val_loss: 0.3140 - val_precision: 0.5000\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.1402 - precision: 0.8667 - val_loss: 0.3209 - val_precision: 0.5000\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.1448 - precision: 0.8000 - val_loss: 0.3133 - val_precision: 0.3333\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 0.1475 - precision: 0.8125 - val_loss: 0.3187 - val_precision: 0.5000\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.1432 - precision: 0.8333 - val_loss: 0.3181 - val_precision: 0.5000\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 0.1409 - precision: 0.8667 - val_loss: 0.3181 - val_precision: 0.5000\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 1s 156ms/step - loss: 0.1405 - precision: 0.8333 - val_loss: 0.3158 - val_precision: 0.5000\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 1s 163ms/step - loss: 0.1463 - precision: 0.8667 - val_loss: 0.3154 - val_precision: 0.3333\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 0.1389 - precision: 0.8571 - val_loss: 0.3221 - val_precision: 0.5000\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 1s 138ms/step - loss: 0.1379 - precision: 0.8571 - val_loss: 0.3185 - val_precision: 0.5000\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 0.1379 - precision: 0.8667 - val_loss: 0.3317 - val_precision: 0.0000e+00\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 1s 162ms/step - loss: 0.1635 - precision: 1.0000 - val_loss: 0.3150 - val_precision: 0.5000\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 0.1435 - precision: 0.8125 - val_loss: 0.3117 - val_precision: 0.5000\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.1438 - precision: 0.9000 - val_loss: 0.3254 - val_precision: 0.5000\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 2s 171ms/step - loss: 0.1418 - precision: 0.8571 - val_loss: 0.3127 - val_precision: 0.3333\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 1s 164ms/step - loss: 0.1424 - precision: 0.8571 - val_loss: 0.3297 - val_precision: 0.0000e+00\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 1s 143ms/step - loss: 0.1533 - precision: 1.0000 - val_loss: 0.3115 - val_precision: 0.5000\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.1502 - precision: 0.8571 - val_loss: 0.3081 - val_precision: 0.5000\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 1s 135ms/step - loss: 0.1428 - precision: 0.8889 - val_loss: 0.3363 - val_precision: 0.0000e+00\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 1s 137ms/step - loss: 0.1450 - precision: 0.9000 - val_loss: 0.3112 - val_precision: 0.5000\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 1s 142ms/step - loss: 0.1405 - precision: 0.8462 - val_loss: 0.3254 - val_precision: 0.5000\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.1407 - precision: 0.8889 - val_loss: 0.3127 - val_precision: 0.5000\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 1s 164ms/step - loss: 0.1368 - precision: 0.9167 - val_loss: 0.3168 - val_precision: 0.5000\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 1s 156ms/step - loss: 0.1372 - precision: 0.9167 - val_loss: 0.3179 - val_precision: 0.5000\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.1363 - precision: 0.9091 - val_loss: 0.3118 - val_precision: 0.5000\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 1s 163ms/step - loss: 0.1375 - precision: 0.8667 - val_loss: 0.3149 - val_precision: 0.5000\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 1s 162ms/step - loss: 0.1364 - precision: 0.8571 - val_loss: 0.3157 - val_precision: 0.3333\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.1381 - precision: 0.8462 - val_loss: 0.3208 - val_precision: 0.3333\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 1s 162ms/step - loss: 0.1374 - precision: 0.8462 - val_loss: 0.3158 - val_precision: 0.3333\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.1396 - precision: 0.8889 - val_loss: 0.3129 - val_precision: 0.5000\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.1413 - precision: 0.8125 - val_loss: 0.3160 - val_precision: 0.5000\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 0.1355 - precision: 0.9167 - val_loss: 0.3197 - val_precision: 0.5000\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.1358 - precision: 0.8571 - val_loss: 0.3221 - val_precision: 0.5000\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.1405 - precision: 1.0000 - val_loss: 0.3120 - val_precision: 0.3333\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.1531 - precision: 0.8125 - val_loss: 0.3142 - val_precision: 0.5000\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 0.1454 - precision: 0.8889 - val_loss: 0.3349 - val_precision: 0.0000e+00\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.1366 - precision: 0.9167 - val_loss: 0.3103 - val_precision: 0.3333\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.1343 - precision: 0.8571 - val_loss: 0.3238 - val_precision: 0.5000\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 1s 153ms/step - loss: 0.1450 - precision: 1.0000 - val_loss: 0.3134 - val_precision: 0.5000\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.1427 - precision: 0.8667 - val_loss: 0.3114 - val_precision: 0.3333\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 1s 129ms/step - loss: 0.1401 - precision: 0.8125 - val_loss: 0.3182 - val_precision: 0.5000\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 1s 153ms/step - loss: 0.1352 - precision: 0.9000 - val_loss: 0.3132 - val_precision: 0.5000\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.1348 - precision: 0.8000 - val_loss: 0.3152 - val_precision: 0.5000\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.1346 - precision: 0.9091 - val_loss: 0.3249 - val_precision: 0.5000\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 1s 167ms/step - loss: 0.1374 - precision: 0.8571 - val_loss: 0.3072 - val_precision: 0.3333\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 1s 163ms/step - loss: 0.1384 - precision: 0.8333 - val_loss: 0.3161 - val_precision: 0.5000\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 0.1317 - precision: 0.9167 - val_loss: 0.3115 - val_precision: 0.5000\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 0.1324 - precision: 0.9167 - val_loss: 0.3204 - val_precision: 0.5000\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 1s 156ms/step - loss: 0.1370 - precision: 0.9000 - val_loss: 0.3139 - val_precision: 0.5000\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.1347 - precision: 0.8571 - val_loss: 0.3086 - val_precision: 0.5000\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.1281 - precision: 1.0000 - val_loss: 0.3516 - val_precision: 0.0000e+00\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 0.1391 - precision: 1.0000 - val_loss: 0.3070 - val_precision: 0.3333\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 1s 162ms/step - loss: 0.1479 - precision: 0.7647 - val_loss: 0.3113 - val_precision: 0.3333\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.1345 - precision: 1.0000 - val_loss: 0.3378 - val_precision: 0.0000e+00\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.1377 - precision: 0.8889 - val_loss: 0.3048 - val_precision: 0.5000\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 0.1344 - precision: 0.8571 - val_loss: 0.3166 - val_precision: 0.5000\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.1360 - precision: 0.9000 - val_loss: 0.3142 - val_precision: 0.5000\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 1s 160ms/step - loss: 0.1336 - precision: 0.8571 - val_loss: 0.3083 - val_precision: 0.5000\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.1309 - precision: 0.9167 - val_loss: 0.3240 - val_precision: 0.5000\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 1s 165ms/step - loss: 0.1316 - precision: 0.9167 - val_loss: 0.3164 - val_precision: 0.5000\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 0.1304 - precision: 0.9167 - val_loss: 0.3174 - val_precision: 0.5000\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.1306 - precision: 0.9167 - val_loss: 0.3155 - val_precision: 0.5000\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 0.1319 - precision: 0.9167 - val_loss: 0.3160 - val_precision: 0.5000\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 1s 136ms/step - loss: 0.1301 - precision: 0.9231 - val_loss: 0.3137 - val_precision: 0.5000\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 0.1324 - precision: 0.9231 - val_loss: 0.3231 - val_precision: 0.5000\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 1s 143ms/step - loss: 0.1334 - precision: 0.9091 - val_loss: 0.3121 - val_precision: 0.5000\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 1s 142ms/step - loss: 0.1318 - precision: 0.8571 - val_loss: 0.3166 - val_precision: 0.5000\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.1327 - precision: 0.8571 - val_loss: 0.3187 - val_precision: 0.5000\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 1s 137ms/step - loss: 0.1296 - precision: 0.9167 - val_loss: 0.3361 - val_precision: 0.0000e+00\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 2s 171ms/step - loss: 0.1404 - precision: 1.0000 - val_loss: 0.3114 - val_precision: 0.3333\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.1310 - precision: 0.9167 - val_loss: 0.3153 - val_precision: 0.5000\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 1s 156ms/step - loss: 0.1294 - precision: 0.9167 - val_loss: 0.3193 - val_precision: 0.5000\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 1s 153ms/step - loss: 0.1289 - precision: 0.9167 - val_loss: 0.3183 - val_precision: 0.5000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300\n",
    "history = modelb_glove200.fit(padded, training_labels_final, \n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(val_padded, val_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision = history.history['precision']\n",
    "val_precision = history.history['val_precision']\n",
    "epochs=range(len(precision))\n",
    "plt.plot(epochs, precision, 'r')\n",
    "plt.plot(epochs, val_precision, 'b')\n",
    "plt.title('Training and validation Precision')\n",
    "plt.ylim((0,1.5))\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4865 - precision: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.48645058274269104, 0.75]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelb_glove200.evaluate(test_padded, test_labels_final)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
